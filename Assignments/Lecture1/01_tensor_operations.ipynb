{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "01-tensor-operations.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfyMQ9qblO_-",
        "colab_type": "text"
      },
      "source": [
        "# Some basic Pytorch functions\n",
        "\n",
        "### torch.Tensor\n",
        "\n",
        "This is a short introduction about some basic functions commonly used with Pytorch tensors. The main reason why I've chosen these functions is because I usually use them when implementing deep learning models and I was confused about their proper use since some of them are quite similar, and even some times this has been the main reason why the model was not trained correctly:\n",
        "- torch.permute vs torch.transpose\n",
        "- torch.view vs torch.reshape and torch.contiguous\n",
        "- torch.squeeze vs torch.unsqueeze\n",
        "- torch.flatten\n",
        "- torch.argmax \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2fcGbKUlPAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcpHQ11IlPAR",
        "colab_type": "text"
      },
      "source": [
        "## Function 1 - torch.permute vs torch.transpose\n",
        "\n",
        "First, we create the tensor we'll be using in the assignment. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sVFR-K-lPAT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f6fd85c-04c2-4a3c-88ea-78ff46c2af1c"
      },
      "source": [
        "x = torch.tensor([[[1, 2], [3, 4.],[5, 6]],[[7, 8],[9, 10],[11, 12]]])\n",
        "x.dtype, x.size()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.float32, torch.Size([2, 3, 2]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8ctLrXElPAh",
        "colab_type": "text"
      },
      "source": [
        "**torch.transpose** is a function that changes the order of the dimensions in a tensor. For instance, if we want to swap the first for the last dimension, you can do the following: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG0CAYVflPAj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "fa00c6e9-5380-4b46-d175-9c56965d8ca2"
      },
      "source": [
        "print(x)\n",
        "y = x.transpose(0,2)\n",
        "print(y, y.size())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 1.,  2.],\n",
            "         [ 3.,  4.],\n",
            "         [ 5.,  6.]],\n",
            "\n",
            "        [[ 7.,  8.],\n",
            "         [ 9., 10.],\n",
            "         [11., 12.]]])\n",
            "tensor([[[ 1.,  7.],\n",
            "         [ 3.,  9.],\n",
            "         [ 5., 11.]],\n",
            "\n",
            "        [[ 2.,  8.],\n",
            "         [ 4., 10.],\n",
            "         [ 6., 12.]]]) torch.Size([2, 3, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGvQKO_uCWUD",
        "colab_type": "text"
      },
      "source": [
        "And if you want to swap the three dimensions at the same time:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peU9njzUvXjC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "55d1b634-65d6-47d9-8d55-a66a702f25c3"
      },
      "source": [
        "y = x.transpose(1, 2, 0)\n",
        "print(y, y.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-102-9b3f51ec6426>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: transpose() received an invalid combination of arguments - got (int, int, int), but expected one of:\n * (name dim0, name dim1)\n * (int dim0, int dim1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TELnDPW2BKRr",
        "colab_type": "text"
      },
      "source": [
        "**torch.transpose** just swaps two dimensions, in this case you should use **torch.permute**. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vfqeu9cDx3M_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "3058c318-e564-4a52-f0ca-e2d71b595f45"
      },
      "source": [
        "y = x.permute(1, 2, 0)\n",
        "print(y, y.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 1.,  7.],\n",
            "         [ 2.,  8.]],\n",
            "\n",
            "        [[ 3.,  9.],\n",
            "         [ 4., 10.]],\n",
            "\n",
            "        [[ 5., 11.],\n",
            "         [ 6., 12.]]]) torch.Size([3, 2, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3iUbLLsA2Zx",
        "colab_type": "text"
      },
      "source": [
        "You can also swap just two dimensions using **torch.permute** as we did with **torch.transpose**, but you should specify all dimensions: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NksTrU1lBKhF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "b9451764-8015-401c-b032-0057e3644b82"
      },
      "source": [
        "y = x.permute(2,1,0)\n",
        "print(y, y.size())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 1.,  7.],\n",
            "         [ 3.,  9.],\n",
            "         [ 5., 11.]],\n",
            "\n",
            "        [[ 2.,  8.],\n",
            "         [ 4., 10.],\n",
            "         [ 6., 12.]]]) torch.Size([2, 3, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8IhQfjxlPA5",
        "colab_type": "text"
      },
      "source": [
        "## Function 2 - torch.view vs torch.reshape\n",
        "\n",
        "**torch.view** is a function that, by using the same data, changes the shape of the tensor. Here you have to specify the new size of each dimension. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMe_b0IERtiv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "5478f414-ccb0-43f2-9dcf-1128ffb349ab"
      },
      "source": [
        "x"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.,  2.],\n",
              "         [ 3.,  4.],\n",
              "         [ 5.,  6.]],\n",
              "\n",
              "        [[ 7.,  8.],\n",
              "         [ 9., 10.],\n",
              "         [11., 12.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUc-srC4lPA6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "63e71475-0558-42dc-bcb4-e70f9d7ce13c"
      },
      "source": [
        "y = x.view(12)\n",
        "print(y.size(), y)\n",
        "z = y.view(3, 2, 2)\n",
        "print(z.size(), z)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([12]) tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.])\n",
            "torch.Size([3, 2, 2]) tensor([[[ 1.,  2.],\n",
            "         [ 3.,  4.]],\n",
            "\n",
            "        [[ 5.,  6.],\n",
            "         [ 7.,  8.]],\n",
            "\n",
            "        [[ 9., 10.],\n",
            "         [11., 12.]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huFyRCyrlPBH",
        "colab_type": "text"
      },
      "source": [
        "If you want to transpose and then change the size using view you can do the following: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGxkS2lRlPBI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "ed093296-b5a0-4bfb-cdc9-21a32e5fa57a"
      },
      "source": [
        "y = x.transpose(2,0)\n",
        "print(y, y.size())\n",
        "z = y.view(12)\n",
        "print(z, z.size())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 1.,  7.],\n",
            "         [ 3.,  9.],\n",
            "         [ 5., 11.]],\n",
            "\n",
            "        [[ 2.,  8.],\n",
            "         [ 4., 10.],\n",
            "         [ 6., 12.]]]) torch.Size([2, 3, 2])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-62e58ee6b8da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUlZlpijlPBM",
        "colab_type": "text"
      },
      "source": [
        "This is not possible because by using transpose you loose the contiguity-like condition. You can solve this using **torch.reshape**, which does not depend on this condition, or by making the new tensor contiguous by using **torch.contiguous**. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhkJbSEPEqWw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "bb1d2a0f-44db-44fe-f87d-9a9c59f06850"
      },
      "source": [
        "z1 = y.reshape(12)\n",
        "print(z1, z1.size())\n",
        "z2 = y.contiguous().view(12)\n",
        "print(z2, z2.size())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 1.,  7.,  3.,  9.,  5., 11.,  2.,  8.,  4., 10.,  6., 12.]) torch.Size([12])\n",
            "tensor([ 1.,  7.,  3.,  9.,  5., 11.,  2.,  8.,  4., 10.,  6., 12.]) torch.Size([12])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqfBbR-SlPBN",
        "colab_type": "text"
      },
      "source": [
        "## Function 3 - torch.flatten\n",
        "\n",
        "This function is used to flatten a tensor. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1voL8xUhRrAI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "1f0651e1-8a88-4434-98da-66632ddbec52"
      },
      "source": [
        "x"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.,  2.],\n",
              "         [ 3.,  4.],\n",
              "         [ 5.,  6.]],\n",
              "\n",
              "        [[ 7.,  8.],\n",
              "         [ 9., 10.],\n",
              "         [11., 12.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljJOvSD7lPBO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "20379726-a66a-4f58-df01-869e0364a8fd"
      },
      "source": [
        "y = x.flatten()\n",
        "print(y, y.size())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.]) torch.Size([12])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-FENuoUlPBV",
        "colab_type": "text"
      },
      "source": [
        "But if you want to flatten just one dimension, for instance the first one, you can do what is next:\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66YCAJ7RlPBW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "51c6dacb-2760-4e3b-c909-d2c393a2b9c0"
      },
      "source": [
        "y = x.flatten(end_dim=1)\n",
        "print(y, y.size())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.,  2.],\n",
            "        [ 3.,  4.],\n",
            "        [ 5.,  6.],\n",
            "        [ 7.,  8.],\n",
            "        [ 9., 10.],\n",
            "        [11., 12.]]) torch.Size([6, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ikab-KielPBZ",
        "colab_type": "text"
      },
      "source": [
        "In both cases you can use **torch.view** or **torch.reshape** for instance: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vP0dQm5pLtgR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "94b95fe3-9924-4b5b-9393-ffc4dfba55e6"
      },
      "source": [
        "y1 = x.view(-1)\n",
        "print(y1, y1.size())\n",
        "\n",
        "y2 = x.view(-1, 6, 2)\n",
        "print(y2, y2.size())\n",
        "\n",
        "y1 = x.reshape(-1)\n",
        "print(y1, y1.size())\n",
        "\n",
        "y2 = x.reshape(-1, 6, 2)\n",
        "print(y2, y2.size())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.]) torch.Size([12])\n",
            "tensor([[[ 1.,  2.],\n",
            "         [ 3.,  4.],\n",
            "         [ 5.,  6.],\n",
            "         [ 7.,  8.],\n",
            "         [ 9., 10.],\n",
            "         [11., 12.]]]) torch.Size([1, 6, 2])\n",
            "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.]) torch.Size([12])\n",
            "tensor([[[ 1.,  2.],\n",
            "         [ 3.,  4.],\n",
            "         [ 5.,  6.],\n",
            "         [ 7.,  8.],\n",
            "         [ 9., 10.],\n",
            "         [11., 12.]]]) torch.Size([1, 6, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXD-EbidlPBa",
        "colab_type": "text"
      },
      "source": [
        "## Function 4 - torch.squeeze vs torch.unsqueeze\n",
        "\n",
        "If we decide to use **torch.view** or **torch.reshape** to flatten a specific dimension, we will have to remove the dimension that is not used (the one it is empty): "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPoYs4FjlPBa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "332c1cbd-02de-45ff-e19e-52ce5bb0c29d"
      },
      "source": [
        "z1 = y2.squeeze(0)\n",
        "print(z1, z1.size())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.,  2.],\n",
            "        [ 3.,  4.],\n",
            "        [ 5.,  6.],\n",
            "        [ 7.,  8.],\n",
            "        [ 9., 10.],\n",
            "        [11., 12.]]) torch.Size([6, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97UuiufTlPBc",
        "colab_type": "text"
      },
      "source": [
        "If you try to remove a dimension that is not empty it will do nothing: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYILYBeFlPBd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "70337306-bc87-45a7-d6c8-9393a9fc9b78"
      },
      "source": [
        "z2 = y2.squeeze(1)\n",
        "print(z2, z2.size())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 1.,  2.],\n",
            "         [ 3.,  4.],\n",
            "         [ 5.,  6.],\n",
            "         [ 7.,  8.],\n",
            "         [ 9., 10.],\n",
            "         [11., 12.]]]) torch.Size([1, 6, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTJrIXDQlPBg",
        "colab_type": "text"
      },
      "source": [
        "You can also create a new dimenion (empty of course) by using the opposite function **torch.unsqeeze**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uahfs7YGlPBh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "01cc28e7-b527-43a9-d1a5-dfeaf9b51596"
      },
      "source": [
        "z3 = z1.unsqueeze(0)\n",
        "print(z3, z3.size())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 1.,  2.],\n",
            "         [ 3.,  4.],\n",
            "         [ 5.,  6.],\n",
            "         [ 7.,  8.],\n",
            "         [ 9., 10.],\n",
            "         [11., 12.]]]) torch.Size([1, 6, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TD_UQ3DlPBn",
        "colab_type": "text"
      },
      "source": [
        "## Function 5 - torch.argmax vs torch.max\n",
        "\n",
        "**torch.argmax** returns the indices of the maximum value of all elements in the input tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6GWsNOBRm9o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "50914581-0eee-463e-a9c4-7730090f3f7d"
      },
      "source": [
        "x"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.,  2.],\n",
              "         [ 3.,  4.],\n",
              "         [ 5.,  6.]],\n",
              "\n",
              "        [[ 7.,  8.],\n",
              "         [ 9., 10.],\n",
              "         [11., 12.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2ybHQAjlPBn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "5387775d-cb24-4caf-a77c-387e4ba82eaa"
      },
      "source": [
        "x.argmax(dim=1)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 2],\n",
              "        [2, 2]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eSNZaHNlPBq",
        "colab_type": "text"
      },
      "source": [
        "**torch.max** returns also the maximum values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFQs8mcglPBq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "5cfe5f1d-9735-45b8-ec4b-b55c53443d5b"
      },
      "source": [
        "x.max(dim=1)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.max(values=tensor([[ 5.,  6.],\n",
              "        [11., 12.]]), indices=tensor([[2, 2],\n",
              "        [2, 2]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6ts07CFCuly",
        "colab_type": "text"
      },
      "source": [
        "You can do the same using both functions but with 1D tensor. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXCgIRAtC1q1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "eccc8c51-3b26-43ed-f44c-1cf830e67be2"
      },
      "source": [
        "y = x.flatten()\n",
        "print(y.argmax(), y.max(dim=0))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(11) torch.return_types.max(\n",
            "values=tensor(12.),\n",
            "indices=tensor(11))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxgwwDvmlPBy",
        "colab_type": "text"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "Here we mentioned some functions that might be used to prepare the input given to the model or when the output of the model needs to be changed to fit in the loss function for instance. It is really important to understand how these functions change the data regarding dimensions and shape, and also how to interpret their ouptut. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4DK-UdXlPBz",
        "colab_type": "text"
      },
      "source": [
        "## Reference Links\n",
        "* Official documentation for `torch.Tensor`: https://pytorch.org/docs/stable/tensors.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7q41uV-lPB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}