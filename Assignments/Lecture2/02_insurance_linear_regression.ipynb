{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "02-insurance-linear-regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "df4e59714a1f4174aad30b805dd5ad0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_873ac26b1e37458a9b208a88c9a8522f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c457229590004076bd2facf8184f7413",
              "IPY_MODEL_985fcf4aafa240d99e34c24b240de0f5"
            ]
          }
        },
        "873ac26b1e37458a9b208a88c9a8522f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c457229590004076bd2facf8184f7413": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fadf89d91cfe44c2a98b9d89ba99aa57",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c6a72df0f325438e9a663e5e65497044"
          }
        },
        "985fcf4aafa240d99e34c24b240de0f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_63663178ed504cf0a0ae31d1daf05acf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 57344/? [00:20&lt;00:00, 140855.69it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c7bec8be1b5a456cb407f14301e84636"
          }
        },
        "fadf89d91cfe44c2a98b9d89ba99aa57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c6a72df0f325438e9a663e5e65497044": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "63663178ed504cf0a0ae31d1daf05acf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c7bec8be1b5a456cb407f14301e84636": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "JzLlTH9wRanm",
        "colab_type": "text"
      },
      "source": [
        "# Insurance cost prediction using linear regression\n",
        "\n",
        "In this assignment we're going to use information like a person's age, sex, BMI, no. of children and smoking habit to predict the price of yearly medical bills. This kind of model is useful for insurance companies to determine the yearly insurance premium for a person. The dataset for this problem is taken from: https://www.kaggle.com/mirichoi0218/insurance\n",
        "\n",
        "\n",
        "We will create a model with the following steps:\n",
        "1. Download and explore the dataset\n",
        "2. Prepare the dataset for training\n",
        "3. Create a linear regression model\n",
        "4. Train the model to fit the data\n",
        "5. Make predictions using the trained model\n",
        "\n",
        "\n",
        "This assignment builds upon the concepts from the first 2 lectures. It will help to review these Jupyter notebooks:\n",
        "- PyTorch basics: https://jovian.ml/aakashns/01-pytorch-basics\n",
        "- Linear Regression: https://jovian.ml/aakashns/02-linear-regression\n",
        "- Logistic Regression: https://jovian.ml/aakashns/03-logistic-regression\n",
        "- Linear regression (minimal): https://jovian.ml/aakashns/housing-linear-minimal\n",
        "- Logistic regression (minimal): https://jovian.ml/aakashns/mnist-logistic-minimal\n",
        "\n",
        "As you go through this notebook, you will find a **???** in certain places. Your job is to replace the **???** with appropriate code or values, to ensure that the notebook runs properly end-to-end . In some cases, you'll be required to choose some hyperparameters (learning rate, batch size etc.). Try to experiment with the hyperparameters to get the lowest loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs4byJViRanv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "import seaborn as sns\n",
        "import random\n",
        "import numpy as np"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obAhuQhRRan2",
        "colab_type": "text"
      },
      "source": [
        "## Step 1: Download and explore the data\n",
        "\n",
        "Let us begin by downloading the data. We'll use the `download_url` function from PyTorch to get the data as a CSV (comma-separated values) file. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "2j2RR41XRan2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "df4e59714a1f4174aad30b805dd5ad0e",
            "873ac26b1e37458a9b208a88c9a8522f",
            "c457229590004076bd2facf8184f7413",
            "985fcf4aafa240d99e34c24b240de0f5",
            "fadf89d91cfe44c2a98b9d89ba99aa57",
            "c6a72df0f325438e9a663e5e65497044",
            "63663178ed504cf0a0ae31d1daf05acf",
            "c7bec8be1b5a456cb407f14301e84636"
          ]
        },
        "outputId": "56666772-25af-49f4-f2d1-d3189f7d62ac"
      },
      "source": [
        "DATASET_URL = \"https://hub.jovian.ml/wp-content/uploads/2020/05/insurance.csv\"\n",
        "DATA_FILENAME = \"insurance.csv\"\n",
        "download_url(DATASET_URL, '.')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://hub.jovian.ml/wp-content/uploads/2020/05/insurance.csv to ./insurance.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df4e59714a1f4174aad30b805dd5ad0e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5L5c3_8NRan5",
        "colab_type": "text"
      },
      "source": [
        "To load the dataset into memory, we'll use the `read_csv` function from the `pandas` library. The data will be loaded as a Pandas dataframe. See this short tutorial to learn more: https://data36.com/pandas-tutorial-1-basics-reading-data-files-dataframes-data-selection/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtexWsMHRan6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "64d3708c-d260-46cc-c89a-d882d1dcae23"
      },
      "source": [
        "dataframe_raw = pd.read_csv(DATA_FILENAME)\n",
        "dataframe_raw.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age     sex     bmi  children smoker     region      charges\n",
              "0   19  female  27.900         0    yes  southwest  16884.92400\n",
              "1   18    male  33.770         1     no  southeast   1725.55230\n",
              "2   28    male  33.000         3     no  southeast   4449.46200\n",
              "3   33    male  22.705         0     no  northwest  21984.47061\n",
              "4   32    male  28.880         0     no  northwest   3866.85520"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cRBxLkSRan9",
        "colab_type": "text"
      },
      "source": [
        "We're going to do a slight customization of the data, so that you every participant receives a slightly different version of the dataset. Fill in your name below as a string (enter at least 5 characters)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzuwOxllRan-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "your_name = 'Carla' # at least 5 characters"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4vsSH2XRaoB",
        "colab_type": "text"
      },
      "source": [
        "The `customize_dataset` function will customize the dataset slightly using your name as a source of random numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D37UdhLsRaoC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def customize_dataset(dataframe_raw, rand_str):\n",
        "    dataframe = dataframe_raw.copy(deep=True)\n",
        "    # drop some rows\n",
        "    dataframe = dataframe.sample(int(0.95*len(dataframe)), random_state=int(ord(rand_str[0])))\n",
        "    # scale input\n",
        "    dataframe.bmi = dataframe.bmi * ord(rand_str[1])/100.\n",
        "    # scale target\n",
        "    dataframe.charges = dataframe.charges * ord(rand_str[2])/100.\n",
        "    # drop column\n",
        "    if ord(rand_str[3]) % 2 == 1:\n",
        "        dataframe = dataframe.drop(['region'], axis=1)\n",
        "    return dataframe"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCgpcMh2RaoH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "753475d1-80ff-4511-ee1e-80e201cfb65f"
      },
      "source": [
        "dataframe = customize_dataset(dataframe_raw, your_name)\n",
        "dataframe.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1054</th>\n",
              "      <td>27</td>\n",
              "      <td>female</td>\n",
              "      <td>20.82590</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3822.956142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>54</td>\n",
              "      <td>female</td>\n",
              "      <td>29.87600</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southwest</td>\n",
              "      <td>13800.064800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1281</th>\n",
              "      <td>47</td>\n",
              "      <td>female</td>\n",
              "      <td>26.81565</td>\n",
              "      <td>2</td>\n",
              "      <td>yes</td>\n",
              "      <td>northwest</td>\n",
              "      <td>27970.696347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>61</td>\n",
              "      <td>female</td>\n",
              "      <td>29.02240</td>\n",
              "      <td>3</td>\n",
              "      <td>yes</td>\n",
              "      <td>southeast</td>\n",
              "      <td>35274.098652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1252</th>\n",
              "      <td>20</td>\n",
              "      <td>male</td>\n",
              "      <td>26.48100</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>18505.445580</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      age     sex       bmi  children smoker     region       charges\n",
              "1054   27  female  20.82590         0     no  northwest   3822.956142\n",
              "96     54  female  29.87600         3     no  southwest  13800.064800\n",
              "1281   47  female  26.81565         2    yes  northwest  27970.696347\n",
              "103    61  female  29.02240         3    yes  southeast  35274.098652\n",
              "1252   20    male  26.48100         0    yes  southwest  18505.445580"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KT5BElfuRaoK",
        "colab_type": "text"
      },
      "source": [
        "Let us answer some basic questions about the dataset. \n",
        "\n",
        "\n",
        "**Q: How many rows does the dataset have?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX3Jo3_IRaoL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fcc992a7-c12b-4551-e4f4-3d4366d303ab"
      },
      "source": [
        "num_rows = dataframe.shape[0]\n",
        "print(num_rows)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1271\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTu3DNHmRaoP",
        "colab_type": "text"
      },
      "source": [
        "**Q: How many columns doe the dataset have**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WftFIAOgRaoQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1030fc32-0214-4a59-a93b-03f2f0e205eb"
      },
      "source": [
        "num_cols = dataframe.shape[1]\n",
        "print(num_cols)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy0FxgYnRaoU",
        "colab_type": "text"
      },
      "source": [
        "**Q: What are the column titles of the input variables?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngx1TlnTRaoU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8759028f-2e52-4f29-d207-2a4909e467de"
      },
      "source": [
        "input_cols = dataframe.columns[:-1]\n",
        "input_cols"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['age', 'sex', 'bmi', 'children', 'smoker', 'region'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAJ9QncrRaoX",
        "colab_type": "text"
      },
      "source": [
        "**Q: Which of the input columns are non-numeric or categorial variables ?**\n",
        "\n",
        "Hint: `sex` is one of them. List the columns that are not numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXAOn8yARaoY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categorical_cols = ['sex', 'smoker', 'region']"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PY7aneVnRaoa",
        "colab_type": "text"
      },
      "source": [
        "**Q: What are the column titles of output/target variable(s)?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YX-8nimjRaoa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_cols = ['charges']"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1PqnRGyRaoe",
        "colab_type": "text"
      },
      "source": [
        "**Q: (Optional) What is the minimum, maximum and average value of the `charges` column? Can you show the distribution of values in a graph?**\n",
        "Use this data visualization cheatsheet for referece: https://jovian.ml/aakashns/dataviz-cheatsheet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8w5bPl3uRaof",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "outputId": "aa2bc523-aa65-4d2d-98b3-aac2cd45588b"
      },
      "source": [
        "min = dataframe['charges'].min()\n",
        "max = dataframe['charges'].max()\n",
        "mean = dataframe['charges'].mean()\n",
        "print('minimum: ', min, 'maximum: ', max, 'average: ', mean)\n",
        "sns.distplot(dataframe.charges)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "minimum:  1278.9362460000002 maximum:  72698.2879314 average:  15176.124146456692\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fad55ab0eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAERCAYAAABSPe3hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZhcVZ3/8fe3q/d9TaeT7k5nIQkhQBKahFVkUYMi4IKjMMroKDM/x2XGcXiY/ef4c1xGfdzBuKIjiyK4oIBA2IWEDoSEkH3tTtJ7p/e9zu+Puh3a2CEVUtX3VtXn9Tz1VNWt21Xfurn59Olzzz3XnHOIiEhwpfldgIiIvDYFtYhIwCmoRUQCTkEtIhJwCmoRkYBTUIuIBFzcgtrMfmhmrWb2cozeb9zMNnq338TiPUVEEoHFaxy1mb0B6AN+4pxbGoP363PO5Z96ZSIiiSVuLWrn3JNA5+RlZjbfzB40sw1m9pSZLY7X54uIJIvp7qNeA3zcOXcO8GngOyfxs9lm1mBmz5nZtfEpT0QkeNKn64PMLB+4APiFmU0szvJeeyfwX1P82EHn3Fu8x3OccwfNbB6w1sw2O+d2x7tuERG/TVtQE2m9H3HOLTv2BefcvcC9r/XDzrmD3v0eM3scWA4oqEUk6U1b14dzrgfYa2bXAVjE2dH8rJmVmNlE67scuBB4JW7FiogESDyH590JPAssMrMmM/tr4Abgr83sJWALcE2Ub3c60OD93GPAF5xzCmoRSQlxG54nIiKxoTMTRUQCLi4HE8vLy11dXV083lpEJClt2LCh3TlXMdVrcQnquro6Ghoa4vHWIiJJycz2H+81dX2IiAScglpEJOAU1CIiAaegFhEJOAW1iEjAKahFRAJOQS0iEnAKahGRgFNQi4gE3HTORx04d6w7cMJ1rl9VOw2ViIgcn1rUIiIBp6AWEQk4BbWISMApqEVEAk5BLSIScApqEZGAU1CLiAScglpEJOAU1CIiAaegFhEJOAW1iEjAKahFRAJOQS0iEnBRBbWZFZvZPWa2zcy2mtn58S5MREQiop3m9OvAg865d5tZJpAbx5pERGSSEwa1mRUBbwD+CsA5NwKMxLcsERGZEE3Xx1ygDfiRmb1oZt83s7xjVzKzm8yswcwa2traYl6oiEiqiiao04EVwK3OueVAP3DLsSs559Y45+qdc/UVFRUxLlNEJHVFE9RNQJNzbp33/B4iwS0iItPghEHtnGsGGs1skbfocuCVuFYlIiJHRTvq4+PAz7wRH3uAD8avJBERmSyqoHbObQTq41yLiIhMQWcmiogEnIJaRCTgFNQiIgGnoBYRCTgFtYhIwCmoRUQCTkEtIhJwCmoRkYBTUIuIBFy0p5CnrDvWHXjN169fVTtNlYhIqlKLWkQk4BTUIiIBp6AWEQk4BbWISMApqEVEAk5BLSIScApqEZGAU1CLiAScglpEJOAU1CIiAaegFhEJOAW1iEjAKahFRAIuqtnzzGwf0AuMA2POufp4FiUiIq86mWlOL3XOtcetEhERmZLmoz4JXQMj/G7TYfpHxhgPO+aV5/POFbPJzgj5XZqIJLFo+6gd8Acz22BmN021gpndZGYNZtbQ1tYWuwoDYmB4jB89s4/dbX2EzEhPS+PJnW1c++1n2NnS63d5IpLEom1RX+ScO2hmM4CHzWybc+7JySs459YAawDq6+tdjOv01chYmJ88t58jAyN88MK5zC3PA2Bbcw+/23SYq7/1DD/7yCpW1Jb4XKmIJKOoWtTOuYPefStwH7AynkUFzYNbmmnsHOA99TVHQxpg8cxCHvjkxVQUZPHh2xvY197vY5UikqxOGNRmlmdmBROPgTcDL8e7sKAYHh3nhQNdLK8tZunsoj97fUZhNrd/aCXOOW780Xo6+oZ9qFJEklk0LepK4GkzewlYD/zOOfdgfMsKjk1N3YyMhVlZV3rcdeaW5/H9G8+luXuIT9z1IuPhpOr5ERGfnTConXN7nHNne7cznHOfm47CguL5/Z1UFmZRU5r7muudM6eE/7rmDJ7Z1cE31+6cpupEJBXozMTXcOjIIE1dg5xbV4qZnXD999TX8M7ls/n6ozv54y4NOReR2FBQv4bn93WSnmYsr4luNIeZ8dlrlzKvPI9P3LWR1t6hOFcoIqlAQX0cY+EwGxuPsHR2ETmZ0Z/QkpeVznduOIe+4VE+eedG9VeLyClTUB/Hwa5BhsfCLKkqPOmfXTSzgM9es5Rn93Tw9UfVXy0ip0ZBfRwTY6LrJo2bPhnX1dfwrhXVfHPtTp7amXxnaorI9FFQH8fejn5mFGSRn/X6p0P57LVnsKAin7+/ayMtPeqvFpHXR0E9hfGwY3/HwOtuTU/IzUznOzesYGBknE/c+SJj4+EYVSgiqURBPYXm7iGGx8LMLTu1oAY4rbKA/3ftUtbt7eRrj6i/WkROnqY5ncLe9j4guv7pO9YdOOE616+qZd3eDr79+C7OnVvKJQsrTrlGEUkdalFPYW/HAKV5mRTlZMTsPT9z9VIWzijgH+7eSHO3+qtFJHoK6mOEnWNfe/+fzJIXCzmZIb59wwqGRtVfLSInR10fx2jtGWZwdDwm/dMTJnePXHVWFT9vaOKmn27gitMrgUjXiIjI8ahFfYz9nac2fvpEltWUsKK2mMe2tbJX81eLSBQU1Mc43D1EdkYaJbmx658+1tvPmkVpXiY/b2hkYGQsbp8jIslBQX2Mlu4hKguzo5ot7/XKygjx3nNr6Rsa4/5Nh+P2OSKSHNRHPYlzjpbeIc6uLo77Z80uyeGSRRWs3dbKf/76ZRbNfO05RdSPLZK61KKepHtwlKHRMDOLsqfl8964sIIZBVn8auMhhkfHp+UzRSTxKKgnmRjfPLNweoI6PZTGO5fPpmdwlIdeaZ6WzxSRxKOgnqTZmzipcpqCGqC2LI9V80pZt6dTEzeJyJQU1JM09wxRnJNBdkb0FwqIhcsXV5KZnsYftqhVLSJ/TkE9SUvP0LT1T0+Wl5XOJQsr2Nrce3QebBGRCQpqz1g4TFvv8LR2e0x2wfxyCrPTeXBLM87p8l0i8qqog9rMQmb2opndH8+C/NLWO0zYTd+BxGNlpqdx+emVHOgcYEdLry81iEgwnUyL+pPA1ngV4reJA3mVPnR9TFhRW0JhdjrP7OrwrQYRCZ6ogtrMqoG3Ad+Pbzn+ae4eJmRGRX6WbzWE0ozz55Wxq61PU6GKyFHRtqi/BtwMHHduTjO7ycwazKyhrS3xLuba0jNERUEWobT4nToejXPnlpIRMp7Z3e5rHSISHCcMajO7Cmh1zm14rfWcc2ucc/XOufqKisS7gklr7xAzCv1rTU/IzUxnRW0JLzUeoW9YEzaJSHQt6guBq81sH3AXcJmZ/W9cq5pmY+EwRwZGKfex22OyC+aXMxZ2rNujvmoRiSKonXP/7Jyrds7VAe8F1jrn/jLulU2jzv4RHFCWl+l3KQBUFGSxYEY+LxzoIqyheiIpT+OogY6+EQDKAtKiBlheU0zXwCgHOgb8LkVEfHZSQe2ce9w5d1W8ivFLR98wAOUBaVEDLJlVSEbI2Nh4xO9SRMRnalED7f0j5GSEyM0KzvTcWekhzphVxOaD3boQrkiKU1ADnX0jlOUHpzU9YVlNMYOj4zpTUSTFKaiB9v7hwBxInGx+RT55Wem8qO4PkZSW8kE9Oh6me2A0UAcSJ4TSjLOri9jW3Evv0Kjf5YiIT1I+qCeG5pUHsOsD4IxZRYyHHU/u0JmKIqkq5YP66NC8vOC1qAFqS3PJyQjx6NYWv0sREZ8oqPu9oXkB7PqASPfHopkFPLa9lfGwTn4RSUUpH9TtfSPkZobIyZzey2+djMUzC+gaGOWFA11+lyIiPkj5oO7oC+aIj8kWVhaQnmY8ou4PkZSkoO4fCeSIj8myM0KsmlfKo1tb/S5FRHyQ0kE9Oh6me3A0kCe7HOuK0yvZ1drH/g5d/FYk1aR0UHf0R0Z8lAd0xMdkV5xeCcDabWpVi6Sa4Exu4YMuL6hLA95HDfDUznbK8jK5+/lGstKnPvB5/araaa5KRKZDSreouwYiQV2SAEENkVPK97b3a5ieSIpJ7aDuHyEjZOQFeGjeZPNn5DM8FuZgl+aoFkklKR3UnQOjlORmYubvBW2jNb88DwN2temAokgqSemg7uofoSQ3Mbo9AHKz0qkqymZ3W5/fpYjINErZoHbO0TUwkjD90xPmV+RzoHOAkTFdTEAkVaRsUHcPjjI8FqY0N8PvUk7K/Bn5jIedxlOLpJCUDerGzkEgcUZ8TKgryyNkpu4PkRSSukHtjZxIpD5qgMz0NGpKc9mtA4oiKSN1g7ozMYMaYF5FHoeODDI0Ou53KSIyDVI3qLsGyM5IC/T0psdTV5aHAw50ajy1SCo4YVCbWbaZrTezl8xsi5l9ZjoKi7emrkFKE7A1DZGrvqQZ7G1X94dIKohmro9h4DLnXJ+ZZQBPm9kDzrnn4lxbXDV2DiTcgcQJmelpzC7OYZ9GfoikhBO2qF3ExBCDDO+W0JNNOOdo6hpMyP7pCXXleTR1DTI6rvHUIskuqj5qMwuZ2UagFXjYObduinVuMrMGM2toa2uLdZ0x1dY7zPBYmJIEG0M9WV1ZHuPhyC8cEUluUQW1c27cObcMqAZWmtnSKdZZ45yrd87VV1RUxLrOmDo6NC9Buz4gEtSG+qlFUsFJjfpwzh0BHgNWx6ec6THRCk3kro+czBCVhdk6Q1EkBUQz6qPCzIq9xznAm4Bt8S4snhJ5DPVkdeW57O8c0PzUIkkumhZ1FfCYmW0CnifSR31/fMuKr8bOQcrzs8hMT+xh5HVleYyMhTncrX5qkWR2wuF5zrlNwPJpqGXaNHYNUFOa43cZp6yuLA+Afe39VJfk+lyNiMRLYjcpX6fGroGkCLbCnAxK8zLZ26EzFEWSWcoF9dh4mMNHhqgpSfwWNcDcsjz2d/QTduqnFklWKRfUzT1DjIUdNaWJ36KGyIkvAyPjtPUO+12KiMRJygX1xDzUNUnQ9QFQVxb5HjqdXCR5pV5Qeye7JMPBRIDSvEwKs9N14otIEku5oG7qHMAMqoqSI6jNjDlleexr78epn1okKaVcUDd2DVJVmJ3wY6gnm1ueR8/QmOb9EElSyZNWUWrqGqA6SQ4kTpgYT71+b6fPlYhIPKRcUDd2DibNgcQJMwqzyMkIKahFklRKBfXw2DgtvUNJcyBxQpoZc8pyWb9PQS2SjFIqqA92DeIcSXFW4rHmluext72f1t4hv0sRkRhLqaBu7JoYQ51cLWp4tZ/6+b1dPlciIrGWUkHddHQMdfK1qGcV55CTEeJ5dX+IJJ2UCurGzkEyQkZlYbbfpcRcKM04Z04J63RAUSTppFZQdw0wuziHUJr5XUpcnFtXyrbmHroHR/0uRURiKKWCuqlzICm7PSasnFuKc7Bhv1rVIskkpYK6sWuQ6iQ8kDhheW0xGSFjvQ4oiiSVlAnqvuExOvtHknJo3oTsjBBnVRezfm+H36WISAylTFBPXNB2TlnyBjVEuj82NXUzMDLmdykiEiMpE9T7vctVzSnN87mS+LpgfhljYafRHyJJJGWCeqJFXZvEBxMhMvIjMz2Np3a0+12KiMRIygT1/s5+inIyKMrN8LuUuMrOCLGyrpSnd7X5XYqIxMgJg9rMaszsMTN7xcy2mNknp6OwWDvQOZj0rekJF51Wzo6WPlp6NO+HSDKIpkU9Bvyjc24JcB7wd2a2JL5lxd6Bjn5qk/xA4oSLTysH4Omd6v4QSQYnDGrn3GHn3Ave415gKzA73oXF0njY0dSVOi3q02cWUpaXydO7FNQiyeCk+qjNrA5YDqyLRzHxcujIIGNhx5wUCeq0NOPCBeU8tbNd11EUSQJRB7WZ5QO/BP7eOdczxes3mVmDmTW0tQXrQFaqjPiY7KLTymnvG2Zbc6/fpYjIKYoqqM0sg0hI/8w5d+9U6zjn1jjn6p1z9RUVFbGs8ZTtnwjqFOmjhlf7qZ/YEaxfmiJy8qIZ9WHAD4Ctzrmvxr+k2DvQOUBGyKgqSt55Po5VVZTDmbOLeGhLs9+liMgpiqZFfSHwfuAyM9vo3d4a57pi6kDHANUluUk7venxrF46kxcPHOFw96DfpYjIKYhm1MfTzjlzzp3lnFvm3X4/HcXFyoEkn970eFYvnQnAH7a0+FyJiJyKlDgzcX9Hf8qM+JhsfkU+p83I58GX1f0hksiSPqi7B0bpGRpLqREfk61eOpN1ezvo7B/xuxQReZ2SPqj3d/YDqTXiY7K3nDGTsINHXlH3h0iiSvqgPpCCY6gnO2NWIdUlOfz+5cN+lyIir1PSB/XetkiLOtkvGHA8ZsbVZ8/iyR1tHDqi0R8iiSjpg3p3Wx+zi3PIzUz3uxTfvG9lLQ64a/0Bv0sRkdch6YN6T3s/8yqS+6ouJ1JTmssbF1Zw1/ONjI6H/S5HRE5SUge1c47drX3Mr8j3uxTf3bBqDq29wzqoKJKAkjqoW3qG6R8ZZ36Kt6gBLl08g9nFOfzvuv1+lyIiJympg3pPWx8A89SiJpRmvG9lDc/s6mBHi2bUE0kkSR3Uu72gVtdHxPWr5lCQlc4XH9jmdykichKSPKj7ycsMUVmY5XcpgVCal8lHL13Ao9ta+aOu/iKSMJJ6zNrutj7mVeQTmak1+d2x7rWH312/qpYPXljH/z63n8/9fiu//dhFpKXYjIIiiSipW9R72vp1IPEY2Rkhbl69iC2HerhnQ5Pf5YhIFJI2qAdHxjl4ZFAHEqfw9rNmUT+nhP/72y1s16W6RAIvaYN6T7sOJB5PWprxretXkJeVzk0/baB7YNTvkkTkNSRvUHtzfMyfoa6Pqcwsyua2v1zBoSODfOzOFxgaHfe7JBE5jqQ9mLi7rQ8zqCtTUB/POXNK+dy1Z3LzLzdx/feeY80H6qO6Gsz1q2qnoToRmZC0Lerdbf1Ul+SQnRHyu5RAe8+5Ndx6wwq2HOrh2m8/Q1PXgN8licgxkjaod2mOj6hdeWYVd//N+YyOh7n18d3cv+kQw+oKEQmMpAzq4bFxdrb0sqSq0O9SEsaymmIe/tQlrJxbyrO7O/jqIzto2NdJ2Dm/SxNJeUkZ1Dtb+hgLO5bMUlCfjMLsDK5ZNpu/vWQ+JbmZ3PviQb65dic7WnpxCmwR3yRlUG851A3AGbOKfK4kMdWU5vI3b5jH+1bWMjru+PEf9/GjZ/bpCjEiPjnhqA8z+yFwFdDqnFsa/5JO3ZZDPeRnpTMnRa+TeDwnOsV8MjPjzNlFnF5VwLo9nazd1sq3H9vF8toSLl1cQVVRThwrFZHJomlR/xhYHec6YmrLoR5OryrQPBYxkJ6WxoULyvn0mxdx0WnlvNR0hMu+/AS3PbFbV4sRmSYnDGrn3JNA5zTUEhPjYcfWwz3q9oixnMwQVy6t4lNXLOTi08r5wgPbeNs3nmL93oTZNUQSVsz6qM3sJjNrMLOGtra2WL3tSdvX0c/AyLgOJMZJSV4maz5Qz/c/UE//8Djv+e6z/NMvXqKzf8Tv0kSSVszOTHTOrQHWANTX1/s2RGDLoR4AzlBQx81EX/dHLp7H2m2t/PKFJu7fdJgrl85kxZwS/vK8OT5XKJJcku4U8i2HuskIGafNKPC7lKSXmZ7G6qUzWV5bzK83HuTeFw/SsL+L+roSFs/UL0qRWEm64XmvHOphYWUBmelJ99UCq7Iwm49cPI93raimvW+Yt33jaf7791vpHx7zuzSRpHDCNDOzO4FngUVm1mRmfx3/sl4f5xxbDvWo28MHZsY5c0r41BULue6catY8uYdL/ucxfvD0Xs3MJ3KKohn18T7nXJVzLsM5V+2c+8F0FPZ6NPcM0dk/ohEfPsrNSucL7zqL+z56AYtmFvDZ+1/h0i8/zh3rDmg4n8jrlFT9Aw37ugA4u6bY50pkeW0JP/vwedzxkVVUFWXzL/dt5vKvPMEvGhoZU2CLnJSkOpj4x90dFGSls1RdH7469gzId62o5szZRTy8tYV/umcTn39gG7dcuZh3LJ9NRiip2goicZFUQf3cng5Wzi0lXf/5A8XMWDSzkIWVBWxr7uXRbS3cfM8mvrl2Jx+/9DTesSLxAzuaK8CLvF6J/b9jkubuIfa293P+/DK/S5HjMDNOryrk7964gB/cWE9JbiY3/3ITl33lce5arz5skeNJmhb1s3vaAThvnoI66MyMy0+v5LLFM3h8extfe2QHt9y7mTVP7uGWKxfzpiWVmAV7npb2vmF2NPeyu72ftp4hnt3Tydh4mLBzpJmRmxkiJzOd0rwMyvKy6B8eIy8raf67yTRLmj3n2d0dFOVk6GIBCcTMuHTxDN64qIK121r5/APbuOmnGzhvXin/9rYlLJ0djNE7d6w7wNDoOFsP97C7rY/dbf10D7565XYjMtolI2SkmTEedgyOjjMy9upfCN99cjenVxVSP6eEc+pKqZ9TwqxizUAo0UmeoN7Twaq5pZoxL0FM1ad74/l1PL+vk0e2tvD2bz3NO5dXc/PqRVQWZk9rHRPCzrGjuZeG/V3saOllLOzIyQgxvyKPC+eXMbMoh4qCLPKz0glNsd+Njofp6h+hvW+EkrwMGvZ18fOGJm5/dj8Ac8pyuWB+ORctKOf8+WWU5mXG7XtKYkuKoG7sHKCxc5APXTjX71LkFITSjPPmlbGsppjHt7fyq40H+e1Lh7h08QwunF/2ZweJ43WAbnQ8zPP7Ovnj7g46+0coyEpn5dxSzqouprokh7Qou2UyQmnMKMxmRmH20VpHx8NsO9x79P1/+9Ih7lx/ADNYUlXIRQvKuXBBOefMKVFXiRyVFHvCs3s6AHQgMUlkZ4RYvbSKc+tK+f3mwzy0pZmGfZ1cdVYVi+I4h8h42LFhfxdrt7XQMzRGbWkub15SyRmziqZsMb8eGaE0zqwu4szqIj500VzGxsO81NTNM7vaeXpXOz98Zi/ffXIPZjC/Ip+zZkfWjVzEoVDhnaKS4l/98e2tlOdnslATMSWVsvws3n9+HTtaerl/02Fuf3Y/iyoLuOqsKsrys2L2OWHneKnxCI9ua6Wzf4Ta0lyuq6+J6VXsTzR8rzw/i5//zfkMjIyxfm8nLx44wssHu3lyZzv3vnjw6HpzynI5fWYhi6sKWDyzkCVVhZFWvrr8klrCB3X34CiPbG3l+pW12lmT1MLKAj5xeR7P7u5g7bZWvvboTi5aUM7Vy2aRfwotTOccLx/s5pGtLbT2DlNVlM0Hzp/DosoCX0adTA7zysJsKguzuWzxDHqGxjh0ZJCKgiy2Nfew9XAvD73SzMT1hvOz0jm7poiLFlTQPzxGVVH2a9avMd2JJ+GD+vebDzMyFuYdy2f7XYrEUXpaGhefVsHZNcX8YUszT+xo46IvruXDF83lxgvqKMjOiPq9xsbDPLSlhdue2M3mg92U52fx3nNrWDq7KOr+5+liZhTlZFCUk/EnATswMsaOlj62Hu5h6+Ee1u/t5IsPbgMirfNlNcXUzymhMCf67SLBZc7Ffo7/+vp619DQEPP3ncp7bnuW9v5hHv3UJSfdCjqZi71KsDR1DbC9uZdHt7WSn5XO286s4t311ayoLTluf/Ku1l4e2NzM3Q2NNHUNMqcsl/o5pSyrKY5ZH7SfeodG2Xq4l42NR9jX0U/IjGU1xVy8sJwZBa+OnFGLOpjMbINzrn6q1xK6Rd3YOcD6fZ18+s0LA3+ChMRWdUkuN69ezOambm5/dh+/3XSIuxsaycsMcVZ1MXXleeRkhHA49ncMsLO1l8bOQQBW1kXGab9pSSV3P9/o7xeJoYLsDFbOLWXl3FI6+oZ5Znc7G/Z38cKBLurrSrni9Bkn9ZeHBEdCB/WvvIMs1yxTt0eqOrO6iC9fdzafufoMHtnacjSYHn6lmcGRccIucgDurNnFfPiiebzljJnMLIrfuOygKMvP4uqzZ3PZ4koe397Kc3s6eKnxCJefPoP31FdrPpwEk7BBHQ477nvxIKvmllJTmut3OeKzvKx0rlk2W7+0j5Gflc5VZ83i/Hll/G7zYR54uZm3f+sZPveOpayoLfG7PIlSwv5avffFg+xp79eFVEWiUJafxfvPm8MNq2rp6h/hXbf+kX+9b/OfnAovwZWQQT04Ms6XH9rO2TXFXHVWld/liCQEM+OMWUU88o+X8MEL5nLn+gNc/pUn+PXGg8RjUIHETkJ2fXzvqT009wzxzeuX6yBiCotm1I5GOPy5/Kx0/uPtS3jnitn8y32b+eRdG7lnQxOfvWYpdeV5fpcnU0i4oG7pGeK2J3az+oyZnFtX6nc5EnAagnl8S2cXcd9HL+Rn6/bzpQe38+avPcnHL13ATZfMIys95Hd5MklCBXXv0Cgfvr2BsHPccuViv8sRSUjH/vJKT0vjY5cu4P7Nh/nKwzu454Um/u7SBbpUWoAkzL/C0Og4N/1kA1sP93DrDefoTzSRGCrMyeD6lbX81QV1FGZncPM9m7j0y4/zncd30do75Hd5KS8hWtQHOga45d5NPLung6/9xTIuXTzD75JEktLCygL+8+1LeHx7G7c9sZsvPbidr/5hBxcsKOdy7yIPtaW5OjY0zaIKajNbDXwdCAHfd859Ia5VeVp6hrhz/QFufXw36WnGl959FtdqTg+RuJq48s6li2ewp62Puxsa+cOWFv7zN1sAKM/P5OzqYk6rLGBeeR6zS3IozcukLC+T4txMMtPj+4f6xAiVVPplccKgNrMQ8G3gTUAT8LyZ/cY590osCwmHHS81HWF3Wz+7Wvt4fl8nG/Z3AfDWM2fy71ctoapIly4Sibdj+7DnlObxkYvn0d47zK62Ppq6BjjQOcCTO9sYHf/zYX0FWenkZoXITE8jI5RGZijtaHiHnWM8HAnbsHOEXWRZOOwYC0+6d5H78WNvzh2dNdAschk0MyPNXr0Pmb362elpzC7OITczRG5mOjmZoaOP8zJD5GZF7nMyQ+RlRurOy0yPrJOVTnZ6GqE0O3pLM++xGWaROczHvNv4eKTukjhcqSeaFvVKYJdzbk9k49hdwDVATIPaAe/73nMMjYbJCBmLZhbwqTct5MqlMzmtUvNMi/itvCCL8p1De4AAAAeZSURBVIIsoIzrV9UyNh6mqWuQ5p4hOvtH6Owfoat/hI7+EYZGx9ne3Hs0bIdGxzHsaLhOBJ6Zec8jy9K8AExLsz9Z9moQRx47ImHvHITdpOAnEp6jY2FGxsOMjodxQEf/CI1dgwyOjDMwMkb/yJ9e0zJm2yg/i4Z/uyLm73vC2fPM7N3Aaufch73n7wdWOec+dsx6NwE3eU8XAdtjXu2pKQfa/S4igLRdjk/bZmraLlM71e0yxzlXMdULMTuY6JxbA6yJ1fvFmpk1HG8KwVSm7XJ82jZT03aZWjy3SzS9/geBmknPq71lIiIyDaIJ6ueB08xsrpllAu8FfhPfskREZMIJuz6cc2Nm9jHgISLD837onNsS98piL7DdMj7Tdjk+bZupabtMLW7bJS6X4hIRkdhJmFPIRURSlYJaRCTgUiKozWy1mW03s11mdovf9cSDmdWY2WNm9oqZbTGzT3rLS83sYTPb6d2XeMvNzL7hbZNNZrZi0nvd6K2/08xunLT8HDPb7P3MNyxBzuE1s5CZvWhm93vP55rZOu973O0dJMfMsrznu7zX6ya9xz97y7eb2VsmLU/YfcvMis3sHjPbZmZbzex87S9gZv/g/R962czuNLNs3/eZyNk9yXsjcgB0NzAPyAReApb4XVccvmcVsMJ7XADsAJYAXwJu8ZbfAnzRe/xW4AEiJ4qdB6zzlpcCe7z7Eu9xiffaem9d8372Sr+/d5Tb5lPAHcD93vOfA+/1Ht8G/B/v8UeB27zH7wXu9h4v8fabLGCutz+FEn3fAm4HPuw9zgSKU31/AWYDe4GcSfvKX/m9z6RCi/roKfDOuRFg4hT4pOKcO+yce8F73AtsJbLTXUPkPyTe/bXe42uAn7iI54BiM6sC3gI87JzrdM51AQ8Dq73XCp1zz7nInviTSe8VWGZWDbwN+L733IDLgHu8VY7dJhPb6h7gcm/9a4C7nHPDzrm9wC4i+1XC7ltmVgS8AfgBgHNuxDl3hBTfXzzpQI6ZpQO5wGF83mdSIahnA42Tnjd5y5KW9+fXcmAdUOmcO+y91AxUeo+Pt11ea3nTFMuD7mvAzcDExA5lwBHn3Jj3fPL3OPrdvde7vfVPdlslgrlAG/Ajr1vo+2aWR4rvL865g8CXgQNEArob2IDP+0wqBHVKMbN84JfA3zvneia/5rVsUmY8ppldBbQ65zb4XUsApQMrgFudc8uBfiJdHUel2v4C4PXJX0PkF9ksIA9Y7WtRpEZQp8wp8GaWQSSkf+acu9db3OL9GYp33+otP952ea3l1VMsD7ILgavNbB+RPzEvIzKverH3Zy386fc4+t2914uADk5+WyWCJqDJObfOe34PkeBO5f0F4Apgr3OuzTk3CtxLZD/ydZ9JhaBOiVPgvX6xHwBbnXNfnfTSb4CJI/E3Ar+etPwD3tH884Bu70/eh4A3m1mJ17p4M/CQ91qPmZ3nfdYHJr1XIDnn/tk5V+2cqyPy777WOXcD8Bjwbm+1Y7fJxLZ6t7e+85a/1zvCPxc4jciBsoTdt5xzzUCjmS3yFl1OZOrilN1fPAeA88ws16t7Yrv4u8/4fZR1Om5EjljvIHK09V/9ridO3/EiIn+mbgI2ere3EukvexTYCTwClHrrG5ELQuwGNgP1k97rQ0QOfuwCPjhpeT3wsvcz38I7szURbsAbeXXUxzzvP80u4BdAlrc823u+y3t93qSf/1fve29n0uiFRN63gGVAg7fP/IrIqI2U31+AzwDbvNp/SmTkhq/7jE4hFxEJuFTo+hARSWgKahGRgFNQi4gEnIJaRCTgFNQiIgGnoJaEZGY/NrN3n3hNkcSnoJaU4520oX1fEoZ2VkkIZvYBbx7kl8zsp97iN5jZH81sz0Tr2szyzexRM3vBmwv5Gm95nTcH8E+InMhQY2b/7i172pt3+NPeuvPN7EEz22BmT5nZYm/5dd4cxS+Z2ZM+bAZJUTrhRQLPzM4A7gMucM61m1kp8FUiE+b8BbAY+I1zbsHE1JTOuR4zKweeI3L67hwicyVf4Jx7zszOBb5HZL7kDOAF4LvOuS+b2aPA3zrndprZKuDzzrnLzGwzsNo5d9DMil1kWlCRuDvhVchFAuAy4BfOuXYA51xnZBoGfuWcCwOvmNnEdJwG/LeZvYHI1KazeXWqzv0uMpcyRCba+bVzbggYMrPfwtHZBy8AfmGvXpAky7t/Bvixmf2cyGQ9ItNCQS2JbHjS44lUvQGoAM5xzo16M+dle6/1R/GeaUTmHl527AvOub/1WthvAzaY2TnOuY7XXb1IlNRHLYlgLXCdmZVB5DqQr7FuEZE5qEfN7FIiXR5TeQZ4u0Wuh5cPXAXgInN47zWz67zPMjM723s83zm3zjn3H0Qm3a85znuLxJRa1BJ4zrktZvY54AkzGwdefI3Vfwb81utPbiAyC9pU7/m8mf2GyMxxLURmhOv2Xr4BuNXM/o1I//VdRK5t9z9mdhqR1vuj3jKRuNPBRElZZpbvnOszs1zgSeAm5113UiRI1KKWVLbGzJYQ6cO+XSEtQaUWtYhIwOlgoohIwCmoRUQCTkEtIhJwCmoRkYBTUIuIBNz/B/XhwJ+AAnRIAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvGOotBORaok",
        "colab_type": "text"
      },
      "source": [
        "## Step 2: Prepare the dataset for training\n",
        "\n",
        "We need to convert the data from the Pandas dataframe into a PyTorch tensors for training. To do this, the first step is to convert it numpy arrays. If you've filled out `input_cols`, `categorial_cols` and `output_cols` correctly, this following function will perform the conversion to numpy arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9rWn0q7Raol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dataframe_to_arrays(dataframe):\n",
        "    # Make a copy of the original dataframe\n",
        "    dataframe1 = dataframe.copy(deep=True)\n",
        "    # Convert non-numeric categorical columns to numbers\n",
        "    for col in categorical_cols:\n",
        "        dataframe1[col] = dataframe1[col].astype('category').cat.codes\n",
        "    # Extract input & outupts as numpy arrays\n",
        "    inputs_array = dataframe1[input_cols].to_numpy()\n",
        "    targets_array = dataframe1[output_cols].to_numpy()\n",
        "    return inputs_array, targets_array"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cchL1rHRaoo",
        "colab_type": "text"
      },
      "source": [
        "Read through the [Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html) to understand how we're converting categorical variables into numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zC-fYYUyRaoo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "5ecd4df4-77a5-445e-d7a3-742790cc8173"
      },
      "source": [
        "inputs_array, targets_array = dataframe_to_arrays(dataframe)\n",
        "inputs_array, targets_array"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[27.     ,  0.     , 20.8259 ,  0.     ,  0.     ,  1.     ],\n",
              "        [54.     ,  0.     , 29.876  ,  3.     ,  0.     ,  3.     ],\n",
              "        [47.     ,  0.     , 26.81565,  2.     ,  1.     ,  1.     ],\n",
              "        ...,\n",
              "        [19.     ,  1.     , 16.9556 ,  0.     ,  0.     ,  1.     ],\n",
              "        [37.     ,  1.     , 28.9351 ,  2.     ,  0.     ,  0.     ],\n",
              "        [52.     ,  0.     , 24.541  ,  2.     ,  1.     ,  2.     ]]),\n",
              " array([[ 3822.956142],\n",
              "        [13800.0648  ],\n",
              "        [27970.696347],\n",
              "        ...,\n",
              "        [ 1848.327828],\n",
              "        [ 7303.308198],\n",
              "        [28120.85766 ]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgbxBrqHRaor",
        "colab_type": "text"
      },
      "source": [
        "**Q: Convert the numpy arrays `inputs_array` and `targets_array` into PyTorch tensors. Make sure that the data type is `torch.float32`.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVSr6EyhRaor",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = torch.from_numpy(inputs_array).to(dtype=torch.float32) \n",
        "targets = torch.from_numpy(targets_array).to(dtype=torch.float32) "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp3TzoF9Raou",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4842c7bb-c256-4ed3-e56c-f09c8f3d529b"
      },
      "source": [
        "inputs.dtype, targets.dtype"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.float32, torch.float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zXrs306Raox",
        "colab_type": "text"
      },
      "source": [
        "Next, we need to create PyTorch datasets & data loaders for training & validation. We'll start by creating a `TensorDataset`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P82M2mRdRaox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = TensorDataset(inputs, targets)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uFbb7EdRao0",
        "colab_type": "text"
      },
      "source": [
        "**Q: Pick a number between `0.1` and `0.2` to determine the fraction of data that will be used for creating the validation set. Then use `random_split` to create training & validation datasets. **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZQhJX0XRao0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_percent =  random.uniform(0.1,0.2)# between 0.1 and 0.2\n",
        "val_size = int(num_rows * val_percent)\n",
        "train_size = num_rows - val_size\n",
        "\n",
        "\n",
        "train_ds, val_ds =  random_split(dataset, [train_size, val_size])# Use the random_split function to split dataset into 2 parts of the desired length"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0fMKS-MRao4",
        "colab_type": "text"
      },
      "source": [
        "Finally, we can create data loaders for training & validation.\n",
        "\n",
        "**Q: Pick a batch size for the data loader.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9b2KlMRRao5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mq385_-tRao9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwyBiqp3RapA",
        "colab_type": "text"
      },
      "source": [
        "Let's look at a batch of data to verify everything is working fine so far."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLoVvh5URapA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5b0a6575-58c0-4f0b-8f43-80734dad870f"
      },
      "source": [
        "for xb, yb in train_loader:\n",
        "    print(\"inputs:\", xb)\n",
        "    print(\"targets:\", yb)\n",
        "    break"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inputs: tensor([[60.0000,  0.0000, 27.8390,  1.0000,  0.0000,  3.0000],\n",
            "        [50.0000,  1.0000, 26.6313,  1.0000,  0.0000,  0.0000],\n",
            "        [41.0000,  0.0000, 31.2340,  1.0000,  0.0000,  3.0000],\n",
            "        [41.0000,  0.0000, 27.4607,  1.0000,  0.0000,  1.0000],\n",
            "        [63.0000,  0.0000, 25.4334,  0.0000,  0.0000,  1.0000],\n",
            "        [23.0000,  0.0000, 31.7966,  2.0000,  1.0000,  2.0000],\n",
            "        [28.0000,  0.0000, 25.1569,  1.0000,  0.0000,  1.0000],\n",
            "        [48.0000,  0.0000, 28.0136,  1.0000,  0.0000,  1.0000],\n",
            "        [19.0000,  1.0000, 32.1070,  0.0000,  0.0000,  3.0000],\n",
            "        [51.0000,  0.0000, 17.5085,  0.0000,  0.0000,  1.0000],\n",
            "        [47.0000,  0.0000, 22.8920,  1.0000,  0.0000,  3.0000],\n",
            "        [47.0000,  1.0000, 37.7718,  2.0000,  1.0000,  2.0000],\n",
            "        [33.0000,  0.0000, 41.6518,  3.0000,  0.0000,  1.0000],\n",
            "        [39.0000,  0.0000, 31.5250,  1.0000,  0.0000,  3.0000],\n",
            "        [24.0000,  0.0000, 26.7720,  0.0000,  0.0000,  3.0000],\n",
            "        [37.0000,  1.0000, 35.9579,  1.0000,  1.0000,  2.0000],\n",
            "        [41.0000,  1.0000, 21.1266,  1.0000,  0.0000,  2.0000],\n",
            "        [30.0000,  0.0000, 37.8785,  3.0000,  1.0000,  2.0000],\n",
            "        [25.0000,  1.0000, 32.3301,  2.0000,  1.0000,  2.0000],\n",
            "        [63.0000,  1.0000, 40.2259,  0.0000,  0.0000,  2.0000],\n",
            "        [25.0000,  0.0000, 33.4505,  0.0000,  0.0000,  1.0000],\n",
            "        [55.0000,  1.0000, 36.1810,  0.0000,  0.0000,  3.0000],\n",
            "        [57.0000,  1.0000, 39.0716,  0.0000,  0.0000,  0.0000],\n",
            "        [45.0000,  1.0000, 35.3856,  2.0000,  1.0000,  1.0000],\n",
            "        [57.0000,  0.0000, 29.5802,  0.0000,  0.0000,  1.0000],\n",
            "        [57.0000,  1.0000, 30.5938,  0.0000,  0.0000,  1.0000],\n",
            "        [30.0000,  1.0000, 37.6651,  1.0000,  0.0000,  2.0000],\n",
            "        [42.0000,  0.0000, 24.2355,  2.0000,  0.0000,  1.0000],\n",
            "        [52.0000,  0.0000, 29.8566,  1.0000,  0.0000,  0.0000],\n",
            "        [53.0000,  0.0000, 34.8230,  2.0000,  0.0000,  3.0000],\n",
            "        [22.0000,  0.0000, 27.2085,  0.0000,  0.0000,  2.0000],\n",
            "        [52.0000,  0.0000, 30.7781,  2.0000,  0.0000,  1.0000],\n",
            "        [50.0000,  1.0000, 30.0409,  3.0000,  0.0000,  1.0000],\n",
            "        [18.0000,  0.0000, 39.0716,  0.0000,  0.0000,  0.0000],\n",
            "        [57.0000,  1.0000, 22.9890,  0.0000,  0.0000,  3.0000],\n",
            "        [55.0000,  0.0000, 28.8090,  2.0000,  0.0000,  3.0000],\n",
            "        [27.0000,  1.0000, 31.6075,  3.0000,  0.0000,  0.0000],\n",
            "        [39.0000,  0.0000, 31.8160,  0.0000,  0.0000,  3.0000],\n",
            "        [42.0000,  0.0000, 28.1300,  1.0000,  0.0000,  3.0000],\n",
            "        [49.0000,  1.0000, 36.3847,  2.0000,  0.0000,  2.0000],\n",
            "        [34.0000,  1.0000, 26.1900,  2.0000,  0.0000,  3.0000],\n",
            "        [39.0000,  0.0000, 25.5256,  2.0000,  0.0000,  1.0000],\n",
            "        [32.0000,  1.0000, 36.2150,  1.0000,  0.0000,  0.0000],\n",
            "        [40.0000,  0.0000, 21.5534,  2.0000,  1.0000,  2.0000],\n",
            "        [59.0000,  0.0000, 25.7099,  0.0000,  0.0000,  0.0000],\n",
            "        [31.0000,  1.0000, 38.3053,  1.0000,  0.0000,  2.0000],\n",
            "        [45.0000,  0.0000, 29.9730,  2.0000,  0.0000,  3.0000],\n",
            "        [62.0000,  1.0000, 37.6651,  0.0000,  0.0000,  2.0000],\n",
            "        [33.0000,  0.0000, 34.4641,  0.0000,  1.0000,  1.0000],\n",
            "        [23.0000,  1.0000, 31.5832,  0.0000,  0.0000,  2.0000],\n",
            "        [52.0000,  1.0000, 40.5460,  2.0000,  1.0000,  2.0000],\n",
            "        [63.0000,  0.0000, 34.1440,  1.0000,  0.0000,  2.0000],\n",
            "        [62.0000,  1.0000, 25.8941,  0.0000,  1.0000,  0.0000],\n",
            "        [49.0000,  0.0000, 40.2259,  4.0000,  0.0000,  2.0000],\n",
            "        [51.0000,  0.0000, 33.9112,  2.0000,  1.0000,  0.0000],\n",
            "        [60.0000,  0.0000, 26.7235,  0.0000,  0.0000,  0.0000],\n",
            "        [30.0000,  1.0000, 30.6229,  3.0000,  0.0000,  2.0000],\n",
            "        [28.0000,  0.0000, 16.7713,  0.0000,  0.0000,  0.0000],\n",
            "        [28.0000,  0.0000, 23.5904,  1.0000,  0.0000,  0.0000],\n",
            "        [40.0000,  0.0000, 26.5780,  1.0000,  0.0000,  3.0000],\n",
            "        [23.0000,  1.0000, 30.7781,  3.0000,  1.0000,  0.0000],\n",
            "        [19.0000,  1.0000, 20.2730,  1.0000,  0.0000,  3.0000],\n",
            "        [53.0000,  1.0000, 33.0818,  0.0000,  1.0000,  0.0000],\n",
            "        [18.0000,  1.0000, 34.1440,  1.0000,  0.0000,  2.0000],\n",
            "        [18.0000,  1.0000, 22.5137,  0.0000,  0.0000,  2.0000],\n",
            "        [52.0000,  0.0000, 24.5410,  2.0000,  1.0000,  2.0000],\n",
            "        [25.0000,  1.0000, 23.4061,  0.0000,  1.0000,  1.0000],\n",
            "        [47.0000,  0.0000, 31.0400,  1.0000,  0.0000,  3.0000],\n",
            "        [32.0000,  0.0000, 28.9060,  2.0000,  0.0000,  3.0000],\n",
            "        [18.0000,  0.0000, 32.8636,  0.0000,  0.0000,  2.0000],\n",
            "        [56.0000,  0.0000, 26.3840,  0.0000,  0.0000,  3.0000],\n",
            "        [20.0000,  1.0000, 34.2507,  1.0000,  0.0000,  2.0000],\n",
            "        [34.0000,  0.0000, 25.6177,  1.0000,  0.0000,  1.0000],\n",
            "        [43.0000,  1.0000, 19.5261,  2.0000,  1.0000,  2.0000],\n",
            "        [35.0000,  0.0000, 34.7842,  2.0000,  0.0000,  2.0000],\n",
            "        [19.0000,  0.0000, 27.0921,  3.0000,  0.0000,  1.0000],\n",
            "        [60.0000,  0.0000, 29.5850,  0.0000,  0.0000,  3.0000],\n",
            "        [61.0000,  1.0000, 34.7842,  0.0000,  1.0000,  2.0000],\n",
            "        [29.0000,  0.0000, 25.1230,  0.0000,  0.0000,  3.0000],\n",
            "        [58.0000,  0.0000, 37.8785,  0.0000,  0.0000,  2.0000],\n",
            "        [39.0000,  1.0000, 21.1945,  1.0000,  0.0000,  1.0000],\n",
            "        [34.0000,  0.0000, 32.2525,  1.0000,  0.0000,  0.0000],\n",
            "        [52.0000,  1.0000, 25.6080,  3.0000,  0.0000,  2.0000],\n",
            "        [59.0000,  0.0000, 35.4244,  1.0000,  0.0000,  2.0000],\n",
            "        [19.0000,  1.0000, 33.0770,  0.0000,  0.0000,  3.0000],\n",
            "        [30.0000,  1.0000, 26.8157,  1.0000,  0.0000,  0.0000],\n",
            "        [32.0000,  1.0000, 28.0136,  0.0000,  0.0000,  1.0000],\n",
            "        [60.0000,  1.0000, 39.6924,  0.0000,  1.0000,  2.0000],\n",
            "        [20.0000,  1.0000, 27.1842,  1.0000,  1.0000,  1.0000],\n",
            "        [27.0000,  0.0000, 29.4880,  3.0000,  0.0000,  1.0000],\n",
            "        [19.0000,  0.0000, 30.8703,  1.0000,  0.0000,  1.0000],\n",
            "        [48.0000,  1.0000, 34.5563,  4.0000,  0.0000,  0.0000],\n",
            "        [19.0000,  0.0000, 17.2660,  0.0000,  0.0000,  3.0000],\n",
            "        [41.0000,  1.0000, 34.6775,  1.0000,  1.0000,  2.0000],\n",
            "        [40.0000,  1.0000, 19.2060,  1.0000,  1.0000,  2.0000],\n",
            "        [21.0000,  0.0000, 34.6484,  0.0000,  0.0000,  1.0000],\n",
            "        [18.0000,  1.0000, 20.9181,  0.0000,  1.0000,  0.0000],\n",
            "        [18.0000,  1.0000, 29.4880,  3.0000,  0.0000,  0.0000],\n",
            "        [28.0000,  1.0000, 32.8054,  0.0000,  0.0000,  1.0000],\n",
            "        [21.0000,  0.0000, 21.1945,  1.0000,  1.0000,  0.0000],\n",
            "        [29.0000,  0.0000, 23.8620,  2.0000,  0.0000,  3.0000],\n",
            "        [22.0000,  1.0000, 24.4198,  0.0000,  0.0000,  1.0000],\n",
            "        [31.0000,  1.0000, 25.1230,  3.0000,  1.0000,  3.0000],\n",
            "        [44.0000,  0.0000, 23.2606,  2.0000,  0.0000,  2.0000],\n",
            "        [35.0000,  1.0000, 35.5699,  1.0000,  1.0000,  0.0000],\n",
            "        [51.0000,  1.0000, 30.6859,  0.0000,  0.0000,  1.0000],\n",
            "        [23.0000,  1.0000, 18.1535,  0.0000,  0.0000,  1.0000],\n",
            "        [34.0000,  1.0000, 24.5119,  1.0000,  0.0000,  1.0000],\n",
            "        [58.0000,  1.0000, 33.8190,  0.0000,  0.0000,  0.0000],\n",
            "        [31.0000,  0.0000, 21.1024,  0.0000,  0.0000,  1.0000],\n",
            "        [56.0000,  1.0000, 32.7132,  0.0000,  0.0000,  1.0000],\n",
            "        [58.0000,  0.0000, 32.4368,  0.0000,  0.0000,  1.0000],\n",
            "        [42.0000,  0.0000, 24.5410,  1.0000,  0.0000,  3.0000],\n",
            "        [29.0000,  0.0000, 37.6651,  3.0000,  0.0000,  2.0000],\n",
            "        [46.0000,  1.0000, 26.7720,  0.0000,  0.0000,  3.0000],\n",
            "        [36.0000,  1.0000, 28.8090,  0.0000,  0.0000,  2.0000],\n",
            "        [57.0000,  0.0000, 30.2252,  0.0000,  1.0000,  1.0000],\n",
            "        [25.0000,  1.0000, 26.7235,  0.0000,  0.0000,  1.0000],\n",
            "        [33.0000,  1.0000, 29.3425,  0.0000,  0.0000,  2.0000],\n",
            "        [61.0000,  0.0000, 20.4573,  0.0000,  0.0000,  1.0000],\n",
            "        [49.0000,  1.0000, 30.4095,  1.0000,  0.0000,  0.0000],\n",
            "        [28.0000,  1.0000, 36.9182,  0.0000,  0.0000,  2.0000],\n",
            "        [41.0000,  0.0000, 31.9760,  0.0000,  0.0000,  1.0000],\n",
            "        [63.0000,  1.0000, 29.8760,  0.0000,  0.0000,  3.0000],\n",
            "        [62.0000,  1.0000, 36.2780,  0.0000,  0.0000,  3.0000],\n",
            "        [44.0000,  0.0000, 36.9182,  0.0000,  1.0000,  2.0000],\n",
            "        [19.0000,  1.0000, 23.8620,  1.0000,  0.0000,  3.0000],\n",
            "        [61.0000,  0.0000, 37.9270,  2.0000,  0.0000,  3.0000]])\n",
            "targets: tensor([[15076.1504],\n",
            "        [10964.1348],\n",
            "        [ 7724.5957],\n",
            "        [ 8155.0513],\n",
            "        [16252.0596],\n",
            "        [41063.9531],\n",
            "        [ 4712.3516],\n",
            "        [10544.4248],\n",
            "        [26314.5684],\n",
            "        [10994.4482],\n",
            "        [ 9735.2246],\n",
            "        [50391.0234],\n",
            "        [ 7251.5327],\n",
            "        [ 7111.6597],\n",
            "        [21608.9512],\n",
            "        [45453.7422],\n",
            "        [ 7150.6240],\n",
            "        [46662.9688],\n",
            "        [41182.0156],\n",
            "        [15282.1445],\n",
            "        [ 3444.8625],\n",
            "        [23518.5234],\n",
            "        [23608.2832],\n",
            "        [48746.9727],\n",
            "        [13498.4834],\n",
            "        [12942.6797],\n",
            "        [21618.0156],\n",
            "        [ 9139.4502],\n",
            "        [12308.9629],\n",
            "        [12726.4678],\n",
            "        [ 2457.4768],\n",
            "        [12753.9287],\n",
            "        [12084.6250],\n",
            "        [ 2528.0654],\n",
            "        [12493.6357],\n",
            "        [13544.7480],\n",
            "        [ 5525.4888],\n",
            "        [ 6440.6753],\n",
            "        [ 8037.7319],\n",
            "        [10607.3604],\n",
            "        [13381.1475],\n",
            "        [ 8209.9395],\n",
            "        [ 5321.0728],\n",
            "        [22166.4629],\n",
            "        [14609.6074],\n",
            "        [ 4418.3369],\n",
            "        [ 9712.8301],\n",
            "        [14798.7344],\n",
            "        [62854.3594],\n",
            "        [ 2079.6853],\n",
            "        [53887.6328],\n",
            "        [16501.1289],\n",
            "        [32035.5195],\n",
            "        [12514.0156],\n",
            "        [50890.9648],\n",
            "        [15067.4873],\n",
            "        [ 5514.8438],\n",
            "        [ 4255.1924],\n",
            "        [26549.3789],\n",
            "        [ 7406.4502],\n",
            "        [41255.5742],\n",
            "        [ 2088.5872],\n",
            "        [49310.0352],\n",
            "        [ 1969.3956],\n",
            "        [ 1278.9363],\n",
            "        [28120.8574],\n",
            "        [18032.5039],\n",
            "        [ 9748.5352],\n",
            "        [ 5873.4326],\n",
            "        [13090.2041],\n",
            "        [12623.4209],\n",
            "        [31605.6895],\n",
            "        [ 6139.2852],\n",
            "        [21395.2207],\n",
            "        [ 6653.6333],\n",
            "        [21476.1230],\n",
            "        [14407.5420],\n",
            "        [53122.9844],\n",
            "        [ 3822.7437],\n",
            "        [13516.3096],\n",
            "        [ 6973.9438],\n",
            "        [ 6378.1240],\n",
            "        [29631.8164],\n",
            "        [32248.2031],\n",
            "        [ 1438.0438],\n",
            "        [ 4830.3242],\n",
            "        [ 4408.2148],\n",
            "        [55487.8555],\n",
            "        [20018.8320],\n",
            "        [21437.4180],\n",
            "        [ 3099.9790],\n",
            "        [12240.0322],\n",
            "        [ 1969.6749],\n",
            "        [45911.9570],\n",
            "        [19584.6543],\n",
            "        [ 2741.3965],\n",
            "        [15672.5742],\n",
            "        [ 3969.3296],\n",
            "        [22427.6035],\n",
            "        [17509.3789],\n",
            "        [ 5163.6040],\n",
            "        [ 2332.0813],\n",
            "        [21887.9355],\n",
            "        [ 9360.6543],\n",
            "        [45342.6758],\n",
            "        [10458.5146],\n",
            "        [24618.7363],\n",
            "        [ 5580.0186],\n",
            "        [13616.8379],\n",
            "        [ 4712.8540],\n",
            "        [12512.9199],\n",
            "        [13944.0391],\n",
            "        [ 8031.8687],\n",
            "        [ 5857.6128],\n",
            "        [28047.4746],\n",
            "        [ 5015.6934],\n",
            "        [49679.9922],\n",
            "        [ 2876.4133],\n",
            "        [ 4222.9644],\n",
            "        [15293.1436],\n",
            "        [10590.7588],\n",
            "        [ 3066.0247],\n",
            "        [ 7490.9678],\n",
            "        [15265.2373],\n",
            "        [14796.4678],\n",
            "        [55729.0547],\n",
            "        [ 2094.4502],\n",
            "        [16227.9824]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtTiGDhORapG",
        "colab_type": "text"
      },
      "source": [
        "## Step 3: Create a Linear Regression Model\n",
        "\n",
        "Our model itself is a fairly straightforward linear regression (we'll build more complex models in the next assignment). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IN18CKLzRapG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_size = len(input_cols)\n",
        "output_size = len(output_cols)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cry-3P9PRapJ",
        "colab_type": "text"
      },
      "source": [
        "**Q: Complete the class definition below by filling out the constructor (`__init__`), `forward`, `training_step` and `validation_step` methods.**\n",
        "\n",
        "Hint: Think carefully about picking a good loss fuction (it's not cross entropy). Maybe try 2-3 of them and see which one works best. See https://pytorch.org/docs/stable/nn.functional.html#loss-functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_csw4cHJRapK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InsuranceModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(input_size, output_size)                   # fill this (hint: use input_size & output_size defined above)\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        out = self.linear(xb)                          # fill this\n",
        "        return out\n",
        "    \n",
        "    def training_step(self, batch):\n",
        "        inputs, targets = batch \n",
        "        # Generate predictions\n",
        "        out = self(inputs) \n",
        "        # Calculate loss\n",
        "        loss = F.l1_loss(out, targets)                          # fill this\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        inputs, targets = batch\n",
        "        # Generate predictions\n",
        "        out = self(inputs)\n",
        "        # Calculate loss\n",
        "        loss = F.l1_loss(out, targets)                          # fill this    \n",
        "        return {'val_loss': loss.detach()}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        return {'val_loss': epoch_loss.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result, num_epochs):\n",
        "        # Print result every 20th epoch\n",
        "        if (epoch+1) % 20 == 0 or epoch == num_epochs-1:\n",
        "            print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch+1, result['val_loss']))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9TIcDEaRapN",
        "colab_type": "text"
      },
      "source": [
        "Let us create a model using the `InsuranceModel` class. You may need to come back later and re-run the next cell to reinitialize the model, in case the loss becomes `nan` or `infinity`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMbnE1rxRapN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = InsuranceModel()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cr3KrcvARapS",
        "colab_type": "text"
      },
      "source": [
        "Let's check out the weights and biases of the model using `model.parameters`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4nOuhrCRapT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "7b5288c4-1053-4f3a-bd97-f9db22024feb"
      },
      "source": [
        "list(model.parameters())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[ 0.0012,  0.3207,  0.3673, -0.3387, -0.3791, -0.2757]],\n",
              "        requires_grad=True), Parameter containing:\n",
              " tensor([-0.1273], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcUD-m90RapY",
        "colab_type": "text"
      },
      "source": [
        "## Step 4: Train the model to fit the data\n",
        "\n",
        "To train our model, we'll use the same `fit` function explained in the lecture. That's the benefit of defining a generic training loop - you can use it for any problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbhI5FdwRapY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, val_loader):\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        model.epoch_end(epoch, result, epochs)\n",
        "        history.append(result)\n",
        "    return history"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IY-P8IORapb",
        "colab_type": "text"
      },
      "source": [
        "**Q: Use the `evaluate` function to calculate the loss on the validation set before training.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhL7RzYRRapb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e38ea16-cf23-4a48-8602-36ea64c35bcd"
      },
      "source": [
        "result = evaluate(model, val_loader) # Use the the evaluate function\n",
        "print(result)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'val_loss': 13964.33984375}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQcpabJSRapd",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "We are now ready to train the model. You may need to run the training loop many times, for different number of epochs and with different learning rates, to get a good result. Also, if your loss becomes too large (or `nan`), you may have to re-initialize the model by running the cell `model = InsuranceModel()`. Experiment with this for a while, and try to get to as low a loss as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbSMcEzyRape",
        "colab_type": "text"
      },
      "source": [
        "**Q: Train the model 4-5 times with different learning rates & for different number of epochs.**\n",
        "\n",
        "Hint: Vary learning rates by orders of 10 (e.g. `1e-2`, `1e-3`, `1e-4`, `1e-5`, `1e-6`) to figure out what works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5TWG4WXRape",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        },
        "outputId": "12de9b99-9600-4380-879b-7f271215ea61"
      },
      "source": [
        "model1 = InsuranceModel()\n",
        "epochs = 1000\n",
        "lr = 0.1\n",
        "history1 = fit(epochs, lr, model1, train_loader, val_loader)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 6994.0430\n",
            "Epoch [40], val_loss: 6775.3330\n",
            "Epoch [60], val_loss: 6604.8848\n",
            "Epoch [80], val_loss: 6509.5381\n",
            "Epoch [100], val_loss: 6460.9756\n",
            "Epoch [120], val_loss: 6446.8105\n",
            "Epoch [140], val_loss: 6442.8569\n",
            "Epoch [160], val_loss: 6441.0059\n",
            "Epoch [180], val_loss: 6436.3755\n",
            "Epoch [200], val_loss: 6432.0181\n",
            "Epoch [220], val_loss: 6430.7803\n",
            "Epoch [240], val_loss: 6428.2705\n",
            "Epoch [260], val_loss: 6425.2910\n",
            "Epoch [280], val_loss: 6421.3799\n",
            "Epoch [300], val_loss: 6418.7744\n",
            "Epoch [320], val_loss: 6417.4180\n",
            "Epoch [340], val_loss: 6415.4590\n",
            "Epoch [360], val_loss: 6412.7349\n",
            "Epoch [380], val_loss: 6409.7930\n",
            "Epoch [400], val_loss: 6408.0430\n",
            "Epoch [420], val_loss: 6403.7759\n",
            "Epoch [440], val_loss: 6401.3369\n",
            "Epoch [460], val_loss: 6398.9253\n",
            "Epoch [480], val_loss: 6395.9258\n",
            "Epoch [500], val_loss: 6391.2354\n",
            "Epoch [520], val_loss: 6389.5601\n",
            "Epoch [540], val_loss: 6386.3662\n",
            "Epoch [560], val_loss: 6384.4736\n",
            "Epoch [580], val_loss: 6385.8301\n",
            "Epoch [600], val_loss: 6380.5010\n",
            "Epoch [620], val_loss: 6379.7754\n",
            "Epoch [640], val_loss: 6378.1934\n",
            "Epoch [660], val_loss: 6371.2461\n",
            "Epoch [680], val_loss: 6370.8975\n",
            "Epoch [700], val_loss: 6368.2920\n",
            "Epoch [720], val_loss: 6364.2866\n",
            "Epoch [740], val_loss: 6361.7212\n",
            "Epoch [760], val_loss: 6364.8789\n",
            "Epoch [780], val_loss: 6356.9707\n",
            "Epoch [800], val_loss: 6356.1299\n",
            "Epoch [820], val_loss: 6353.8838\n",
            "Epoch [840], val_loss: 6352.7773\n",
            "Epoch [860], val_loss: 6347.7837\n",
            "Epoch [880], val_loss: 6352.3242\n",
            "Epoch [900], val_loss: 6343.3164\n",
            "Epoch [920], val_loss: 6342.8613\n",
            "Epoch [940], val_loss: 6342.8525\n",
            "Epoch [960], val_loss: 6343.2305\n",
            "Epoch [980], val_loss: 6336.8008\n",
            "Epoch [1000], val_loss: 6338.8633\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ILU9Gi0Raph",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1c124b9d-ffc8-4e9d-c57d-3aba869f80b4"
      },
      "source": [
        "model2 = InsuranceModel()\n",
        "epochs = 2000\n",
        "lr = 0.01\n",
        "history2 = fit(epochs, lr, model2, train_loader, val_loader)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 9969.6465\n",
            "Epoch [40], val_loss: 7990.5742\n",
            "Epoch [60], val_loss: 7332.8438\n",
            "Epoch [80], val_loss: 7175.8545\n",
            "Epoch [100], val_loss: 7126.5640\n",
            "Epoch [120], val_loss: 7097.2812\n",
            "Epoch [140], val_loss: 7070.7852\n",
            "Epoch [160], val_loss: 7044.7393\n",
            "Epoch [180], val_loss: 7019.5244\n",
            "Epoch [200], val_loss: 6995.2441\n",
            "Epoch [220], val_loss: 6971.3276\n",
            "Epoch [240], val_loss: 6946.8828\n",
            "Epoch [260], val_loss: 6924.0918\n",
            "Epoch [280], val_loss: 6901.0752\n",
            "Epoch [300], val_loss: 6878.8730\n",
            "Epoch [320], val_loss: 6856.8516\n",
            "Epoch [340], val_loss: 6835.5903\n",
            "Epoch [360], val_loss: 6815.0859\n",
            "Epoch [380], val_loss: 6794.5142\n",
            "Epoch [400], val_loss: 6774.0620\n",
            "Epoch [420], val_loss: 6753.8018\n",
            "Epoch [440], val_loss: 6733.6719\n",
            "Epoch [460], val_loss: 6713.7441\n",
            "Epoch [480], val_loss: 6694.2759\n",
            "Epoch [500], val_loss: 6676.5615\n",
            "Epoch [520], val_loss: 6659.9365\n",
            "Epoch [540], val_loss: 6645.2046\n",
            "Epoch [560], val_loss: 6631.1851\n",
            "Epoch [580], val_loss: 6617.8154\n",
            "Epoch [600], val_loss: 6605.0215\n",
            "Epoch [620], val_loss: 6592.7251\n",
            "Epoch [640], val_loss: 6581.7236\n",
            "Epoch [660], val_loss: 6571.2388\n",
            "Epoch [680], val_loss: 6560.9141\n",
            "Epoch [700], val_loss: 6551.3374\n",
            "Epoch [720], val_loss: 6542.0986\n",
            "Epoch [740], val_loss: 6533.7319\n",
            "Epoch [760], val_loss: 6525.4287\n",
            "Epoch [780], val_loss: 6517.5107\n",
            "Epoch [800], val_loss: 6510.0220\n",
            "Epoch [820], val_loss: 6503.3906\n",
            "Epoch [840], val_loss: 6496.8438\n",
            "Epoch [860], val_loss: 6490.6943\n",
            "Epoch [880], val_loss: 6485.0498\n",
            "Epoch [900], val_loss: 6479.5552\n",
            "Epoch [920], val_loss: 6475.6992\n",
            "Epoch [940], val_loss: 6471.8228\n",
            "Epoch [960], val_loss: 6468.8936\n",
            "Epoch [980], val_loss: 6466.0029\n",
            "Epoch [1000], val_loss: 6462.9780\n",
            "Epoch [1020], val_loss: 6460.5142\n",
            "Epoch [1040], val_loss: 6457.7949\n",
            "Epoch [1060], val_loss: 6455.3184\n",
            "Epoch [1080], val_loss: 6453.2471\n",
            "Epoch [1100], val_loss: 6452.3955\n",
            "Epoch [1120], val_loss: 6451.4980\n",
            "Epoch [1140], val_loss: 6450.5361\n",
            "Epoch [1160], val_loss: 6449.6450\n",
            "Epoch [1180], val_loss: 6448.9302\n",
            "Epoch [1200], val_loss: 6447.9023\n",
            "Epoch [1220], val_loss: 6447.2817\n",
            "Epoch [1240], val_loss: 6446.5015\n",
            "Epoch [1260], val_loss: 6446.6562\n",
            "Epoch [1280], val_loss: 6445.9033\n",
            "Epoch [1300], val_loss: 6445.7612\n",
            "Epoch [1320], val_loss: 6445.0972\n",
            "Epoch [1340], val_loss: 6444.9976\n",
            "Epoch [1360], val_loss: 6444.3320\n",
            "Epoch [1380], val_loss: 6443.8496\n",
            "Epoch [1400], val_loss: 6443.9980\n",
            "Epoch [1420], val_loss: 6443.5801\n",
            "Epoch [1440], val_loss: 6442.7012\n",
            "Epoch [1460], val_loss: 6442.5654\n",
            "Epoch [1480], val_loss: 6441.5757\n",
            "Epoch [1500], val_loss: 6441.2925\n",
            "Epoch [1520], val_loss: 6441.2129\n",
            "Epoch [1540], val_loss: 6440.7783\n",
            "Epoch [1560], val_loss: 6440.1621\n",
            "Epoch [1580], val_loss: 6440.2900\n",
            "Epoch [1600], val_loss: 6439.6934\n",
            "Epoch [1620], val_loss: 6439.0396\n",
            "Epoch [1640], val_loss: 6438.6797\n",
            "Epoch [1660], val_loss: 6439.0596\n",
            "Epoch [1680], val_loss: 6438.6143\n",
            "Epoch [1700], val_loss: 6438.2637\n",
            "Epoch [1720], val_loss: 6437.9663\n",
            "Epoch [1740], val_loss: 6437.8379\n",
            "Epoch [1760], val_loss: 6437.5698\n",
            "Epoch [1780], val_loss: 6437.2178\n",
            "Epoch [1800], val_loss: 6437.0889\n",
            "Epoch [1820], val_loss: 6436.6768\n",
            "Epoch [1840], val_loss: 6436.4819\n",
            "Epoch [1860], val_loss: 6435.7451\n",
            "Epoch [1880], val_loss: 6435.8379\n",
            "Epoch [1900], val_loss: 6435.7559\n",
            "Epoch [1920], val_loss: 6435.5103\n",
            "Epoch [1940], val_loss: 6434.8086\n",
            "Epoch [1960], val_loss: 6434.3486\n",
            "Epoch [1980], val_loss: 6434.2134\n",
            "Epoch [2000], val_loss: 6434.0474\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiWtBF3j_v1U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "186d64c5-8c07-4a7b-9cae-76239017e015"
      },
      "source": [
        "model3 = InsuranceModel()\n",
        "epochs = 4000\n",
        "lr = 0.001\n",
        "history3 = fit(epochs, lr, model3, train_loader, val_loader)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 13526.4941\n",
            "Epoch [40], val_loss: 13086.3945\n",
            "Epoch [60], val_loss: 12646.1182\n",
            "Epoch [80], val_loss: 12208.3115\n",
            "Epoch [100], val_loss: 11779.4590\n",
            "Epoch [120], val_loss: 11362.5020\n",
            "Epoch [140], val_loss: 10969.9678\n",
            "Epoch [160], val_loss: 10608.3652\n",
            "Epoch [180], val_loss: 10278.1035\n",
            "Epoch [200], val_loss: 9971.3984\n",
            "Epoch [220], val_loss: 9693.5869\n",
            "Epoch [240], val_loss: 9431.7988\n",
            "Epoch [260], val_loss: 9187.4102\n",
            "Epoch [280], val_loss: 8960.0117\n",
            "Epoch [300], val_loss: 8754.7217\n",
            "Epoch [320], val_loss: 8565.9033\n",
            "Epoch [340], val_loss: 8396.8232\n",
            "Epoch [360], val_loss: 8246.3711\n",
            "Epoch [380], val_loss: 8114.7490\n",
            "Epoch [400], val_loss: 7995.5820\n",
            "Epoch [420], val_loss: 7885.9844\n",
            "Epoch [440], val_loss: 7788.9688\n",
            "Epoch [460], val_loss: 7701.7407\n",
            "Epoch [480], val_loss: 7624.2754\n",
            "Epoch [500], val_loss: 7556.3242\n",
            "Epoch [520], val_loss: 7498.1548\n",
            "Epoch [540], val_loss: 7448.4268\n",
            "Epoch [560], val_loss: 7404.0273\n",
            "Epoch [580], val_loss: 7365.5991\n",
            "Epoch [600], val_loss: 7333.4629\n",
            "Epoch [620], val_loss: 7306.8984\n",
            "Epoch [640], val_loss: 7282.7441\n",
            "Epoch [660], val_loss: 7260.9717\n",
            "Epoch [680], val_loss: 7242.8433\n",
            "Epoch [700], val_loss: 7225.7402\n",
            "Epoch [720], val_loss: 7211.5874\n",
            "Epoch [740], val_loss: 7201.3887\n",
            "Epoch [760], val_loss: 7192.9727\n",
            "Epoch [780], val_loss: 7184.8853\n",
            "Epoch [800], val_loss: 7177.5615\n",
            "Epoch [820], val_loss: 7171.1450\n",
            "Epoch [840], val_loss: 7165.1143\n",
            "Epoch [860], val_loss: 7159.4165\n",
            "Epoch [880], val_loss: 7153.7051\n",
            "Epoch [900], val_loss: 7148.0469\n",
            "Epoch [920], val_loss: 7143.1733\n",
            "Epoch [940], val_loss: 7138.6738\n",
            "Epoch [960], val_loss: 7134.7544\n",
            "Epoch [980], val_loss: 7130.9438\n",
            "Epoch [1000], val_loss: 7127.4346\n",
            "Epoch [1020], val_loss: 7124.1172\n",
            "Epoch [1040], val_loss: 7120.9272\n",
            "Epoch [1060], val_loss: 7117.7524\n",
            "Epoch [1080], val_loss: 7114.6807\n",
            "Epoch [1100], val_loss: 7111.7461\n",
            "Epoch [1120], val_loss: 7108.8618\n",
            "Epoch [1140], val_loss: 7106.0967\n",
            "Epoch [1160], val_loss: 7103.3472\n",
            "Epoch [1180], val_loss: 7100.5601\n",
            "Epoch [1200], val_loss: 7097.8740\n",
            "Epoch [1220], val_loss: 7095.2119\n",
            "Epoch [1240], val_loss: 7092.5264\n",
            "Epoch [1260], val_loss: 7089.8477\n",
            "Epoch [1280], val_loss: 7087.1880\n",
            "Epoch [1300], val_loss: 7084.4824\n",
            "Epoch [1320], val_loss: 7081.8511\n",
            "Epoch [1340], val_loss: 7079.2080\n",
            "Epoch [1360], val_loss: 7076.5283\n",
            "Epoch [1380], val_loss: 7073.8291\n",
            "Epoch [1400], val_loss: 7071.1396\n",
            "Epoch [1420], val_loss: 7068.4893\n",
            "Epoch [1440], val_loss: 7065.8936\n",
            "Epoch [1460], val_loss: 7063.2930\n",
            "Epoch [1480], val_loss: 7060.6729\n",
            "Epoch [1500], val_loss: 7058.0073\n",
            "Epoch [1520], val_loss: 7055.4141\n",
            "Epoch [1540], val_loss: 7052.8604\n",
            "Epoch [1560], val_loss: 7050.3047\n",
            "Epoch [1580], val_loss: 7047.7041\n",
            "Epoch [1600], val_loss: 7045.1660\n",
            "Epoch [1620], val_loss: 7042.5840\n",
            "Epoch [1640], val_loss: 7039.9932\n",
            "Epoch [1660], val_loss: 7037.3984\n",
            "Epoch [1680], val_loss: 7034.7920\n",
            "Epoch [1700], val_loss: 7032.2271\n",
            "Epoch [1720], val_loss: 7029.6812\n",
            "Epoch [1740], val_loss: 7027.2065\n",
            "Epoch [1760], val_loss: 7024.7402\n",
            "Epoch [1780], val_loss: 7022.2441\n",
            "Epoch [1800], val_loss: 7019.7910\n",
            "Epoch [1820], val_loss: 7017.3135\n",
            "Epoch [1840], val_loss: 7014.8545\n",
            "Epoch [1860], val_loss: 7012.3774\n",
            "Epoch [1880], val_loss: 7009.9014\n",
            "Epoch [1900], val_loss: 7007.4102\n",
            "Epoch [1920], val_loss: 7004.9668\n",
            "Epoch [1940], val_loss: 7002.5078\n",
            "Epoch [1960], val_loss: 7000.0879\n",
            "Epoch [1980], val_loss: 6997.6299\n",
            "Epoch [2000], val_loss: 6995.2246\n",
            "Epoch [2020], val_loss: 6992.7925\n",
            "Epoch [2040], val_loss: 6990.3428\n",
            "Epoch [2060], val_loss: 6987.8477\n",
            "Epoch [2080], val_loss: 6985.3828\n",
            "Epoch [2100], val_loss: 6982.9258\n",
            "Epoch [2120], val_loss: 6980.4609\n",
            "Epoch [2140], val_loss: 6978.0234\n",
            "Epoch [2160], val_loss: 6975.5615\n",
            "Epoch [2180], val_loss: 6973.1240\n",
            "Epoch [2200], val_loss: 6970.6777\n",
            "Epoch [2220], val_loss: 6968.2334\n",
            "Epoch [2240], val_loss: 6965.7793\n",
            "Epoch [2260], val_loss: 6963.3140\n",
            "Epoch [2280], val_loss: 6960.8896\n",
            "Epoch [2300], val_loss: 6958.5596\n",
            "Epoch [2320], val_loss: 6956.2065\n",
            "Epoch [2340], val_loss: 6953.7769\n",
            "Epoch [2360], val_loss: 6951.3750\n",
            "Epoch [2380], val_loss: 6949.0684\n",
            "Epoch [2400], val_loss: 6946.7607\n",
            "Epoch [2420], val_loss: 6944.4712\n",
            "Epoch [2440], val_loss: 6942.1064\n",
            "Epoch [2460], val_loss: 6939.7974\n",
            "Epoch [2480], val_loss: 6937.5088\n",
            "Epoch [2500], val_loss: 6935.2183\n",
            "Epoch [2520], val_loss: 6932.9502\n",
            "Epoch [2540], val_loss: 6930.6436\n",
            "Epoch [2560], val_loss: 6928.4238\n",
            "Epoch [2580], val_loss: 6926.1401\n",
            "Epoch [2600], val_loss: 6923.8926\n",
            "Epoch [2620], val_loss: 6921.5986\n",
            "Epoch [2640], val_loss: 6919.2510\n",
            "Epoch [2660], val_loss: 6916.9893\n",
            "Epoch [2680], val_loss: 6914.6948\n",
            "Epoch [2700], val_loss: 6912.3730\n",
            "Epoch [2720], val_loss: 6910.0557\n",
            "Epoch [2740], val_loss: 6907.7686\n",
            "Epoch [2760], val_loss: 6905.4531\n",
            "Epoch [2780], val_loss: 6903.1426\n",
            "Epoch [2800], val_loss: 6900.8145\n",
            "Epoch [2820], val_loss: 6898.5176\n",
            "Epoch [2840], val_loss: 6896.2373\n",
            "Epoch [2860], val_loss: 6893.9980\n",
            "Epoch [2880], val_loss: 6891.7041\n",
            "Epoch [2900], val_loss: 6889.4951\n",
            "Epoch [2920], val_loss: 6887.2500\n",
            "Epoch [2940], val_loss: 6885.0234\n",
            "Epoch [2960], val_loss: 6882.8223\n",
            "Epoch [2980], val_loss: 6880.6157\n",
            "Epoch [3000], val_loss: 6878.4121\n",
            "Epoch [3020], val_loss: 6876.2080\n",
            "Epoch [3040], val_loss: 6874.0566\n",
            "Epoch [3060], val_loss: 6871.8848\n",
            "Epoch [3080], val_loss: 6869.6958\n",
            "Epoch [3100], val_loss: 6867.5459\n",
            "Epoch [3120], val_loss: 6865.3535\n",
            "Epoch [3140], val_loss: 6863.1289\n",
            "Epoch [3160], val_loss: 6860.9678\n",
            "Epoch [3180], val_loss: 6858.8125\n",
            "Epoch [3200], val_loss: 6856.6533\n",
            "Epoch [3220], val_loss: 6854.5264\n",
            "Epoch [3240], val_loss: 6852.4155\n",
            "Epoch [3260], val_loss: 6850.2324\n",
            "Epoch [3280], val_loss: 6848.1167\n",
            "Epoch [3300], val_loss: 6845.9990\n",
            "Epoch [3320], val_loss: 6843.8574\n",
            "Epoch [3340], val_loss: 6841.7539\n",
            "Epoch [3360], val_loss: 6839.5879\n",
            "Epoch [3380], val_loss: 6837.5146\n",
            "Epoch [3400], val_loss: 6835.4482\n",
            "Epoch [3420], val_loss: 6833.3877\n",
            "Epoch [3440], val_loss: 6831.3345\n",
            "Epoch [3460], val_loss: 6829.2793\n",
            "Epoch [3480], val_loss: 6827.2012\n",
            "Epoch [3500], val_loss: 6825.1577\n",
            "Epoch [3520], val_loss: 6823.0811\n",
            "Epoch [3540], val_loss: 6821.0073\n",
            "Epoch [3560], val_loss: 6818.9434\n",
            "Epoch [3580], val_loss: 6816.8911\n",
            "Epoch [3600], val_loss: 6814.8105\n",
            "Epoch [3620], val_loss: 6812.7471\n",
            "Epoch [3640], val_loss: 6810.6719\n",
            "Epoch [3660], val_loss: 6808.6045\n",
            "Epoch [3680], val_loss: 6806.5347\n",
            "Epoch [3700], val_loss: 6804.4775\n",
            "Epoch [3720], val_loss: 6802.4204\n",
            "Epoch [3740], val_loss: 6800.3740\n",
            "Epoch [3760], val_loss: 6798.2969\n",
            "Epoch [3780], val_loss: 6796.2109\n",
            "Epoch [3800], val_loss: 6794.1353\n",
            "Epoch [3820], val_loss: 6792.0957\n",
            "Epoch [3840], val_loss: 6790.0703\n",
            "Epoch [3860], val_loss: 6788.0469\n",
            "Epoch [3880], val_loss: 6786.0254\n",
            "Epoch [3900], val_loss: 6783.9888\n",
            "Epoch [3920], val_loss: 6781.9658\n",
            "Epoch [3940], val_loss: 6779.9229\n",
            "Epoch [3960], val_loss: 6777.8760\n",
            "Epoch [3980], val_loss: 6775.8516\n",
            "Epoch [4000], val_loss: 6773.8237\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llOw8mQ3AHov",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "325654a6-d58a-40ac-f337-486f1f07a1f8"
      },
      "source": [
        "model4 = InsuranceModel()\n",
        "epochs = 8000\n",
        "lr = 0.0001\n",
        "history4 = fit(epochs, lr, model4, train_loader, val_loader)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 13944.0244\n",
            "Epoch [40], val_loss: 13899.9824\n",
            "Epoch [60], val_loss: 13855.9766\n",
            "Epoch [80], val_loss: 13811.9688\n",
            "Epoch [100], val_loss: 13767.9453\n",
            "Epoch [120], val_loss: 13723.9189\n",
            "Epoch [140], val_loss: 13679.8721\n",
            "Epoch [160], val_loss: 13635.8555\n",
            "Epoch [180], val_loss: 13591.8574\n",
            "Epoch [200], val_loss: 13547.8320\n",
            "Epoch [220], val_loss: 13503.8340\n",
            "Epoch [240], val_loss: 13459.8457\n",
            "Epoch [260], val_loss: 13415.8008\n",
            "Epoch [280], val_loss: 13371.7773\n",
            "Epoch [300], val_loss: 13327.7559\n",
            "Epoch [320], val_loss: 13283.7773\n",
            "Epoch [340], val_loss: 13239.7695\n",
            "Epoch [360], val_loss: 13195.7373\n",
            "Epoch [380], val_loss: 13151.7178\n",
            "Epoch [400], val_loss: 13107.6465\n",
            "Epoch [420], val_loss: 13063.6465\n",
            "Epoch [440], val_loss: 13019.6221\n",
            "Epoch [460], val_loss: 12975.6484\n",
            "Epoch [480], val_loss: 12931.6445\n",
            "Epoch [500], val_loss: 12887.6084\n",
            "Epoch [520], val_loss: 12843.6211\n",
            "Epoch [540], val_loss: 12799.6309\n",
            "Epoch [560], val_loss: 12755.6016\n",
            "Epoch [580], val_loss: 12711.6143\n",
            "Epoch [600], val_loss: 12667.6074\n",
            "Epoch [620], val_loss: 12623.5762\n",
            "Epoch [640], val_loss: 12579.5645\n",
            "Epoch [660], val_loss: 12535.5752\n",
            "Epoch [680], val_loss: 12491.8691\n",
            "Epoch [700], val_loss: 12448.1777\n",
            "Epoch [720], val_loss: 12404.4746\n",
            "Epoch [740], val_loss: 12360.7812\n",
            "Epoch [760], val_loss: 12317.1406\n",
            "Epoch [780], val_loss: 12273.5371\n",
            "Epoch [800], val_loss: 12229.9668\n",
            "Epoch [820], val_loss: 12186.4316\n",
            "Epoch [840], val_loss: 12142.9453\n",
            "Epoch [860], val_loss: 12099.6807\n",
            "Epoch [880], val_loss: 12056.7363\n",
            "Epoch [900], val_loss: 12013.7988\n",
            "Epoch [920], val_loss: 11970.9004\n",
            "Epoch [940], val_loss: 11928.3223\n",
            "Epoch [960], val_loss: 11885.7568\n",
            "Epoch [980], val_loss: 11843.2129\n",
            "Epoch [1000], val_loss: 11800.7520\n",
            "Epoch [1020], val_loss: 11758.3125\n",
            "Epoch [1040], val_loss: 11715.9062\n",
            "Epoch [1060], val_loss: 11673.6953\n",
            "Epoch [1080], val_loss: 11631.5449\n",
            "Epoch [1100], val_loss: 11589.4297\n",
            "Epoch [1120], val_loss: 11547.3984\n",
            "Epoch [1140], val_loss: 11505.9609\n",
            "Epoch [1160], val_loss: 11464.6650\n",
            "Epoch [1180], val_loss: 11423.7070\n",
            "Epoch [1200], val_loss: 11383.0303\n",
            "Epoch [1220], val_loss: 11342.6914\n",
            "Epoch [1240], val_loss: 11302.3984\n",
            "Epoch [1260], val_loss: 11262.0977\n",
            "Epoch [1280], val_loss: 11221.8076\n",
            "Epoch [1300], val_loss: 11182.3477\n",
            "Epoch [1320], val_loss: 11143.5918\n",
            "Epoch [1340], val_loss: 11105.0186\n",
            "Epoch [1360], val_loss: 11066.4805\n",
            "Epoch [1380], val_loss: 11028.0859\n",
            "Epoch [1400], val_loss: 10989.9219\n",
            "Epoch [1420], val_loss: 10952.1064\n",
            "Epoch [1440], val_loss: 10914.7988\n",
            "Epoch [1460], val_loss: 10877.5322\n",
            "Epoch [1480], val_loss: 10840.7051\n",
            "Epoch [1500], val_loss: 10804.2832\n",
            "Epoch [1520], val_loss: 10768.1045\n",
            "Epoch [1540], val_loss: 10732.2510\n",
            "Epoch [1560], val_loss: 10696.7949\n",
            "Epoch [1580], val_loss: 10661.7109\n",
            "Epoch [1600], val_loss: 10627.0586\n",
            "Epoch [1620], val_loss: 10592.8359\n",
            "Epoch [1640], val_loss: 10558.7910\n",
            "Epoch [1660], val_loss: 10524.9385\n",
            "Epoch [1680], val_loss: 10491.4160\n",
            "Epoch [1700], val_loss: 10458.1445\n",
            "Epoch [1720], val_loss: 10425.3906\n",
            "Epoch [1740], val_loss: 10392.7510\n",
            "Epoch [1760], val_loss: 10360.3760\n",
            "Epoch [1780], val_loss: 10328.1094\n",
            "Epoch [1800], val_loss: 10296.1797\n",
            "Epoch [1820], val_loss: 10264.4014\n",
            "Epoch [1840], val_loss: 10232.6289\n",
            "Epoch [1860], val_loss: 10200.9688\n",
            "Epoch [1880], val_loss: 10169.9961\n",
            "Epoch [1900], val_loss: 10139.1328\n",
            "Epoch [1920], val_loss: 10108.3516\n",
            "Epoch [1940], val_loss: 10077.7559\n",
            "Epoch [1960], val_loss: 10047.6543\n",
            "Epoch [1980], val_loss: 10017.9648\n",
            "Epoch [2000], val_loss: 9988.4258\n",
            "Epoch [2020], val_loss: 9959.2100\n",
            "Epoch [2040], val_loss: 9930.2715\n",
            "Epoch [2060], val_loss: 9901.7754\n",
            "Epoch [2080], val_loss: 9873.5615\n",
            "Epoch [2100], val_loss: 9845.5742\n",
            "Epoch [2120], val_loss: 9818.0781\n",
            "Epoch [2140], val_loss: 9791.1543\n",
            "Epoch [2160], val_loss: 9764.2090\n",
            "Epoch [2180], val_loss: 9737.1973\n",
            "Epoch [2200], val_loss: 9710.2090\n",
            "Epoch [2220], val_loss: 9683.3945\n",
            "Epoch [2240], val_loss: 9657.0020\n",
            "Epoch [2260], val_loss: 9630.5957\n",
            "Epoch [2280], val_loss: 9604.1494\n",
            "Epoch [2300], val_loss: 9577.6504\n",
            "Epoch [2320], val_loss: 9551.3652\n",
            "Epoch [2340], val_loss: 9525.1758\n",
            "Epoch [2360], val_loss: 9499.0586\n",
            "Epoch [2380], val_loss: 9473.1475\n",
            "Epoch [2400], val_loss: 9447.5820\n",
            "Epoch [2420], val_loss: 9422.1377\n",
            "Epoch [2440], val_loss: 9396.8350\n",
            "Epoch [2460], val_loss: 9371.8164\n",
            "Epoch [2480], val_loss: 9346.9570\n",
            "Epoch [2500], val_loss: 9322.3398\n",
            "Epoch [2520], val_loss: 9298.0938\n",
            "Epoch [2540], val_loss: 9274.0488\n",
            "Epoch [2560], val_loss: 9250.1143\n",
            "Epoch [2580], val_loss: 9226.1025\n",
            "Epoch [2600], val_loss: 9202.2969\n",
            "Epoch [2620], val_loss: 9178.6582\n",
            "Epoch [2640], val_loss: 9155.1504\n",
            "Epoch [2660], val_loss: 9131.6875\n",
            "Epoch [2680], val_loss: 9108.8008\n",
            "Epoch [2700], val_loss: 9086.0742\n",
            "Epoch [2720], val_loss: 9063.5273\n",
            "Epoch [2740], val_loss: 9041.0293\n",
            "Epoch [2760], val_loss: 9018.7285\n",
            "Epoch [2780], val_loss: 8996.5645\n",
            "Epoch [2800], val_loss: 8974.4443\n",
            "Epoch [2820], val_loss: 8952.6914\n",
            "Epoch [2840], val_loss: 8931.3926\n",
            "Epoch [2860], val_loss: 8910.4053\n",
            "Epoch [2880], val_loss: 8889.5332\n",
            "Epoch [2900], val_loss: 8868.6250\n",
            "Epoch [2920], val_loss: 8848.0176\n",
            "Epoch [2940], val_loss: 8827.7666\n",
            "Epoch [2960], val_loss: 8807.5430\n",
            "Epoch [2980], val_loss: 8787.3926\n",
            "Epoch [3000], val_loss: 8767.6035\n",
            "Epoch [3020], val_loss: 8748.0908\n",
            "Epoch [3040], val_loss: 8728.6484\n",
            "Epoch [3060], val_loss: 8709.3135\n",
            "Epoch [3080], val_loss: 8689.9580\n",
            "Epoch [3100], val_loss: 8670.7715\n",
            "Epoch [3120], val_loss: 8651.7266\n",
            "Epoch [3140], val_loss: 8632.8223\n",
            "Epoch [3160], val_loss: 8614.2939\n",
            "Epoch [3180], val_loss: 8595.9668\n",
            "Epoch [3200], val_loss: 8577.7070\n",
            "Epoch [3220], val_loss: 8559.8701\n",
            "Epoch [3240], val_loss: 8542.0439\n",
            "Epoch [3260], val_loss: 8524.3008\n",
            "Epoch [3280], val_loss: 8506.8535\n",
            "Epoch [3300], val_loss: 8489.9980\n",
            "Epoch [3320], val_loss: 8473.3125\n",
            "Epoch [3340], val_loss: 8456.8008\n",
            "Epoch [3360], val_loss: 8440.3184\n",
            "Epoch [3380], val_loss: 8423.9102\n",
            "Epoch [3400], val_loss: 8407.8281\n",
            "Epoch [3420], val_loss: 8391.9160\n",
            "Epoch [3440], val_loss: 8376.0693\n",
            "Epoch [3460], val_loss: 8360.3359\n",
            "Epoch [3480], val_loss: 8344.7324\n",
            "Epoch [3500], val_loss: 8329.5566\n",
            "Epoch [3520], val_loss: 8314.3711\n",
            "Epoch [3540], val_loss: 8299.5156\n",
            "Epoch [3560], val_loss: 8284.9316\n",
            "Epoch [3580], val_loss: 8270.4199\n",
            "Epoch [3600], val_loss: 8256.0293\n",
            "Epoch [3620], val_loss: 8241.7812\n",
            "Epoch [3640], val_loss: 8227.8252\n",
            "Epoch [3660], val_loss: 8213.9531\n",
            "Epoch [3680], val_loss: 8200.2373\n",
            "Epoch [3700], val_loss: 8186.6567\n",
            "Epoch [3720], val_loss: 8173.7656\n",
            "Epoch [3740], val_loss: 8161.0967\n",
            "Epoch [3760], val_loss: 8148.4990\n",
            "Epoch [3780], val_loss: 8135.9375\n",
            "Epoch [3800], val_loss: 8123.4209\n",
            "Epoch [3820], val_loss: 8111.1792\n",
            "Epoch [3840], val_loss: 8098.9971\n",
            "Epoch [3860], val_loss: 8086.8091\n",
            "Epoch [3880], val_loss: 8074.6943\n",
            "Epoch [3900], val_loss: 8062.7705\n",
            "Epoch [3920], val_loss: 8050.8613\n",
            "Epoch [3940], val_loss: 8039.0166\n",
            "Epoch [3960], val_loss: 8027.2100\n",
            "Epoch [3980], val_loss: 8015.4355\n",
            "Epoch [4000], val_loss: 8003.8711\n",
            "Epoch [4020], val_loss: 7992.5117\n",
            "Epoch [4040], val_loss: 7981.2461\n",
            "Epoch [4060], val_loss: 7969.9932\n",
            "Epoch [4080], val_loss: 7958.8560\n",
            "Epoch [4100], val_loss: 7947.7871\n",
            "Epoch [4120], val_loss: 7936.8057\n",
            "Epoch [4140], val_loss: 7925.8916\n",
            "Epoch [4160], val_loss: 7915.0312\n",
            "Epoch [4180], val_loss: 7904.3467\n",
            "Epoch [4200], val_loss: 7893.8540\n",
            "Epoch [4220], val_loss: 7883.4414\n",
            "Epoch [4240], val_loss: 7872.8994\n",
            "Epoch [4260], val_loss: 7862.6812\n",
            "Epoch [4280], val_loss: 7852.7793\n",
            "Epoch [4300], val_loss: 7843.1797\n",
            "Epoch [4320], val_loss: 7833.6533\n",
            "Epoch [4340], val_loss: 7824.1768\n",
            "Epoch [4360], val_loss: 7814.7432\n",
            "Epoch [4380], val_loss: 7805.3213\n",
            "Epoch [4400], val_loss: 7796.0840\n",
            "Epoch [4420], val_loss: 7786.9697\n",
            "Epoch [4440], val_loss: 7777.8711\n",
            "Epoch [4460], val_loss: 7768.9248\n",
            "Epoch [4480], val_loss: 7760.0986\n",
            "Epoch [4500], val_loss: 7751.2471\n",
            "Epoch [4520], val_loss: 7742.4785\n",
            "Epoch [4540], val_loss: 7733.7583\n",
            "Epoch [4560], val_loss: 7725.1318\n",
            "Epoch [4580], val_loss: 7716.7383\n",
            "Epoch [4600], val_loss: 7708.4033\n",
            "Epoch [4620], val_loss: 7700.1392\n",
            "Epoch [4640], val_loss: 7692.0908\n",
            "Epoch [4660], val_loss: 7684.2310\n",
            "Epoch [4680], val_loss: 7676.4873\n",
            "Epoch [4700], val_loss: 7668.8066\n",
            "Epoch [4720], val_loss: 7661.1323\n",
            "Epoch [4740], val_loss: 7653.4990\n",
            "Epoch [4760], val_loss: 7645.9863\n",
            "Epoch [4780], val_loss: 7638.3647\n",
            "Epoch [4800], val_loss: 7630.9326\n",
            "Epoch [4820], val_loss: 7623.4941\n",
            "Epoch [4840], val_loss: 7616.2041\n",
            "Epoch [4860], val_loss: 7609.1421\n",
            "Epoch [4880], val_loss: 7602.1191\n",
            "Epoch [4900], val_loss: 7595.3350\n",
            "Epoch [4920], val_loss: 7588.6641\n",
            "Epoch [4940], val_loss: 7582.1436\n",
            "Epoch [4960], val_loss: 7575.6523\n",
            "Epoch [4980], val_loss: 7569.1685\n",
            "Epoch [5000], val_loss: 7562.8027\n",
            "Epoch [5020], val_loss: 7556.6582\n",
            "Epoch [5040], val_loss: 7550.6133\n",
            "Epoch [5060], val_loss: 7544.5596\n",
            "Epoch [5080], val_loss: 7538.5420\n",
            "Epoch [5100], val_loss: 7532.5938\n",
            "Epoch [5120], val_loss: 7526.7837\n",
            "Epoch [5140], val_loss: 7521.0469\n",
            "Epoch [5160], val_loss: 7515.4043\n",
            "Epoch [5180], val_loss: 7509.8115\n",
            "Epoch [5200], val_loss: 7504.4473\n",
            "Epoch [5220], val_loss: 7499.1641\n",
            "Epoch [5240], val_loss: 7493.9707\n",
            "Epoch [5260], val_loss: 7488.7334\n",
            "Epoch [5280], val_loss: 7483.5962\n",
            "Epoch [5300], val_loss: 7478.6377\n",
            "Epoch [5320], val_loss: 7473.6650\n",
            "Epoch [5340], val_loss: 7468.7041\n",
            "Epoch [5360], val_loss: 7463.8652\n",
            "Epoch [5380], val_loss: 7458.9712\n",
            "Epoch [5400], val_loss: 7454.1885\n",
            "Epoch [5420], val_loss: 7449.5415\n",
            "Epoch [5440], val_loss: 7444.8789\n",
            "Epoch [5460], val_loss: 7440.2715\n",
            "Epoch [5480], val_loss: 7435.7529\n",
            "Epoch [5500], val_loss: 7431.2852\n",
            "Epoch [5520], val_loss: 7426.8037\n",
            "Epoch [5540], val_loss: 7422.3877\n",
            "Epoch [5560], val_loss: 7418.0410\n",
            "Epoch [5580], val_loss: 7413.6768\n",
            "Epoch [5600], val_loss: 7409.4092\n",
            "Epoch [5620], val_loss: 7405.2061\n",
            "Epoch [5640], val_loss: 7401.2363\n",
            "Epoch [5660], val_loss: 7397.3447\n",
            "Epoch [5680], val_loss: 7393.4287\n",
            "Epoch [5700], val_loss: 7389.6108\n",
            "Epoch [5720], val_loss: 7385.7949\n",
            "Epoch [5740], val_loss: 7381.9971\n",
            "Epoch [5760], val_loss: 7378.2725\n",
            "Epoch [5780], val_loss: 7374.5493\n",
            "Epoch [5800], val_loss: 7370.8135\n",
            "Epoch [5820], val_loss: 7367.1562\n",
            "Epoch [5840], val_loss: 7363.5410\n",
            "Epoch [5860], val_loss: 7360.1699\n",
            "Epoch [5880], val_loss: 7356.7686\n",
            "Epoch [5900], val_loss: 7353.4424\n",
            "Epoch [5920], val_loss: 7350.2139\n",
            "Epoch [5940], val_loss: 7346.9307\n",
            "Epoch [5960], val_loss: 7343.7842\n",
            "Epoch [5980], val_loss: 7340.6963\n",
            "Epoch [6000], val_loss: 7337.7056\n",
            "Epoch [6020], val_loss: 7334.7881\n",
            "Epoch [6040], val_loss: 7331.8477\n",
            "Epoch [6060], val_loss: 7328.9897\n",
            "Epoch [6080], val_loss: 7326.1602\n",
            "Epoch [6100], val_loss: 7323.4062\n",
            "Epoch [6120], val_loss: 7320.7100\n",
            "Epoch [6140], val_loss: 7318.2021\n",
            "Epoch [6160], val_loss: 7315.6997\n",
            "Epoch [6180], val_loss: 7313.2134\n",
            "Epoch [6200], val_loss: 7310.7305\n",
            "Epoch [6220], val_loss: 7308.2632\n",
            "Epoch [6240], val_loss: 7305.8242\n",
            "Epoch [6260], val_loss: 7303.4326\n",
            "Epoch [6280], val_loss: 7301.0161\n",
            "Epoch [6300], val_loss: 7298.6182\n",
            "Epoch [6320], val_loss: 7296.2383\n",
            "Epoch [6340], val_loss: 7293.8628\n",
            "Epoch [6360], val_loss: 7291.4790\n",
            "Epoch [6380], val_loss: 7289.1357\n",
            "Epoch [6400], val_loss: 7286.8340\n",
            "Epoch [6420], val_loss: 7284.5566\n",
            "Epoch [6440], val_loss: 7282.3379\n",
            "Epoch [6460], val_loss: 7280.1826\n",
            "Epoch [6480], val_loss: 7277.9844\n",
            "Epoch [6500], val_loss: 7275.7803\n",
            "Epoch [6520], val_loss: 7273.6396\n",
            "Epoch [6540], val_loss: 7271.5000\n",
            "Epoch [6560], val_loss: 7269.3428\n",
            "Epoch [6580], val_loss: 7267.2412\n",
            "Epoch [6600], val_loss: 7265.0996\n",
            "Epoch [6620], val_loss: 7263.0718\n",
            "Epoch [6640], val_loss: 7261.1714\n",
            "Epoch [6660], val_loss: 7259.3350\n",
            "Epoch [6680], val_loss: 7257.4795\n",
            "Epoch [6700], val_loss: 7255.6475\n",
            "Epoch [6720], val_loss: 7253.9160\n",
            "Epoch [6740], val_loss: 7252.0996\n",
            "Epoch [6760], val_loss: 7250.3765\n",
            "Epoch [6780], val_loss: 7248.6104\n",
            "Epoch [6800], val_loss: 7246.8467\n",
            "Epoch [6820], val_loss: 7245.1050\n",
            "Epoch [6840], val_loss: 7243.3848\n",
            "Epoch [6860], val_loss: 7241.6396\n",
            "Epoch [6880], val_loss: 7239.8955\n",
            "Epoch [6900], val_loss: 7238.1494\n",
            "Epoch [6920], val_loss: 7236.4282\n",
            "Epoch [6940], val_loss: 7234.7124\n",
            "Epoch [6960], val_loss: 7233.0293\n",
            "Epoch [6980], val_loss: 7231.3330\n",
            "Epoch [7000], val_loss: 7229.6714\n",
            "Epoch [7020], val_loss: 7228.0884\n",
            "Epoch [7040], val_loss: 7226.5098\n",
            "Epoch [7060], val_loss: 7224.9546\n",
            "Epoch [7080], val_loss: 7223.4307\n",
            "Epoch [7100], val_loss: 7221.8867\n",
            "Epoch [7120], val_loss: 7220.3818\n",
            "Epoch [7140], val_loss: 7218.9766\n",
            "Epoch [7160], val_loss: 7217.6396\n",
            "Epoch [7180], val_loss: 7216.3379\n",
            "Epoch [7200], val_loss: 7215.0410\n",
            "Epoch [7220], val_loss: 7213.7241\n",
            "Epoch [7240], val_loss: 7212.5342\n",
            "Epoch [7260], val_loss: 7211.3545\n",
            "Epoch [7280], val_loss: 7210.1821\n",
            "Epoch [7300], val_loss: 7209.1279\n",
            "Epoch [7320], val_loss: 7208.0811\n",
            "Epoch [7340], val_loss: 7207.0459\n",
            "Epoch [7360], val_loss: 7205.9883\n",
            "Epoch [7380], val_loss: 7205.0532\n",
            "Epoch [7400], val_loss: 7204.1416\n",
            "Epoch [7420], val_loss: 7203.2373\n",
            "Epoch [7440], val_loss: 7202.3535\n",
            "Epoch [7460], val_loss: 7201.4561\n",
            "Epoch [7480], val_loss: 7200.5586\n",
            "Epoch [7500], val_loss: 7199.6680\n",
            "Epoch [7520], val_loss: 7198.8008\n",
            "Epoch [7540], val_loss: 7197.9170\n",
            "Epoch [7560], val_loss: 7197.0986\n",
            "Epoch [7580], val_loss: 7196.2725\n",
            "Epoch [7600], val_loss: 7195.4473\n",
            "Epoch [7620], val_loss: 7194.6172\n",
            "Epoch [7640], val_loss: 7193.7998\n",
            "Epoch [7660], val_loss: 7192.9951\n",
            "Epoch [7680], val_loss: 7192.1963\n",
            "Epoch [7700], val_loss: 7191.4131\n",
            "Epoch [7720], val_loss: 7190.6016\n",
            "Epoch [7740], val_loss: 7189.8057\n",
            "Epoch [7760], val_loss: 7189.0156\n",
            "Epoch [7780], val_loss: 7188.2065\n",
            "Epoch [7800], val_loss: 7187.4219\n",
            "Epoch [7820], val_loss: 7186.6802\n",
            "Epoch [7840], val_loss: 7185.9600\n",
            "Epoch [7860], val_loss: 7185.2256\n",
            "Epoch [7880], val_loss: 7184.4844\n",
            "Epoch [7900], val_loss: 7183.7783\n",
            "Epoch [7920], val_loss: 7183.0645\n",
            "Epoch [7940], val_loss: 7182.3564\n",
            "Epoch [7960], val_loss: 7181.6328\n",
            "Epoch [7980], val_loss: 7180.9121\n",
            "Epoch [8000], val_loss: 7180.2119\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJ_b5HTwRapu",
        "colab_type": "text"
      },
      "source": [
        "**Q: What is the final validation loss of your model?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4JGZ97TRapu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b5e16fe-d4d1-4fbf-c8be-5c06780f345c"
      },
      "source": [
        "val_loss = evaluate(model1, val_loader) \n",
        "print(val_loss)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'val_loss': 6338.86328125}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYrSJU_X41m_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "06a2ec63-01a4-443a-85da-b02154b5fb19"
      },
      "source": [
        "history = history1\n",
        "loss = [result['val_loss'] for result in history]\n",
        "plt.plot(loss)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('l1 loss')\n",
        "plt.title('Validation loss vs. No. of epochs');"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-G11hJ9Rap7",
        "colab_type": "text"
      },
      "source": [
        "## Step 5: Make predictions using the trained model\n",
        "\n",
        "**Q: Complete the following function definition to make predictions on a single input**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7XhqAkSRap7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_single(input, target, model):\n",
        "    inputs = input.unsqueeze(0)\n",
        "    predictions = model(inputs)                # fill this\n",
        "    prediction = predictions[0].detach()\n",
        "    print(\"Input:\", input)\n",
        "    print(\"Target:\", target)\n",
        "    print(\"Prediction:\", prediction)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oA60q8FRap-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "82b51cb6-ba81-42db-f734-3488f7d8ca08"
      },
      "source": [
        "input, target = val_ds[0]\n",
        "predict_single(input, target, model1)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: tensor([52.0000,  0.0000, 17.7850,  0.0000,  0.0000,  1.0000])\n",
            "Target: tensor([11389.7832])\n",
            "Prediction: tensor([13218.2588])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B1KAixBRaqB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "2ae6369b-def1-48f1-9701-0360a243d8d9"
      },
      "source": [
        "input, target = val_ds[10]\n",
        "predict_single(input, target, model1)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: tensor([55.0000,  0.0000, 24.6040,  3.0000,  0.0000,  0.0000])\n",
            "Target: tensor([14873.9590])\n",
            "Prediction: tensor([14133.2354])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOb6_gKiRaqF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "b3471126-2228-48a2-9a93-63686e91f8c3"
      },
      "source": [
        "input, target = val_ds[23]\n",
        "predict_single(input, target, model1)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: tensor([38.0000,  1.0000, 30.0700,  1.0000,  0.0000,  3.0000])\n",
            "Target: tensor([6256.6187])\n",
            "Prediction: tensor([7894.5786])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHaoV-_KRaqJ",
        "colab_type": "text"
      },
      "source": [
        "Are you happy with your model's predictions? Try to improve them further."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7ePRllmDgTe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "da19a726-9fd5-488d-ed51-a3040c4efd57"
      },
      "source": [
        "model = InsuranceModel()\n",
        "epochs = 5000\n",
        "lr = 0.1\n",
        "history = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 6997.7607\n",
            "Epoch [40], val_loss: 6776.4766\n",
            "Epoch [60], val_loss: 6607.8184\n",
            "Epoch [80], val_loss: 6512.1650\n",
            "Epoch [100], val_loss: 6462.2354\n",
            "Epoch [120], val_loss: 6450.0381\n",
            "Epoch [140], val_loss: 6441.5776\n",
            "Epoch [160], val_loss: 6438.6050\n",
            "Epoch [180], val_loss: 6435.9399\n",
            "Epoch [200], val_loss: 6434.4253\n",
            "Epoch [220], val_loss: 6429.7275\n",
            "Epoch [240], val_loss: 6428.6729\n",
            "Epoch [260], val_loss: 6425.7617\n",
            "Epoch [280], val_loss: 6421.6064\n",
            "Epoch [300], val_loss: 6419.6445\n",
            "Epoch [320], val_loss: 6416.8037\n",
            "Epoch [340], val_loss: 6414.6064\n",
            "Epoch [360], val_loss: 6412.6235\n",
            "Epoch [380], val_loss: 6409.1719\n",
            "Epoch [400], val_loss: 6408.7837\n",
            "Epoch [420], val_loss: 6402.5728\n",
            "Epoch [440], val_loss: 6400.4829\n",
            "Epoch [460], val_loss: 6397.5068\n",
            "Epoch [480], val_loss: 6396.1953\n",
            "Epoch [500], val_loss: 6393.6963\n",
            "Epoch [520], val_loss: 6391.6826\n",
            "Epoch [540], val_loss: 6387.7529\n",
            "Epoch [560], val_loss: 6384.5942\n",
            "Epoch [580], val_loss: 6381.6748\n",
            "Epoch [600], val_loss: 6379.8232\n",
            "Epoch [620], val_loss: 6378.4570\n",
            "Epoch [640], val_loss: 6375.8584\n",
            "Epoch [660], val_loss: 6374.0166\n",
            "Epoch [680], val_loss: 6371.8428\n",
            "Epoch [700], val_loss: 6370.3760\n",
            "Epoch [720], val_loss: 6366.4756\n",
            "Epoch [740], val_loss: 6362.6592\n",
            "Epoch [760], val_loss: 6361.2090\n",
            "Epoch [780], val_loss: 6358.3994\n",
            "Epoch [800], val_loss: 6357.1133\n",
            "Epoch [820], val_loss: 6355.9844\n",
            "Epoch [840], val_loss: 6351.5654\n",
            "Epoch [860], val_loss: 6350.0811\n",
            "Epoch [880], val_loss: 6355.1392\n",
            "Epoch [900], val_loss: 6344.7998\n",
            "Epoch [920], val_loss: 6344.6514\n",
            "Epoch [940], val_loss: 6339.8086\n",
            "Epoch [960], val_loss: 6341.3057\n",
            "Epoch [980], val_loss: 6339.2422\n",
            "Epoch [1000], val_loss: 6344.0908\n",
            "Epoch [1020], val_loss: 6340.2881\n",
            "Epoch [1040], val_loss: 6335.1387\n",
            "Epoch [1060], val_loss: 6332.3057\n",
            "Epoch [1080], val_loss: 6336.8213\n",
            "Epoch [1100], val_loss: 6329.1045\n",
            "Epoch [1120], val_loss: 6326.3989\n",
            "Epoch [1140], val_loss: 6325.1973\n",
            "Epoch [1160], val_loss: 6319.1792\n",
            "Epoch [1180], val_loss: 6319.8945\n",
            "Epoch [1200], val_loss: 6323.7178\n",
            "Epoch [1220], val_loss: 6315.1904\n",
            "Epoch [1240], val_loss: 6313.7451\n",
            "Epoch [1260], val_loss: 6318.8262\n",
            "Epoch [1280], val_loss: 6317.1230\n",
            "Epoch [1300], val_loss: 6316.9048\n",
            "Epoch [1320], val_loss: 6307.6841\n",
            "Epoch [1340], val_loss: 6309.6270\n",
            "Epoch [1360], val_loss: 6312.2046\n",
            "Epoch [1380], val_loss: 6306.3740\n",
            "Epoch [1400], val_loss: 6302.4795\n",
            "Epoch [1420], val_loss: 6302.8672\n",
            "Epoch [1440], val_loss: 6305.6338\n",
            "Epoch [1460], val_loss: 6296.7705\n",
            "Epoch [1480], val_loss: 6300.8110\n",
            "Epoch [1500], val_loss: 6297.1963\n",
            "Epoch [1520], val_loss: 6300.8672\n",
            "Epoch [1540], val_loss: 6290.1465\n",
            "Epoch [1560], val_loss: 6291.8779\n",
            "Epoch [1580], val_loss: 6294.5918\n",
            "Epoch [1600], val_loss: 6289.9951\n",
            "Epoch [1620], val_loss: 6287.0352\n",
            "Epoch [1640], val_loss: 6283.9443\n",
            "Epoch [1660], val_loss: 6282.5947\n",
            "Epoch [1680], val_loss: 6282.9360\n",
            "Epoch [1700], val_loss: 6282.4121\n",
            "Epoch [1720], val_loss: 6277.6079\n",
            "Epoch [1740], val_loss: 6284.8989\n",
            "Epoch [1760], val_loss: 6278.7378\n",
            "Epoch [1780], val_loss: 6278.6865\n",
            "Epoch [1800], val_loss: 6273.1699\n",
            "Epoch [1820], val_loss: 6272.2500\n",
            "Epoch [1840], val_loss: 6270.2129\n",
            "Epoch [1860], val_loss: 6269.7842\n",
            "Epoch [1880], val_loss: 6269.1201\n",
            "Epoch [1900], val_loss: 6270.1987\n",
            "Epoch [1920], val_loss: 6263.0605\n",
            "Epoch [1940], val_loss: 6266.1909\n",
            "Epoch [1960], val_loss: 6262.3643\n",
            "Epoch [1980], val_loss: 6260.8262\n",
            "Epoch [2000], val_loss: 6261.7627\n",
            "Epoch [2020], val_loss: 6257.5728\n",
            "Epoch [2040], val_loss: 6259.9482\n",
            "Epoch [2060], val_loss: 6256.1689\n",
            "Epoch [2080], val_loss: 6252.5229\n",
            "Epoch [2100], val_loss: 6253.8086\n",
            "Epoch [2120], val_loss: 6248.9980\n",
            "Epoch [2140], val_loss: 6250.2515\n",
            "Epoch [2160], val_loss: 6250.4741\n",
            "Epoch [2180], val_loss: 6247.9609\n",
            "Epoch [2200], val_loss: 6249.6104\n",
            "Epoch [2220], val_loss: 6244.1069\n",
            "Epoch [2240], val_loss: 6245.1006\n",
            "Epoch [2260], val_loss: 6241.9746\n",
            "Epoch [2280], val_loss: 6242.6182\n",
            "Epoch [2300], val_loss: 6246.4395\n",
            "Epoch [2320], val_loss: 6242.8682\n",
            "Epoch [2340], val_loss: 6239.7334\n",
            "Epoch [2360], val_loss: 6238.3242\n",
            "Epoch [2380], val_loss: 6239.5039\n",
            "Epoch [2400], val_loss: 6236.5713\n",
            "Epoch [2420], val_loss: 6234.2544\n",
            "Epoch [2440], val_loss: 6233.5205\n",
            "Epoch [2460], val_loss: 6231.6182\n",
            "Epoch [2480], val_loss: 6230.0098\n",
            "Epoch [2500], val_loss: 6228.7227\n",
            "Epoch [2520], val_loss: 6228.4424\n",
            "Epoch [2540], val_loss: 6226.7119\n",
            "Epoch [2560], val_loss: 6225.1396\n",
            "Epoch [2580], val_loss: 6223.1738\n",
            "Epoch [2600], val_loss: 6222.1729\n",
            "Epoch [2620], val_loss: 6226.2817\n",
            "Epoch [2640], val_loss: 6221.1533\n",
            "Epoch [2660], val_loss: 6222.2690\n",
            "Epoch [2680], val_loss: 6218.4395\n",
            "Epoch [2700], val_loss: 6218.2031\n",
            "Epoch [2720], val_loss: 6216.9189\n",
            "Epoch [2740], val_loss: 6216.6426\n",
            "Epoch [2760], val_loss: 6214.7285\n",
            "Epoch [2780], val_loss: 6214.5537\n",
            "Epoch [2800], val_loss: 6212.0576\n",
            "Epoch [2820], val_loss: 6211.0420\n",
            "Epoch [2840], val_loss: 6210.2661\n",
            "Epoch [2860], val_loss: 6209.6533\n",
            "Epoch [2880], val_loss: 6208.7876\n",
            "Epoch [2900], val_loss: 6209.4639\n",
            "Epoch [2920], val_loss: 6206.6035\n",
            "Epoch [2940], val_loss: 6204.6826\n",
            "Epoch [2960], val_loss: 6204.4922\n",
            "Epoch [2980], val_loss: 6203.3584\n",
            "Epoch [3000], val_loss: 6202.2871\n",
            "Epoch [3020], val_loss: 6202.4570\n",
            "Epoch [3040], val_loss: 6200.2090\n",
            "Epoch [3060], val_loss: 6199.7520\n",
            "Epoch [3080], val_loss: 6199.3486\n",
            "Epoch [3100], val_loss: 6195.9863\n",
            "Epoch [3120], val_loss: 6196.2666\n",
            "Epoch [3140], val_loss: 6194.6357\n",
            "Epoch [3160], val_loss: 6196.4033\n",
            "Epoch [3180], val_loss: 6192.1973\n",
            "Epoch [3200], val_loss: 6191.1904\n",
            "Epoch [3220], val_loss: 6190.2100\n",
            "Epoch [3240], val_loss: 6189.2705\n",
            "Epoch [3260], val_loss: 6188.6265\n",
            "Epoch [3280], val_loss: 6187.1826\n",
            "Epoch [3300], val_loss: 6187.2119\n",
            "Epoch [3320], val_loss: 6186.3779\n",
            "Epoch [3340], val_loss: 6185.4795\n",
            "Epoch [3360], val_loss: 6184.8662\n",
            "Epoch [3380], val_loss: 6182.6992\n",
            "Epoch [3400], val_loss: 6181.7686\n",
            "Epoch [3420], val_loss: 6180.5332\n",
            "Epoch [3440], val_loss: 6179.6118\n",
            "Epoch [3460], val_loss: 6178.7075\n",
            "Epoch [3480], val_loss: 6178.0791\n",
            "Epoch [3500], val_loss: 6178.3066\n",
            "Epoch [3520], val_loss: 6176.5000\n",
            "Epoch [3540], val_loss: 6175.6792\n",
            "Epoch [3560], val_loss: 6174.3306\n",
            "Epoch [3580], val_loss: 6173.1743\n",
            "Epoch [3600], val_loss: 6172.6982\n",
            "Epoch [3620], val_loss: 6171.2656\n",
            "Epoch [3640], val_loss: 6170.6230\n",
            "Epoch [3660], val_loss: 6169.3213\n",
            "Epoch [3680], val_loss: 6168.4658\n",
            "Epoch [3700], val_loss: 6167.7280\n",
            "Epoch [3720], val_loss: 6166.7275\n",
            "Epoch [3740], val_loss: 6166.9316\n",
            "Epoch [3760], val_loss: 6165.3320\n",
            "Epoch [3780], val_loss: 6164.4512\n",
            "Epoch [3800], val_loss: 6163.6719\n",
            "Epoch [3820], val_loss: 6162.4355\n",
            "Epoch [3840], val_loss: 6161.8149\n",
            "Epoch [3860], val_loss: 6160.5835\n",
            "Epoch [3880], val_loss: 6159.6768\n",
            "Epoch [3900], val_loss: 6160.2656\n",
            "Epoch [3920], val_loss: 6158.1470\n",
            "Epoch [3940], val_loss: 6156.8701\n",
            "Epoch [3960], val_loss: 6156.0947\n",
            "Epoch [3980], val_loss: 6155.6074\n",
            "Epoch [4000], val_loss: 6154.3252\n",
            "Epoch [4020], val_loss: 6153.3438\n",
            "Epoch [4040], val_loss: 6152.6328\n",
            "Epoch [4060], val_loss: 6152.5811\n",
            "Epoch [4080], val_loss: 6150.9561\n",
            "Epoch [4100], val_loss: 6150.2446\n",
            "Epoch [4120], val_loss: 6149.0972\n",
            "Epoch [4140], val_loss: 6148.3882\n",
            "Epoch [4160], val_loss: 6148.1104\n",
            "Epoch [4180], val_loss: 6147.4707\n",
            "Epoch [4200], val_loss: 6146.1982\n",
            "Epoch [4220], val_loss: 6144.6729\n",
            "Epoch [4240], val_loss: 6144.0713\n",
            "Epoch [4260], val_loss: 6143.4126\n",
            "Epoch [4280], val_loss: 6142.1055\n",
            "Epoch [4300], val_loss: 6141.1572\n",
            "Epoch [4320], val_loss: 6140.1094\n",
            "Epoch [4340], val_loss: 6140.5156\n",
            "Epoch [4360], val_loss: 6139.0864\n",
            "Epoch [4380], val_loss: 6137.8433\n",
            "Epoch [4400], val_loss: 6136.8438\n",
            "Epoch [4420], val_loss: 6136.5166\n",
            "Epoch [4440], val_loss: 6135.1553\n",
            "Epoch [4460], val_loss: 6134.7832\n",
            "Epoch [4480], val_loss: 6134.6973\n",
            "Epoch [4500], val_loss: 6132.4482\n",
            "Epoch [4520], val_loss: 6131.6904\n",
            "Epoch [4540], val_loss: 6130.9658\n",
            "Epoch [4560], val_loss: 6129.8867\n",
            "Epoch [4580], val_loss: 6129.2402\n",
            "Epoch [4600], val_loss: 6129.8120\n",
            "Epoch [4620], val_loss: 6127.7109\n",
            "Epoch [4640], val_loss: 6128.4473\n",
            "Epoch [4660], val_loss: 6125.6416\n",
            "Epoch [4680], val_loss: 6124.9004\n",
            "Epoch [4700], val_loss: 6124.3281\n",
            "Epoch [4720], val_loss: 6123.1123\n",
            "Epoch [4740], val_loss: 6122.3154\n",
            "Epoch [4760], val_loss: 6123.2930\n",
            "Epoch [4780], val_loss: 6120.8228\n",
            "Epoch [4800], val_loss: 6120.3594\n",
            "Epoch [4820], val_loss: 6119.5615\n",
            "Epoch [4840], val_loss: 6118.8091\n",
            "Epoch [4860], val_loss: 6117.7715\n",
            "Epoch [4880], val_loss: 6116.5801\n",
            "Epoch [4900], val_loss: 6115.7578\n",
            "Epoch [4920], val_loss: 6114.9961\n",
            "Epoch [4940], val_loss: 6114.1035\n",
            "Epoch [4960], val_loss: 6113.2939\n",
            "Epoch [4980], val_loss: 6112.4844\n",
            "Epoch [5000], val_loss: 6112.3525\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiUKuC45RaqK",
        "colab_type": "text"
      },
      "source": [
        "## (Optional) Step 6: Try another dataset & blog about it\n",
        "\n",
        "While this last step is optional for the submission of your assignment, we highly recommend that you do it. Try to clean up & replicate this notebook (or [this one](https://jovian.ml/aakashns/housing-linear-minimal), or [this one](https://jovian.ml/aakashns/mnist-logistic-minimal) ) for a different linear regression or logistic regression problem. This will help solidify your understanding, and give you a chance to differentiate the generic patters in machine learning from problem-specific details.\n",
        "\n",
        "Here are some sources to find good datasets:\n",
        "\n",
        "- https://lionbridge.ai/datasets/10-open-datasets-for-linear-regression/\n",
        "- https://www.kaggle.com/rtatman/datasets-for-regression-analysis\n",
        "- https://archive.ics.uci.edu/ml/datasets.php?format=&task=reg&att=&area=&numAtt=&numIns=&type=&sort=nameUp&view=table\n",
        "- https://people.sc.fsu.edu/~jburkardt/datasets/regression/regression.html\n",
        "- https://archive.ics.uci.edu/ml/datasets/wine+quality\n",
        "- https://pytorch.org/docs/stable/torchvision/datasets.html\n",
        "\n",
        "We also recommend that you write a blog about your approach to the problem. Here is a suggested structure for your post (feel free to experiment with it):\n",
        "\n",
        "- Interesting title & subtitle\n",
        "- Overview of what the blog covers (which dataset, linear regression or logistic regression, intro to PyTorch)\n",
        "- Downloading & exploring the data\n",
        "- Preparing the data for training\n",
        "- Creating a model using PyTorch\n",
        "- Training the model to fit the data\n",
        "- Your thoughts on how to experiment with different hyperparmeters to reduce loss\n",
        "- Making predictions using the model\n",
        "\n",
        "As with the previous assignment, you can [embed Juptyer notebook cells & outputs from Jovian](https://medium.com/jovianml/share-and-embed-jupyter-notebooks-online-with-jovian-ml-df709a03064e) into your blog. \n",
        "\n",
        "Don't forget to share your work on the forum: https://jovian.ml/forum/t/share-your-work-here-assignment-2/4931"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vynX-FpkLtq",
        "colab_type": "text"
      },
      "source": [
        "### Life Expectancy (WHO) ###\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwA4m_YCkmIk",
        "colab_type": "text"
      },
      "source": [
        "Here the idea is to predict the life expectancy. The dataset is obtained from https://www.kaggle.com/kumarajarshi/life-expectancy-who?select=Life+Expectancy+Data.csv "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDvbSh-4lAEn",
        "colab_type": "text"
      },
      "source": [
        "1. Read the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLq0VhNgRaqM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "63bb7f57-5be8-4b96-a046-9acdcc19a921"
      },
      "source": [
        "df = pd.read_csv('Life_Expectancy_Data.csv')\n",
        "df.head()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Country</th>\n",
              "      <th>Year</th>\n",
              "      <th>Status</th>\n",
              "      <th>Life expectancy</th>\n",
              "      <th>Adult Mortality</th>\n",
              "      <th>infant deaths</th>\n",
              "      <th>Alcohol</th>\n",
              "      <th>percentage expenditure</th>\n",
              "      <th>Hepatitis B</th>\n",
              "      <th>Measles</th>\n",
              "      <th>BMI</th>\n",
              "      <th>under-five deaths</th>\n",
              "      <th>Polio</th>\n",
              "      <th>Total expenditure</th>\n",
              "      <th>Diphtheria</th>\n",
              "      <th>HIV/AIDS</th>\n",
              "      <th>GDP</th>\n",
              "      <th>Population</th>\n",
              "      <th>thinness  1-19 years</th>\n",
              "      <th>thinness 5-9 years</th>\n",
              "      <th>Income composition of resources</th>\n",
              "      <th>Schooling</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>2015</td>\n",
              "      <td>Developing</td>\n",
              "      <td>65.0</td>\n",
              "      <td>263.0</td>\n",
              "      <td>62</td>\n",
              "      <td>0.01</td>\n",
              "      <td>71.279624</td>\n",
              "      <td>65.0</td>\n",
              "      <td>1154</td>\n",
              "      <td>19.1</td>\n",
              "      <td>83</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.16</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>584.259210</td>\n",
              "      <td>33736494.0</td>\n",
              "      <td>17.2</td>\n",
              "      <td>17.3</td>\n",
              "      <td>0.479</td>\n",
              "      <td>10.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>2014</td>\n",
              "      <td>Developing</td>\n",
              "      <td>59.9</td>\n",
              "      <td>271.0</td>\n",
              "      <td>64</td>\n",
              "      <td>0.01</td>\n",
              "      <td>73.523582</td>\n",
              "      <td>62.0</td>\n",
              "      <td>492</td>\n",
              "      <td>18.6</td>\n",
              "      <td>86</td>\n",
              "      <td>58.0</td>\n",
              "      <td>8.18</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>612.696514</td>\n",
              "      <td>327582.0</td>\n",
              "      <td>17.5</td>\n",
              "      <td>17.5</td>\n",
              "      <td>0.476</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>2013</td>\n",
              "      <td>Developing</td>\n",
              "      <td>59.9</td>\n",
              "      <td>268.0</td>\n",
              "      <td>66</td>\n",
              "      <td>0.01</td>\n",
              "      <td>73.219243</td>\n",
              "      <td>64.0</td>\n",
              "      <td>430</td>\n",
              "      <td>18.1</td>\n",
              "      <td>89</td>\n",
              "      <td>62.0</td>\n",
              "      <td>8.13</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>631.744976</td>\n",
              "      <td>31731688.0</td>\n",
              "      <td>17.7</td>\n",
              "      <td>17.7</td>\n",
              "      <td>0.470</td>\n",
              "      <td>9.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>2012</td>\n",
              "      <td>Developing</td>\n",
              "      <td>59.5</td>\n",
              "      <td>272.0</td>\n",
              "      <td>69</td>\n",
              "      <td>0.01</td>\n",
              "      <td>78.184215</td>\n",
              "      <td>67.0</td>\n",
              "      <td>2787</td>\n",
              "      <td>17.6</td>\n",
              "      <td>93</td>\n",
              "      <td>67.0</td>\n",
              "      <td>8.52</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>669.959000</td>\n",
              "      <td>3696958.0</td>\n",
              "      <td>17.9</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.463</td>\n",
              "      <td>9.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>2011</td>\n",
              "      <td>Developing</td>\n",
              "      <td>59.2</td>\n",
              "      <td>275.0</td>\n",
              "      <td>71</td>\n",
              "      <td>0.01</td>\n",
              "      <td>7.097109</td>\n",
              "      <td>68.0</td>\n",
              "      <td>3013</td>\n",
              "      <td>17.2</td>\n",
              "      <td>97</td>\n",
              "      <td>68.0</td>\n",
              "      <td>7.87</td>\n",
              "      <td>68.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>63.537231</td>\n",
              "      <td>2978599.0</td>\n",
              "      <td>18.2</td>\n",
              "      <td>18.2</td>\n",
              "      <td>0.454</td>\n",
              "      <td>9.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Country  Year  ... Income composition of resources  Schooling\n",
              "0  Afghanistan  2015  ...                           0.479       10.1\n",
              "1  Afghanistan  2014  ...                           0.476       10.0\n",
              "2  Afghanistan  2013  ...                           0.470        9.9\n",
              "3  Afghanistan  2012  ...                           0.463        9.8\n",
              "4  Afghanistan  2011  ...                           0.454        9.5\n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o13ZrQmXEvTS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "32993236-bf8d-4557-f730-2c5a5c9b5682"
      },
      "source": [
        "df.shape[0], df.shape[1]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2938, 22)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdhSzbJYGDaL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "20d0f76c-7c02-46ff-a78f-e3adaee8d1ab"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Country', 'Year', 'Status', 'Life expectancy ', 'Adult Mortality',\n",
              "       'infant deaths', 'Alcohol', 'percentage expenditure', 'Hepatitis B',\n",
              "       'Measles ', ' BMI ', 'under-five deaths ', 'Polio', 'Total expenditure',\n",
              "       'Diphtheria ', ' HIV/AIDS', 'GDP', 'Population',\n",
              "       ' thinness  1-19 years', ' thinness 5-9 years',\n",
              "       'Income composition of resources', 'Schooling'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXH0GKzJlIP4",
        "colab_type": "text"
      },
      "source": [
        "2. Define the input columns of the model, the categorical columns and the output column. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNkOQJdGZzRP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "66d06a6a-7c54-4511-81b1-adfcd2e08895"
      },
      "source": [
        "df_drop = df.drop(['Life expectancy '], axis=1) \n",
        "input_cols = df_drop.columns\n",
        "\n",
        "df['Life_expectancy'] = df['Life expectancy '] \n",
        "df = df.drop(['Life expectancy '], axis=1)\n",
        "\n",
        "categorical_cols = ['Country', 'Status']\n",
        "\n",
        "output_cols = ['Life_expectancy']"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['Country', 'Year', 'Status', 'Adult Mortality', 'infant deaths',\n",
            "       'Alcohol', 'percentage expenditure', 'Hepatitis B', 'Measles ', ' BMI ',\n",
            "       'under-five deaths ', 'Polio', 'Total expenditure', 'Diphtheria ',\n",
            "       ' HIV/AIDS', 'GDP', 'Population', ' thinness  1-19 years',\n",
            "       ' thinness 5-9 years', 'Income composition of resources', 'Schooling'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgnaseWhRc_m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "0f594636-b255-4105-faac-bbe056c0f698"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Country</th>\n",
              "      <th>Year</th>\n",
              "      <th>Status</th>\n",
              "      <th>Adult Mortality</th>\n",
              "      <th>infant deaths</th>\n",
              "      <th>Alcohol</th>\n",
              "      <th>percentage expenditure</th>\n",
              "      <th>Hepatitis B</th>\n",
              "      <th>Measles</th>\n",
              "      <th>BMI</th>\n",
              "      <th>under-five deaths</th>\n",
              "      <th>Polio</th>\n",
              "      <th>Total expenditure</th>\n",
              "      <th>Diphtheria</th>\n",
              "      <th>HIV/AIDS</th>\n",
              "      <th>GDP</th>\n",
              "      <th>Population</th>\n",
              "      <th>thinness  1-19 years</th>\n",
              "      <th>thinness 5-9 years</th>\n",
              "      <th>Income composition of resources</th>\n",
              "      <th>Schooling</th>\n",
              "      <th>Life_expectancy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>2015</td>\n",
              "      <td>Developing</td>\n",
              "      <td>263.0</td>\n",
              "      <td>62</td>\n",
              "      <td>0.01</td>\n",
              "      <td>71.279624</td>\n",
              "      <td>65.0</td>\n",
              "      <td>1154</td>\n",
              "      <td>19.1</td>\n",
              "      <td>83</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.16</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>584.259210</td>\n",
              "      <td>33736494.0</td>\n",
              "      <td>17.2</td>\n",
              "      <td>17.3</td>\n",
              "      <td>0.479</td>\n",
              "      <td>10.1</td>\n",
              "      <td>65.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>2014</td>\n",
              "      <td>Developing</td>\n",
              "      <td>271.0</td>\n",
              "      <td>64</td>\n",
              "      <td>0.01</td>\n",
              "      <td>73.523582</td>\n",
              "      <td>62.0</td>\n",
              "      <td>492</td>\n",
              "      <td>18.6</td>\n",
              "      <td>86</td>\n",
              "      <td>58.0</td>\n",
              "      <td>8.18</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>612.696514</td>\n",
              "      <td>327582.0</td>\n",
              "      <td>17.5</td>\n",
              "      <td>17.5</td>\n",
              "      <td>0.476</td>\n",
              "      <td>10.0</td>\n",
              "      <td>59.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>2013</td>\n",
              "      <td>Developing</td>\n",
              "      <td>268.0</td>\n",
              "      <td>66</td>\n",
              "      <td>0.01</td>\n",
              "      <td>73.219243</td>\n",
              "      <td>64.0</td>\n",
              "      <td>430</td>\n",
              "      <td>18.1</td>\n",
              "      <td>89</td>\n",
              "      <td>62.0</td>\n",
              "      <td>8.13</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>631.744976</td>\n",
              "      <td>31731688.0</td>\n",
              "      <td>17.7</td>\n",
              "      <td>17.7</td>\n",
              "      <td>0.470</td>\n",
              "      <td>9.9</td>\n",
              "      <td>59.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>2012</td>\n",
              "      <td>Developing</td>\n",
              "      <td>272.0</td>\n",
              "      <td>69</td>\n",
              "      <td>0.01</td>\n",
              "      <td>78.184215</td>\n",
              "      <td>67.0</td>\n",
              "      <td>2787</td>\n",
              "      <td>17.6</td>\n",
              "      <td>93</td>\n",
              "      <td>67.0</td>\n",
              "      <td>8.52</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>669.959000</td>\n",
              "      <td>3696958.0</td>\n",
              "      <td>17.9</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.463</td>\n",
              "      <td>9.8</td>\n",
              "      <td>59.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>2011</td>\n",
              "      <td>Developing</td>\n",
              "      <td>275.0</td>\n",
              "      <td>71</td>\n",
              "      <td>0.01</td>\n",
              "      <td>7.097109</td>\n",
              "      <td>68.0</td>\n",
              "      <td>3013</td>\n",
              "      <td>17.2</td>\n",
              "      <td>97</td>\n",
              "      <td>68.0</td>\n",
              "      <td>7.87</td>\n",
              "      <td>68.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>63.537231</td>\n",
              "      <td>2978599.0</td>\n",
              "      <td>18.2</td>\n",
              "      <td>18.2</td>\n",
              "      <td>0.454</td>\n",
              "      <td>9.5</td>\n",
              "      <td>59.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Country  Year  ... Schooling  Life_expectancy\n",
              "0  Afghanistan  2015  ...      10.1             65.0\n",
              "1  Afghanistan  2014  ...      10.0             59.9\n",
              "2  Afghanistan  2013  ...       9.9             59.9\n",
              "3  Afghanistan  2012  ...       9.8             59.5\n",
              "4  Afghanistan  2011  ...       9.5             59.2\n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caIvyxX-lWqo",
        "colab_type": "text"
      },
      "source": [
        "3. Distribution of the output. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZNm3FS7Fgvh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "9db0caee-e621-4744-e07c-1a87b402246f"
      },
      "source": [
        "min = df['Life_expectancy'].min()\n",
        "max = df['Life_expectancy'].max()\n",
        "mean = df['Life_expectancy'].mean()\n",
        "print('minimum: ', min, 'maximum: ', max, 'average: ', mean)\n",
        "sns.distplot(df.Life_expectancy)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "minimum:  36.3 maximum:  89.0 average:  69.22493169398912\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fad51773780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcB0Khfblf9H",
        "colab_type": "text"
      },
      "source": [
        "4. Check nan's in the dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EBXg3R8OOZZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "d326ee88-455d-435f-d4ba-d4bea1d01405"
      },
      "source": [
        "for i in df.columns: \n",
        "  print(i, df[i].isna().sum())"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Country 0\n",
            "Year 0\n",
            "Status 0\n",
            "Adult Mortality 10\n",
            "infant deaths 0\n",
            "Alcohol 194\n",
            "percentage expenditure 0\n",
            "Hepatitis B 553\n",
            "Measles  0\n",
            " BMI  34\n",
            "under-five deaths  0\n",
            "Polio 19\n",
            "Total expenditure 226\n",
            "Diphtheria  19\n",
            " HIV/AIDS 0\n",
            "GDP 448\n",
            "Population 652\n",
            " thinness  1-19 years 34\n",
            " thinness 5-9 years 34\n",
            "Income composition of resources 167\n",
            "Schooling 163\n",
            "Life_expectancy 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyisG-zhlktP",
        "colab_type": "text"
      },
      "source": [
        "5. Drop rows which have nan in the output column and those input columns with > 400 nan's. For the rest just use the mean of the column and fill nan's. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDMTMG5DUpyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.drop(index=df[df['Life_expectancy'].isnull()].index)\n",
        "df['Adult Mortality'].fillna((df['Adult Mortality'].mean()), inplace=True)\n",
        "df['Alcohol'].fillna((df['Alcohol'].mean()), inplace=True)\n",
        "df[' BMI '].fillna((df[' BMI '].mean()), inplace=True)\n",
        "df['Polio'].fillna((df['Polio'].mean()), inplace=True)\n",
        "df['Total expenditure'].fillna((df['Total expenditure'].mean()), inplace=True)\n",
        "df['Diphtheria '].fillna((df['Diphtheria '].mean()), inplace=True)\n",
        "df[' thinness  1-19 years'].fillna((df[' thinness  1-19 years'].mean()), inplace=True)\n",
        "df[' thinness 5-9 years'].fillna((df[' thinness 5-9 years'].mean()), inplace=True)\n",
        "df['Income composition of resources'].fillna((df['Income composition of resources'].mean()), inplace=True)\n",
        "df['Schooling'].fillna((df['Schooling'].mean()), inplace=True)\n",
        "df = df.drop(columns='Hepatitis B')\n",
        "df = df.drop(columns='GDP')\n",
        "df = df.drop(columns='Population')"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gisQUWG1l7xf",
        "colab_type": "text"
      },
      "source": [
        "6. Check nan's again. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sabqhf9UJy3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "28eedfda-a6ae-45c0-d7cc-49abe35cce88"
      },
      "source": [
        "for i in df.columns: \n",
        "  print(i, df[i].isna().sum())"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Country 0\n",
            "Year 0\n",
            "Status 0\n",
            "Adult Mortality 0\n",
            "infant deaths 0\n",
            "Alcohol 0\n",
            "percentage expenditure 0\n",
            "Measles  0\n",
            " BMI  0\n",
            "under-five deaths  0\n",
            "Polio 0\n",
            "Total expenditure 0\n",
            "Diphtheria  0\n",
            " HIV/AIDS 0\n",
            " thinness  1-19 years 0\n",
            " thinness 5-9 years 0\n",
            "Income composition of resources 0\n",
            "Schooling 0\n",
            "Life_expectancy 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KL4N_3hme5g",
        "colab_type": "text"
      },
      "source": [
        "7. Re-define input columns. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P69yLwBEZpzA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_drop = df.drop(['Life_expectancy'], axis=1) \n",
        "input_cols = df_drop.columns"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2irSPlRRmtjj",
        "colab_type": "text"
      },
      "source": [
        "8. Function to convert non-numeric categorical columns to numbers and convert input and target arrays to numpy. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA5Tv9zuG3-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def df_to_arrays(df):\n",
        "    # Make a copy of the original dataframe\n",
        "    df1 = df.copy(deep=True)\n",
        "    # Convert non-numeric categorical columns to numbers\n",
        "    for col in categorical_cols:\n",
        "      df1[col] = df1[col].astype('category').cat.codes\n",
        "\n",
        "    # Extract input & outupts as numpy arrays\n",
        "    inputs_array = df1[input_cols].to_numpy()\n",
        "    targets_array = df1[output_cols].to_numpy()\n",
        "    return inputs_array, targets_array"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suLCnSuMHC5C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6f83ee82-35fa-4c17-f077-b8b62058a661"
      },
      "source": [
        "inputs_array, targets_array = df_to_arrays(df)\n",
        "inputs_array.shape, targets_array.shape"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2928, 18), (2928, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQHmTHXonCAU",
        "colab_type": "text"
      },
      "source": [
        "9. Re-convert them to pytorch tensors (float32 type)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-h03LbLI9ba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = torch.from_numpy(inputs_array).to(dtype=torch.float32) \n",
        "targets = torch.from_numpy(targets_array).to(dtype=torch.float32) "
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFMuFqwsJ6TH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = TensorDataset(inputs, targets)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AX7sM24nTIa",
        "colab_type": "text"
      },
      "source": [
        "10. Split the dataset into training and validation dataset with a % between 10 and 20 for the validation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbHuDGOZLoRI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_percent =  random.uniform(0.1,0.2)# between 0.1 and 0.2\n",
        "num_rows = inputs_array.shape[0]\n",
        "val_size = int(num_rows * val_percent)\n",
        "train_size = num_rows - val_size\n",
        "\n",
        "\n",
        "train_ds, val_ds =  random_split(dataset, [train_size, val_size])# Use the random_split function to split dataset into 2 parts of the desired length"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wqGwd_6nmAn",
        "colab_type": "text"
      },
      "source": [
        "11. Create the dataloader for both cases and define the batch size. Then, check it works. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZs20zXNMEsx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4RZWvozMNuk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7ce13b58-2f22-469c-93e9-7e67dc56fabe"
      },
      "source": [
        "for xb, yb in train_loader:\n",
        "    print(\"inputs:\", xb)\n",
        "    print(\"targets:\", yb)\n",
        "    break"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inputs: tensor([[8.5000e+01, 2.0100e+03, 1.0000e+00,  ..., 8.0000e+00, 5.2300e-01,\n",
            "         1.1100e+01],\n",
            "        [5.7000e+01, 2.0080e+03, 1.0000e+00,  ..., 8.0000e-01, 8.7600e-01,\n",
            "         1.7100e+01],\n",
            "        [9.5000e+01, 2.0000e+03, 0.0000e+00,  ..., 3.4000e+00, 7.4500e-01,\n",
            "         1.4000e+01],\n",
            "        ...,\n",
            "        [1.0400e+02, 2.0030e+03, 1.0000e+00,  ..., 7.8000e+00, 6.8700e-01,\n",
            "         1.2600e+01],\n",
            "        [9.5000e+01, 2.0040e+03, 0.0000e+00,  ..., 3.1000e+00, 7.9200e-01,\n",
            "         1.6300e+01],\n",
            "        [2.1000e+01, 2.0030e+03, 1.0000e+00,  ..., 1.8000e+00, 5.6700e-01,\n",
            "         1.1800e+01]])\n",
            "targets: tensor([[63.0000],\n",
            "        [79.6000],\n",
            "        [71.6000],\n",
            "        [57.9000],\n",
            "        [75.0000],\n",
            "        [78.0000],\n",
            "        [83.0000],\n",
            "        [45.3000],\n",
            "        [73.6000],\n",
            "        [45.7000],\n",
            "        [74.6000],\n",
            "        [51.9000],\n",
            "        [65.0000],\n",
            "        [72.9000],\n",
            "        [79.7000],\n",
            "        [79.7000],\n",
            "        [74.2000],\n",
            "        [74.0000],\n",
            "        [47.8000],\n",
            "        [54.9000],\n",
            "        [76.1000],\n",
            "        [48.5000],\n",
            "        [72.7000],\n",
            "        [74.6000],\n",
            "        [75.3000],\n",
            "        [49.6000],\n",
            "        [64.0000],\n",
            "        [67.5000],\n",
            "        [84.0000],\n",
            "        [77.6000],\n",
            "        [58.1000],\n",
            "        [75.3000],\n",
            "        [76.8000],\n",
            "        [44.5000],\n",
            "        [72.8000],\n",
            "        [74.5000],\n",
            "        [45.4000],\n",
            "        [81.1000],\n",
            "        [49.2000],\n",
            "        [67.8000],\n",
            "        [51.4000],\n",
            "        [71.1000],\n",
            "        [79.0000],\n",
            "        [65.6000],\n",
            "        [53.4000],\n",
            "        [51.1000],\n",
            "        [71.5000],\n",
            "        [82.0000],\n",
            "        [57.6000],\n",
            "        [76.6000],\n",
            "        [56.9000],\n",
            "        [72.6000],\n",
            "        [73.8000],\n",
            "        [76.9000],\n",
            "        [77.0000],\n",
            "        [63.8000],\n",
            "        [59.4000],\n",
            "        [64.7000],\n",
            "        [75.0000],\n",
            "        [76.9000],\n",
            "        [78.2000],\n",
            "        [51.2000],\n",
            "        [73.8000],\n",
            "        [78.8000],\n",
            "        [75.0000],\n",
            "        [71.2000],\n",
            "        [53.1000],\n",
            "        [66.8000],\n",
            "        [69.0000],\n",
            "        [75.5000],\n",
            "        [51.0000],\n",
            "        [56.9000],\n",
            "        [84.0000],\n",
            "        [86.0000],\n",
            "        [74.9000],\n",
            "        [74.7000],\n",
            "        [67.6000],\n",
            "        [79.9000],\n",
            "        [76.5000],\n",
            "        [78.4000],\n",
            "        [45.1000],\n",
            "        [79.1000],\n",
            "        [64.6000],\n",
            "        [64.5000],\n",
            "        [78.3000],\n",
            "        [74.6000],\n",
            "        [52.2000],\n",
            "        [67.1000],\n",
            "        [74.5000],\n",
            "        [65.2000],\n",
            "        [67.3000],\n",
            "        [68.3000],\n",
            "        [55.3000],\n",
            "        [53.1000],\n",
            "        [52.1000],\n",
            "        [65.4000],\n",
            "        [79.7000],\n",
            "        [67.9000],\n",
            "        [46.5000],\n",
            "        [52.2000],\n",
            "        [81.1000],\n",
            "        [82.0000],\n",
            "        [69.4000],\n",
            "        [71.5000],\n",
            "        [68.0000],\n",
            "        [75.7000],\n",
            "        [74.7000],\n",
            "        [72.4000],\n",
            "        [79.7000],\n",
            "        [77.8000],\n",
            "        [57.5000],\n",
            "        [81.8000],\n",
            "        [66.1000],\n",
            "        [52.5000],\n",
            "        [60.0000],\n",
            "        [53.7000],\n",
            "        [78.0000],\n",
            "        [73.3000],\n",
            "        [75.6000],\n",
            "        [69.8000],\n",
            "        [71.2000],\n",
            "        [65.5000],\n",
            "        [73.1000],\n",
            "        [75.4000],\n",
            "        [77.8000],\n",
            "        [71.5000],\n",
            "        [71.6000],\n",
            "        [46.4000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgumCh1kMUTW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "30bd2ba0-61cc-406b-8a95-af1441811015"
      },
      "source": [
        "input_size = len(input_cols)\n",
        "output_size = len(output_cols)\n",
        "input_size, output_size"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfIIAGq5n1O_",
        "colab_type": "text"
      },
      "source": [
        "12. Define the linear model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IglYN_DMMeo3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ExpectancyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(input_size, output_size)                   # fill this (hint: use input_size & output_size defined above)\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        out = self.linear(xb)                          # fill this\n",
        "        return out\n",
        "    \n",
        "    def training_step(self, batch):\n",
        "        inputs, targets = batch \n",
        "        # Generate predictions\n",
        "        out = self(inputs) \n",
        "        # Calculate loss\n",
        "        loss = F.l1_loss(out, targets)                          # fill this\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        inputs, targets = batch\n",
        "        # Generate predictions\n",
        "        out = self(inputs)\n",
        "        # Calculate loss\n",
        "        loss = F.l1_loss(out, targets)                          # fill this    \n",
        "        return {'val_loss': loss.detach()}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        return {'val_loss': epoch_loss.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result, num_epochs):\n",
        "        # Print result every 20th epoch\n",
        "        if (epoch+1) % 20 == 0 or epoch == num_epochs-1:\n",
        "            print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch+1, result['val_loss']))"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxlOKDk9Np2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = ExpectancyModel()"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ny5in_wnn9wk",
        "colab_type": "text"
      },
      "source": [
        "13. Evaluate the model before training. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RbHLB1FNnVQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5cd625f2-9b5a-41a3-e4d9-5574badd8e85"
      },
      "source": [
        "result = evaluate(model, val_loader) # Use the the evaluate function\n",
        "print(result)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'val_loss': 736.3666381835938}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dILZaEXoECM",
        "colab_type": "text"
      },
      "source": [
        "14. Train the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SwGaP25Mp7S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        },
        "outputId": "73930e4e-c0ed-4600-87c6-55e9f3563684"
      },
      "source": [
        "model = ExpectancyModel()\n",
        "epochs = 1000\n",
        "lr = 0.0000001\n",
        "history = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 329.4610\n",
            "Epoch [40], val_loss: 158.2326\n",
            "Epoch [60], val_loss: 105.0468\n",
            "Epoch [80], val_loss: 84.8400\n",
            "Epoch [100], val_loss: 65.2594\n",
            "Epoch [120], val_loss: 46.2192\n",
            "Epoch [140], val_loss: 28.0253\n",
            "Epoch [160], val_loss: 14.9716\n",
            "Epoch [180], val_loss: 14.5242\n",
            "Epoch [200], val_loss: 14.4181\n",
            "Epoch [220], val_loss: 14.6298\n",
            "Epoch [240], val_loss: 14.0649\n",
            "Epoch [260], val_loss: 14.3441\n",
            "Epoch [280], val_loss: 13.8906\n",
            "Epoch [300], val_loss: 13.9233\n",
            "Epoch [320], val_loss: 13.9180\n",
            "Epoch [340], val_loss: 13.7217\n",
            "Epoch [360], val_loss: 13.5514\n",
            "Epoch [380], val_loss: 13.4493\n",
            "Epoch [400], val_loss: 13.3004\n",
            "Epoch [420], val_loss: 13.2723\n",
            "Epoch [440], val_loss: 13.1312\n",
            "Epoch [460], val_loss: 13.1242\n",
            "Epoch [480], val_loss: 13.2045\n",
            "Epoch [500], val_loss: 13.0162\n",
            "Epoch [520], val_loss: 13.0680\n",
            "Epoch [540], val_loss: 12.8933\n",
            "Epoch [560], val_loss: 12.9038\n",
            "Epoch [580], val_loss: 12.6997\n",
            "Epoch [600], val_loss: 12.6465\n",
            "Epoch [620], val_loss: 12.3626\n",
            "Epoch [640], val_loss: 12.2922\n",
            "Epoch [660], val_loss: 12.2544\n",
            "Epoch [680], val_loss: 12.0744\n",
            "Epoch [700], val_loss: 12.0175\n",
            "Epoch [720], val_loss: 12.0961\n",
            "Epoch [740], val_loss: 11.8289\n",
            "Epoch [760], val_loss: 12.0448\n",
            "Epoch [780], val_loss: 11.9915\n",
            "Epoch [800], val_loss: 12.0822\n",
            "Epoch [820], val_loss: 11.7067\n",
            "Epoch [840], val_loss: 11.7071\n",
            "Epoch [860], val_loss: 11.6596\n",
            "Epoch [880], val_loss: 11.4485\n",
            "Epoch [900], val_loss: 11.2069\n",
            "Epoch [920], val_loss: 11.2188\n",
            "Epoch [940], val_loss: 11.0679\n",
            "Epoch [960], val_loss: 10.9558\n",
            "Epoch [980], val_loss: 11.1462\n",
            "Epoch [1000], val_loss: 10.8719\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vi5l-ulJM3jl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "ab2304e9-8df6-478b-bfbb-891536524820"
      },
      "source": [
        "loss = [result['val_loss'] for result in history]\n",
        "plt.plot(loss)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('l1 loss')\n",
        "plt.title('Validation loss vs. No. of epochs');"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9fE-d3erMBz",
        "colab_type": "text"
      },
      "source": [
        "15. Final predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWPAA9kgslsr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_single(input, target, model):\n",
        "    inputs = input.unsqueeze(0)\n",
        "    predictions = model(inputs)                # fill this\n",
        "    prediction = predictions[0].detach()\n",
        "    print(\"Input:\", input)\n",
        "    print(\"Target:\", target)\n",
        "    print(\"Prediction:\", prediction)\n",
        "    return prediction"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcLxb_3ErQEV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1b32d980-2339-42e3-de72-f5712c4c0ada"
      },
      "source": [
        "predictions = []\n",
        "for i in range (len(val_ds)):\n",
        "  input, target = val_ds[i]\n",
        "  predictions.append(predict_single(input, target, model1))"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: tensor([1.7600e+02, 2.0030e+03, 1.0000e+00, 1.8300e+02, 2.5000e+01, 1.5400e+00,\n",
            "        2.8521e+01, 8.5000e+01, 3.6400e+01, 3.0000e+01, 9.9000e+01, 5.1700e+00,\n",
            "        9.8000e+01, 3.0000e-01, 3.3000e+00, 3.3000e+00, 6.0700e-01, 1.1300e+01])\n",
            "Target: tensor([67.2000])\n",
            "Prediction: tensor([79.3290])\n",
            "Input: tensor([7.6000e+01, 2.0110e+03, 1.0000e+00, 9.3000e+01, 2.2000e+01, 3.0000e-02,\n",
            "        0.0000e+00, 7.3000e+01, 5.4800e+01, 2.5000e+01, 9.9000e+01, 7.1200e+00,\n",
            "        9.9000e+01, 1.0000e-01, 7.9000e+00, 8.1000e+00, 7.4500e-01, 1.3100e+01])\n",
            "Target: tensor([74.7000])\n",
            "Prediction: tensor([74.3889])\n",
            "Input: tensor([1.5000e+02, 2.0110e+03, 1.0000e+00, 3.5500e+02, 2.7000e+01, 4.6149e+00,\n",
            "        0.0000e+00, 1.2560e+03, 3.8235e+01, 4.1000e+01, 6.6000e+01, 5.9302e+00,\n",
            "        6.1000e+01, 3.9000e+00, 4.8506e+00, 4.8814e+00, 4.2900e-01, 4.9000e+00])\n",
            "Target: tensor([55.4000])\n",
            "Prediction: tensor([67.4918])\n",
            "Input: tensor([8.5000e+01, 2.0040e+03, 1.0000e+00, 4.3200e+02, 7.2000e+01, 1.4300e+00,\n",
            "        3.6298e+01, 2.0000e+01, 1.5900e+01, 1.1200e+02, 7.3000e+01, 4.2900e+00,\n",
            "        7.3000e+01, 1.3200e+01, 8.7000e+00, 8.6000e+00, 4.6100e-01, 8.9000e+00])\n",
            "Target: tensor([53.])\n",
            "Prediction: tensor([56.9238])\n",
            "Input: tensor([1.0000e+01, 2.0060e+03, 1.0000e+00, 1.7100e+02, 0.0000e+00, 1.1070e+01,\n",
            "        0.0000e+00, 0.0000e+00, 5.8700e+01, 0.0000e+00, 9.4000e+01, 6.9300e+00,\n",
            "        9.5000e+01, 1.0000e-01, 2.5000e+00, 2.5000e+00, 7.8800e-01, 1.2400e+01])\n",
            "Target: tensor([74.2000])\n",
            "Prediction: tensor([59.7793])\n",
            "Input: tensor([5.4000e+01, 2.0120e+03, 1.0000e+00, 1.3500e+02, 0.0000e+00, 1.0000e-02,\n",
            "        2.2631e+03, 4.0000e+00, 5.8500e+01, 0.0000e+00, 9.4000e+01, 6.3600e+00,\n",
            "        9.4000e+01, 1.0000e-01, 1.9000e+00, 1.9000e+00, 8.5000e-01, 1.6500e+01])\n",
            "Target: tensor([76.3000])\n",
            "Prediction: tensor([67.6892])\n",
            "Input: tensor([1.5200e+02, 2.0120e+03, 1.0000e+00, 1.4300e+02, 3.0000e+00, 2.8000e+00,\n",
            "        2.0769e+01, 5.1000e+01, 2.1200e+01, 4.0000e+00, 9.9000e+01, 3.2100e+00,\n",
            "        9.9000e+01, 1.0000e-01, 1.5300e+01, 1.5200e+01, 7.5200e-01, 1.3700e+01])\n",
            "Target: tensor([74.5000])\n",
            "Prediction: tensor([69.7010])\n",
            "Input: tensor([6.9000e+01, 2.0110e+03, 1.0000e+00, 2.2900e+02, 0.0000e+00, 7.5600e+00,\n",
            "        5.3623e+02, 0.0000e+00, 4.3200e+01, 1.0000e+00, 9.3000e+01, 6.8000e+00,\n",
            "        9.3000e+01, 4.0000e-01, 5.6000e+00, 5.3000e+00, 6.2400e-01, 1.0300e+01])\n",
            "Target: tensor([65.6000])\n",
            "Prediction: tensor([60.1778])\n",
            "Input: tensor([3.5000e+01, 2.0100e+03, 1.0000e+00, 1.5000e+01, 1.2000e+01, 4.2800e+00,\n",
            "        1.1324e+02, 0.0000e+00, 5.4200e+01, 1.5000e+01, 8.8000e+01, 6.7600e+00,\n",
            "        8.8000e+01, 1.0000e-01, 2.2000e+00, 2.0000e+00, 6.9500e-01, 1.2800e+01])\n",
            "Target: tensor([73.6000])\n",
            "Prediction: tensor([75.5180])\n",
            "Input: tensor([1.7800e+02, 2.0150e+03, 1.0000e+00, 1.5700e+02, 9.0000e+00, 4.6149e+00,\n",
            "        0.0000e+00, 0.0000e+00, 6.2100e+01, 1.0000e+01, 8.7000e+01, 5.9302e+00,\n",
            "        8.7000e+01, 1.0000e-01, 1.6000e+00, 1.5000e+00, 7.6900e-01, 1.4300e+01])\n",
            "Target: tensor([74.1000])\n",
            "Prediction: tensor([85.8216])\n",
            "Input: tensor([1.7900e+02, 2.0020e+03, 1.0000e+00, 1.3700e+02, 3.0000e+01, 2.0300e+00,\n",
            "        0.0000e+00, 6.7550e+03, 1.0000e+00, 3.9000e+01, 9.2000e+01, 4.7000e+00,\n",
            "        7.5000e+01, 2.0000e-01, 1.5600e+01, 1.6300e+01, 5.8400e-01, 1.0700e+01])\n",
            "Target: tensor([73.8000])\n",
            "Prediction: tensor([68.7485])\n",
            "Input: tensor([6.0000e+01, 2.0030e+03, 1.0000e+00, 2.9700e+02, 3.0000e+00, 2.4700e+00,\n",
            "        0.0000e+00, 1.1900e+02, 1.9700e+01, 6.0000e+00, 8.7000e+01, 4.2200e+00,\n",
            "        8.7000e+01, 2.7000e+00, 9.6000e+00, 9.6000e+00, 3.9500e-01, 7.3000e+00])\n",
            "Target: tensor([57.])\n",
            "Prediction: tensor([47.9388])\n",
            "Input: tensor([1.2700e+02, 2.0050e+03, 0.0000e+00, 1.4400e+02, 2.0000e+00, 9.5000e+00,\n",
            "        7.9415e+01, 1.3000e+01, 5.5500e+01, 3.0000e+00, 9.9000e+01, 6.2000e+00,\n",
            "        9.9000e+01, 1.0000e-01, 2.3000e+00, 2.5000e+00, 7.9700e-01, 1.4800e+01])\n",
            "Target: tensor([75.])\n",
            "Prediction: tensor([76.4794])\n",
            "Input: tensor([8.6000e+01, 2.0120e+03, 1.0000e+00, 2.4000e+01, 0.0000e+00, 1.0000e-02,\n",
            "        1.4745e+02, 0.0000e+00, 7.6200e+01, 0.0000e+00, 9.2000e+01, 1.3700e+00,\n",
            "        9.4000e+01, 1.0000e-01, 1.0000e-01, 1.0000e-01, 5.8100e-01, 1.1900e+01])\n",
            "Target: tensor([65.7000])\n",
            "Prediction: tensor([81.9311])\n",
            "Input: tensor([5.5000e+01, 2.0130e+03, 1.0000e+00, 2.3700e+02, 1.4500e+02, 1.8600e+00,\n",
            "        8.3133e+00, 5.2530e+03, 1.6800e+01, 2.1100e+02, 7.0000e+00, 5.1900e+00,\n",
            "        7.2000e+01, 9.0000e-01, 1.6000e+00, 1.4000e+00, 4.2700e-01, 8.4000e+00])\n",
            "Target: tensor([63.7000])\n",
            "Prediction: tensor([95.0576])\n",
            "Input: tensor([1.1800e+02, 2.0100e+03, 1.0000e+00, 3.7400e+02, 5.2100e+02, 8.9000e+00,\n",
            "        1.3312e+02, 8.4910e+03, 2.2200e+01, 8.1700e+02, 5.4000e+01, 3.4700e+00,\n",
            "        5.4000e+01, 4.8000e+00, 1.1300e+01, 1.1200e+01, 4.9200e-01, 9.5000e+00])\n",
            "Target: tensor([52.])\n",
            "Prediction: tensor([164.1136])\n",
            "Input: tensor([7.4000e+01, 2.0100e+03, 1.0000e+00, 1.9600e+02, 1.2000e+03, 2.7700e+00,\n",
            "        5.7734e+01, 3.1458e+04, 1.5900e+01, 1.6000e+03, 7.6000e+01, 4.2800e+00,\n",
            "        7.9000e+01, 2.0000e-01, 2.7000e+01, 2.7800e+01, 5.6900e-01, 1.0400e+01])\n",
            "Target: tensor([66.4000])\n",
            "Prediction: tensor([286.8037])\n",
            "Input: tensor([1.6000e+02, 2.0070e+03, 1.0000e+00, 1.6500e+02, 1.2000e+01, 6.2000e+00,\n",
            "        5.2076e+02, 3.8930e+03, 2.4600e+01, 1.4000e+01, 9.8000e+01, 3.5600e+00,\n",
            "        9.8000e+01, 4.0000e-01, 8.6000e+00, 8.8000e+00, 6.8700e-01, 1.2300e+01])\n",
            "Target: tensor([73.3000])\n",
            "Prediction: tensor([70.5983])\n",
            "Input: tensor([6.6000e+01, 2.0020e+03, 1.0000e+00, 2.1000e+01, 1.6000e+01, 2.4100e+00,\n",
            "        2.5250e+01, 0.0000e+00, 4.1700e+01, 2.0000e+01, 8.2000e+01, 6.7100e+00,\n",
            "        8.2000e+01, 3.0000e-01, 1.5000e+00, 1.5000e+00, 5.5300e-01, 8.8000e+00])\n",
            "Target: tensor([69.3000])\n",
            "Prediction: tensor([77.9324])\n",
            "Input: tensor([1.3100e+02, 2.0100e+03, 1.0000e+00, 2.1900e+02, 1.0000e+00, 8.2500e+00,\n",
            "        0.0000e+00, 0.0000e+00, 5.4000e+00, 1.0000e+00, 9.7000e+01, 1.2800e+01,\n",
            "        9.0000e+00, 1.0000e-01, 2.8000e+00, 3.0000e+00, 6.2742e-01, 1.2000e+01])\n",
            "Target: tensor([68.8000])\n",
            "Prediction: tensor([54.4827])\n",
            "Input: tensor([1.7000e+02, 2.0120e+03, 1.0000e+00, 2.5000e+01, 5.0000e+00, 8.4400e+00,\n",
            "        4.5378e+02, 1.2746e+04, 5.9600e+01, 5.0000e+00, 7.2000e+01, 7.4700e+00,\n",
            "        7.6000e+01, 2.0000e-01, 2.4000e+00, 2.4000e+00, 7.3900e-01, 1.5100e+01])\n",
            "Target: tensor([77.])\n",
            "Prediction: tensor([85.0054])\n",
            "Input: tensor([8.9000e+01, 2.0080e+03, 1.0000e+00, 2.2800e+02, 1.0000e+01, 5.1000e+00,\n",
            "        0.0000e+00, 1.7400e+02, 1.6700e+01, 1.4000e+01, 6.0000e+00, 2.7700e+00,\n",
            "        6.1000e+01, 2.0000e-01, 9.6000e+00, 9.7000e+00, 5.1800e-01, 9.2000e+00])\n",
            "Target: tensor([62.6000])\n",
            "Prediction: tensor([72.8915])\n",
            "Input: tensor([3.0000e+00, 2.0050e+03, 1.0000e+00, 3.8200e+02, 9.2000e+01, 5.0400e+00,\n",
            "        9.8191e+01, 2.5800e+02, 1.7700e+01, 1.4800e+02, 3.9000e+01, 4.1000e+00,\n",
            "        3.8000e+01, 2.6000e+00, 1.0000e+00, 9.9000e+00, 4.2600e-01, 6.8000e+00])\n",
            "Target: tensor([47.4000])\n",
            "Prediction: tensor([59.1070])\n",
            "Input: tensor([1.0500e+02, 2.0040e+03, 1.0000e+00, 1.2400e+02, 4.4000e+01, 4.9000e+00,\n",
            "        9.2083e+02, 6.4000e+01, 5.5700e+01, 5.2000e+01, 9.8000e+01, 6.1100e+00,\n",
            "        9.8000e+01, 1.0000e-01, 1.8000e+00, 1.8000e+00, 7.1400e-01, 1.2100e+01])\n",
            "Target: tensor([75.4000])\n",
            "Prediction: tensor([83.5343])\n",
            "Input: tensor([9.6000e+01, 2.0100e+03, 0.0000e+00, 7.3000e+01, 0.0000e+00, 1.1360e+01,\n",
            "        2.2673e+03, 0.0000e+00, 5.9200e+01, 0.0000e+00, 9.6000e+01, 7.6800e+00,\n",
            "        9.9000e+01, 1.0000e-01, 9.0000e-01, 9.0000e-01, 8.8400e-01, 1.3700e+01])\n",
            "Target: tensor([86.])\n",
            "Prediction: tensor([80.9232])\n",
            "Input: tensor([1.3000e+01, 2.0080e+03, 1.0000e+00, 1.1100e+02, 0.0000e+00, 8.9500e+00,\n",
            "        2.5523e+01, 0.0000e+00, 4.9200e+01, 0.0000e+00, 8.5000e+01, 6.1000e+00,\n",
            "        8.5000e+01, 1.0000e-01, 3.9000e+00, 3.9000e+00, 7.7500e-01, 1.5300e+01])\n",
            "Target: tensor([74.4000])\n",
            "Prediction: tensor([62.8339])\n",
            "Input: tensor([1.4200e+02, 2.0070e+03, 1.0000e+00, 1.8500e+02, 0.0000e+00, 8.1200e+00,\n",
            "        9.1647e+02, 1.0000e+00, 3.1200e+01, 0.0000e+00, 9.9000e+01, 3.3000e+00,\n",
            "        9.9000e+01, 1.0000e-01, 5.9000e+00, 6.3000e+00, 7.3300e-01, 1.3100e+01])\n",
            "Target: tensor([72.2000])\n",
            "Prediction: tensor([69.7587])\n",
            "Input: tensor([1.7000e+02, 2.0150e+03, 1.0000e+00, 1.9500e+02, 4.0000e+00, 4.6149e+00,\n",
            "        0.0000e+00, 1.0500e+02, 6.1300e+01, 5.0000e+00, 5.1000e+01, 5.9302e+00,\n",
            "        2.3000e+01, 2.0000e-01, 2.3000e+00, 2.4000e+00, 7.4800e-01, 1.5300e+01])\n",
            "Target: tensor([71.3000])\n",
            "Prediction: tensor([82.0434])\n",
            "Input: tensor([1.7000e+02, 2.0130e+03, 1.0000e+00, 1.9800e+02, 4.0000e+00, 8.4400e+00,\n",
            "        5.2425e+01, 0.0000e+00, 6.1000e+00, 5.0000e+00, 7.2000e+01, 7.6700e+00,\n",
            "        7.6000e+01, 2.0000e-01, 2.3000e+00, 2.4000e+00, 7.4400e-01, 1.5200e+01])\n",
            "Target: tensor([71.])\n",
            "Prediction: tensor([73.1146])\n",
            "Input: tensor([4.4000e+01, 2.0030e+03, 1.0000e+00, 1.6500e+02, 1.2000e+01, 3.1300e+00,\n",
            "        0.0000e+00, 0.0000e+00, 2.6700e+01, 1.5000e+01, 9.9000e+01, 5.9302e+00,\n",
            "        6.8000e+01, 1.0000e-01, 5.8000e+00, 5.8000e+00, 6.2742e-01, 1.2000e+01])\n",
            "Target: tensor([68.1000])\n",
            "Prediction: tensor([55.3101])\n",
            "Input: tensor([2.1000e+01, 2.0080e+03, 1.0000e+00, 4.2700e+02, 2.0000e+00, 6.5600e+00,\n",
            "        4.7686e+02, 0.0000e+00, 3.4200e+01, 3.0000e+00, 9.6000e+01, 5.5500e+00,\n",
            "        9.6000e+01, 1.2700e+01, 8.8000e+00, 8.6000e+00, 6.4600e-01, 1.2100e+01])\n",
            "Target: tensor([57.5000])\n",
            "Prediction: tensor([35.4385])\n",
            "Input: tensor([4.1000e+01, 2.0080e+03, 0.0000e+00, 6.2000e+01, 0.0000e+00, 1.2010e+01,\n",
            "        2.3964e+02, 1.0000e+00, 5.6800e+01, 0.0000e+00, 9.7000e+01, 6.8900e+00,\n",
            "        9.7000e+01, 1.0000e-01, 9.0000e-01, 1.0000e+00, 8.4400e-01, 1.3700e+01])\n",
            "Target: tensor([79.1000])\n",
            "Prediction: tensor([71.8127])\n",
            "Input: tensor([7.8000e+01, 2.0070e+03, 0.0000e+00, 7.5000e+01, 0.0000e+00, 1.3590e+01,\n",
            "        9.7976e+03, 6.4000e+01, 5.6600e+01, 0.0000e+00, 9.2000e+01, 7.5700e+00,\n",
            "        9.2000e+01, 1.0000e-01, 3.0000e-01, 2.0000e-01, 9.0200e-01, 1.7600e+01])\n",
            "Target: tensor([79.5000])\n",
            "Prediction: tensor([83.8940])\n",
            "Input: tensor([4.5000e+01, 2.0150e+03, 1.0000e+00, 2.5800e+02, 2.3600e+02, 4.6149e+00,\n",
            "        0.0000e+00, 5.0200e+03, 2.1600e+01, 3.0800e+02, 7.8000e+01, 5.9302e+00,\n",
            "        8.1000e+01, 1.1000e+00, 9.5000e+00, 9.3000e+00, 6.2742e-01, 1.2000e+01])\n",
            "Target: tensor([59.8000])\n",
            "Prediction: tensor([97.3952])\n",
            "Input: tensor([5.2000e+01, 2.0060e+03, 1.0000e+00, 3.3700e+02, 3.0000e+00, 7.2800e+00,\n",
            "        8.2760e+02, 0.0000e+00, 2.5000e+00, 4.0000e+00, 5.2000e+01, 2.1300e+00,\n",
            "        4.0000e+00, 5.3000e+00, 9.7000e+00, 9.6000e+00, 5.6900e-01, 9.0000e+00])\n",
            "Target: tensor([54.8000])\n",
            "Prediction: tensor([41.3631])\n",
            "Input: tensor([7.8000e+01, 2.0110e+03, 0.0000e+00, 7.0000e+00, 0.0000e+00, 1.1720e+01,\n",
            "        6.3870e+03, 2.8500e+02, 5.9700e+01, 0.0000e+00, 9.5000e+01, 8.1500e+00,\n",
            "        9.5000e+01, 1.0000e-01, 3.0000e-01, 2.0000e-01, 9.0900e-01, 1.8500e+01])\n",
            "Target: tensor([84.])\n",
            "Prediction: tensor([86.0869])\n",
            "Input: tensor([1.8000e+02, 2.0030e+03, 1.0000e+00, 2.4900e+02, 4.3000e+01, 4.0000e-02,\n",
            "        0.0000e+00, 8.5360e+03, 3.2700e+01, 5.8000e+01, 6.1000e+01, 5.0000e+00,\n",
            "        6.1000e+01, 1.0000e-01, 1.4000e+01, 1.3900e+01, 4.5700e-01, 8.2000e+00])\n",
            "Target: tensor([61.9000])\n",
            "Prediction: tensor([73.5920])\n",
            "Input: tensor([1.1000e+02, 2.0140e+03, 1.0000e+00, 3.7500e+02, 6.1000e+01, 1.0000e-02,\n",
            "        5.4912e+01, 9.0000e+00, 2.2200e+01, 8.4000e+01, 7.9000e+01, 6.9800e+00,\n",
            "        7.9000e+01, 4.1000e+00, 3.6000e+00, 3.5000e+00, 4.0900e-01, 9.1000e+00])\n",
            "Target: tensor([56.7000])\n",
            "Prediction: tensor([64.3700])\n",
            "Input: tensor([1.0000e+02, 2.0070e+03, 1.0000e+00, 8.2000e+01, 0.0000e+00, 1.7800e+00,\n",
            "        6.4915e+00, 2.0000e+01, 1.9500e+01, 0.0000e+00, 9.8000e+01, 6.6400e+00,\n",
            "        9.8000e+01, 1.0000e-01, 1.4300e+01, 1.4400e+01, 6.3200e-01, 1.1900e+01])\n",
            "Target: tensor([75.4000])\n",
            "Prediction: tensor([66.4380])\n",
            "Input: tensor([1.3400e+02, 2.0120e+03, 1.0000e+00, 2.3900e+02, 1.3000e+01, 1.0000e-02,\n",
            "        9.7747e+00, 7.5000e+01, 1.9500e+01, 1.8000e+01, 9.8000e+01, 7.6800e+00,\n",
            "        9.8000e+01, 7.0000e-01, 6.1000e+00, 6.1000e+00, 4.7500e-01, 1.0500e+01])\n",
            "Target: tensor([64.6000])\n",
            "Prediction: tensor([64.0101])\n",
            "Input: tensor([1.0800e+02, 2.0110e+03, 1.0000e+00, 1.1300e+02, 0.0000e+00, 6.5600e+00,\n",
            "        6.6674e+02, 5.0000e+00, 5.9700e+01, 0.0000e+00, 9.5000e+01, 6.9200e+00,\n",
            "        9.5000e+01, 1.0000e-01, 1.9000e+00, 2.0000e+00, 7.9200e-01, 1.5100e+01])\n",
            "Target: tensor([75.4000])\n",
            "Prediction: tensor([76.9612])\n",
            "Input: tensor([1.7900e+02, 2.0090e+03, 1.0000e+00, 1.3400e+02, 2.9000e+01, 3.8600e+00,\n",
            "        0.0000e+00, 6.5820e+03, 1.3400e+01, 3.5000e+01, 9.7000e+01, 6.4000e+00,\n",
            "        9.6000e+01, 1.0000e-01, 1.4600e+01, 1.5500e+01, 6.4100e-01, 1.1700e+01])\n",
            "Target: tensor([75.])\n",
            "Prediction: tensor([73.0546])\n",
            "Input: tensor([1.2200e+02, 2.0050e+03, 1.0000e+00, 1.2200e+02, 1.0000e+00, 5.5300e+00,\n",
            "        6.2391e+02, 0.0000e+00, 5.3000e+00, 2.0000e+00, 8.8000e+01, 7.4800e+00,\n",
            "        9.2000e+01, 1.0000e-01, 2.1000e+00, 2.1000e+00, 7.4000e-01, 1.2900e+01])\n",
            "Target: tensor([75.8000])\n",
            "Prediction: tensor([69.0548])\n",
            "Input: tensor([5.4000e+01, 2.0130e+03, 1.0000e+00, 1.2700e+02, 0.0000e+00, 1.0000e-02,\n",
            "        2.6129e+02, 2.0000e+00, 5.9000e+01, 0.0000e+00, 9.4000e+01, 6.4800e+00,\n",
            "        9.4000e+01, 1.0000e-01, 1.9000e+00, 1.9000e+00, 8.5600e-01, 1.6500e+01])\n",
            "Target: tensor([76.9000])\n",
            "Prediction: tensor([66.9281])\n",
            "Input: tensor([4.0000e+01, 2.0120e+03, 1.0000e+00, 9.6000e+01, 1.0000e+00, 4.1600e+00,\n",
            "        7.4220e+02, 0.0000e+00, 5.9200e+01, 1.0000e+00, 9.8000e+01, 8.5900e+00,\n",
            "        9.9000e+01, 1.0000e-01, 3.4000e+00, 3.2000e+00, 7.7800e-01, 1.5700e+01])\n",
            "Target: tensor([78.7000])\n",
            "Prediction: tensor([68.4149])\n",
            "Input: tensor([1.0400e+02, 2.0080e+03, 1.0000e+00, 1.6600e+02, 0.0000e+00, 2.4900e+00,\n",
            "        6.6490e+00, 1.2000e+01, 2.9700e+01, 0.0000e+00, 9.9000e+01, 4.6000e+00,\n",
            "        9.9000e+01, 1.0000e-01, 7.4000e+00, 7.3000e+00, 7.2800e-01, 1.3600e+01])\n",
            "Target: tensor([72.7000])\n",
            "Prediction: tensor([63.8763])\n",
            "Input: tensor([7.8000e+01, 2.0010e+03, 0.0000e+00, 8.9000e+01, 0.0000e+00, 1.4270e+01,\n",
            "        4.2646e+03, 2.4100e+02, 5.2200e+01, 0.0000e+00, 8.4000e+01, 6.6000e+00,\n",
            "        8.4000e+01, 1.0000e-01, 3.0000e-01, 3.0000e-01, 8.5700e-01, 1.6400e+01])\n",
            "Target: tensor([77.])\n",
            "Prediction: tensor([78.5570])\n",
            "Input: tensor([2.2000e+01, 2.0070e+03, 1.0000e+00, 1.5900e+02, 6.5000e+01, 7.1900e+00,\n",
            "        3.9493e+02, 0.0000e+00, 4.9400e+01, 7.3000e+01, 9.9000e+01, 8.2800e+00,\n",
            "        9.9000e+01, 1.0000e-01, 3.1000e+00, 3.0000e+00, 7.0000e-01, 1.3500e+01])\n",
            "Target: tensor([73.3000])\n",
            "Prediction: tensor([73.0702])\n",
            "Input: tensor([9.3000e+01, 2.0070e+03, 1.0000e+00, 2.8600e+02, 1.0000e+01, 4.0300e+00,\n",
            "        3.6869e+00, 1.0000e+00, 2.2900e+01, 1.4000e+01, 6.7000e+01, 1.2400e+00,\n",
            "        6.5000e+01, 2.8000e+00, 7.9000e+00, 7.8000e+00, 3.8300e-01, 9.9000e+00])\n",
            "Target: tensor([57.9000])\n",
            "Prediction: tensor([57.7854])\n",
            "Input: tensor([3.3000e+01, 2.0010e+03, 1.0000e+00, 1.6000e+01, 2.0000e+00, 6.1000e+00,\n",
            "        6.8751e+02, 0.0000e+00, 5.4700e+01, 3.0000e+00, 9.6000e+01, 6.5100e+00,\n",
            "        9.7000e+01, 1.0000e-01, 1.0000e+00, 1.0000e+00, 7.6100e-01, 1.3700e+01])\n",
            "Target: tensor([77.3000])\n",
            "Prediction: tensor([72.9148])\n",
            "Input: tensor([9.2000e+01, 2.0010e+03, 1.0000e+00, 5.8600e+02, 5.0000e+00, 2.8600e+00,\n",
            "        3.8572e+01, 2.1700e+02, 2.5400e+01, 7.0000e+00, 7.8000e+01, 7.5300e+00,\n",
            "        7.8000e+01, 3.1200e+01, 1.1100e+01, 1.1100e+01, 4.4300e-01, 1.0300e+01])\n",
            "Target: tensor([47.8000])\n",
            "Prediction: tensor([31.2683])\n",
            "Input: tensor([1.1800e+02, 2.0110e+03, 1.0000e+00, 3.7500e+02, 5.1300e+02, 8.7500e+00,\n",
            "        1.8757e+02, 1.8843e+04, 2.2800e+01, 8.0200e+02, 4.8000e+01, 3.6900e+00,\n",
            "        4.8000e+01, 4.7000e+00, 1.1000e+01, 1.9000e+00, 5.0000e-01, 9.6000e+00])\n",
            "Target: tensor([52.3000])\n",
            "Prediction: tensor([156.2818])\n",
            "Input: tensor([5.4000e+01, 2.0050e+03, 1.0000e+00, 1.8900e+02, 0.0000e+00, 1.5520e+01,\n",
            "        1.5350e+02, 2.0000e+00, 5.5500e+01, 0.0000e+00, 9.6000e+01, 5.2000e+00,\n",
            "        9.6000e+01, 1.0000e-01, 2.1000e+00, 2.2000e+00, 8.1200e-01, 1.5900e+01])\n",
            "Target: tensor([72.8000])\n",
            "Prediction: tensor([64.2558])\n",
            "Input: tensor([6.3000e+01, 2.0140e+03, 1.0000e+00, 2.5300e+02, 3.7000e+01, 1.0000e-02,\n",
            "        9.7678e+01, 1.2400e+02, 2.8000e+01, 5.4000e+01, 9.3000e+01, 3.5600e+00,\n",
            "        9.8000e+01, 8.0000e-01, 6.4000e+00, 6.3000e+00, 5.7600e-01, 1.1700e+01])\n",
            "Target: tensor([62.1000])\n",
            "Prediction: tensor([60.7474])\n",
            "Input: tensor([1.0700e+02, 2.0020e+03, 1.0000e+00, 2.6300e+02, 2.0000e+00, 2.4300e+00,\n",
            "        5.5609e+01, 1.2050e+03, 3.9800e+01, 2.0000e+00, 9.8000e+01, 5.8100e+00,\n",
            "        9.8000e+01, 1.0000e-01, 2.4000e+00, 2.5000e+00, 5.9900e-01, 1.0100e+01])\n",
            "Target: tensor([63.8000])\n",
            "Prediction: tensor([59.6734])\n",
            "Input: tensor([1.6800e+02, 2.0140e+03, 1.0000e+00, 2.1700e+02, 7.0000e+00, 2.9000e+00,\n",
            "        6.9113e+02, 0.0000e+00, 4.7700e+01, 8.0000e+00, 9.8000e+01, 2.7000e+00,\n",
            "        9.8000e+01, 1.0000e-01, 3.3000e+00, 3.3000e+00, 6.8300e-01, 1.0800e+01])\n",
            "Target: tensor([66.])\n",
            "Prediction: tensor([75.2239])\n",
            "Input: tensor([6.8000e+01, 2.0000e+03, 1.0000e+00, 3.0000e+00, 5.0000e+00, 2.8400e+00,\n",
            "        6.6994e+00, 0.0000e+00, 1.7400e+01, 9.0000e+00, 5.2000e+01, 4.9400e+00,\n",
            "        4.9000e+01, 3.1000e+00, 1.2000e+00, 1.2000e+00, 0.0000e+00, 6.4000e+00])\n",
            "Target: tensor([52.1000])\n",
            "Prediction: tensor([75.4484])\n",
            "Input: tensor([1.0800e+02, 2.0080e+03, 1.0000e+00, 1.2100e+02, 0.0000e+00, 6.1700e+00,\n",
            "        7.0913e+02, 0.0000e+00, 5.7800e+01, 0.0000e+00, 9.5000e+01, 6.1300e+00,\n",
            "        9.5000e+01, 1.0000e-01, 2.1000e+00, 2.1000e+00, 7.7400e-01, 1.4200e+01])\n",
            "Target: tensor([74.6000])\n",
            "Prediction: tensor([75.7865])\n",
            "Input: tensor([1.7400e+02, 2.0140e+03, 0.0000e+00, 1.4000e+01, 2.3000e+01, 8.8200e+00,\n",
            "        0.0000e+00, 6.6700e+02, 6.9100e+01, 2.7000e+01, 9.3000e+01, 1.7140e+01,\n",
            "        9.5000e+01, 1.0000e-01, 8.0000e-01, 6.0000e-01, 6.2742e-01, 1.2000e+01])\n",
            "Target: tensor([79.1000])\n",
            "Prediction: tensor([101.5540])\n",
            "Input: tensor([6.0000e+01, 2.0000e+03, 1.0000e+00, 3.3000e+01, 3.0000e+00, 2.1800e+00,\n",
            "        0.0000e+00, 3.3600e+02, 1.8000e+01, 6.0000e+00, 8.4000e+01, 3.6100e+00,\n",
            "        8.0000e+00, 2.0000e+00, 1.2000e+00, 1.2000e+00, 3.7700e-01, 6.5000e+00])\n",
            "Target: tensor([55.9000])\n",
            "Prediction: tensor([60.7452])\n",
            "Input: tensor([1.1300e+02, 2.0110e+03, 1.0000e+00, 1.7200e+02, 2.2000e+01, 2.7000e-01,\n",
            "        1.1212e+02, 2.3590e+03, 1.6900e+01, 2.7000e+01, 9.2000e+01, 6.7300e+00,\n",
            "        9.2000e+01, 2.0000e-01, 1.6500e+01, 1.6900e+01, 5.2900e-01, 1.2000e+01])\n",
            "Target: tensor([68.4000])\n",
            "Prediction: tensor([64.0992])\n",
            "Input: tensor([3.2000e+01, 2.0030e+03, 1.0000e+00, 4.3000e+01, 4.4000e+01, 4.2000e-01,\n",
            "        3.9792e+00, 1.5801e+04, 1.4800e+01, 7.7000e+01, 3.6000e+01, 5.4900e+00,\n",
            "        2.3000e+01, 5.1000e+00, 1.9000e+00, 1.8000e+00, 2.8400e-01, 5.4000e+00])\n",
            "Target: tensor([48.4000])\n",
            "Prediction: tensor([62.7689])\n",
            "Input: tensor([3.7000e+01, 2.0100e+03, 1.0000e+00, 2.9800e+02, 7.0000e+00, 3.5300e+00,\n",
            "        0.0000e+00, 4.0000e+00, 2.4500e+01, 1.0000e+01, 7.2000e+01, 2.2900e+00,\n",
            "        7.4000e+01, 3.8000e+00, 8.1000e+00, 7.7000e+00, 5.4800e-01, 1.0500e+01])\n",
            "Target: tensor([62.])\n",
            "Prediction: tensor([48.8080])\n",
            "Input: tensor([4.2000e+01, 2.0060e+03, 0.0000e+00, 1.9000e+01, 0.0000e+00, 1.3030e+01,\n",
            "        0.0000e+00, 7.0000e+00, 6.1800e+01, 0.0000e+00, 9.8000e+01, 6.6900e+00,\n",
            "        9.8000e+01, 1.0000e-01, 2.0000e+00, 2.1000e+00, 6.2742e-01, 1.2000e+01])\n",
            "Target: tensor([76.5000])\n",
            "Prediction: tensor([75.6602])\n",
            "Input: tensor([1.6800e+02, 2.0130e+03, 1.0000e+00, 2.2800e+02, 7.0000e+00, 2.9300e+00,\n",
            "        6.3748e+01, 0.0000e+00, 4.6700e+01, 8.0000e+00, 9.8000e+01, 2.1200e+00,\n",
            "        9.8000e+01, 1.0000e-01, 3.2000e+00, 3.3000e+00, 6.7800e-01, 1.0700e+01])\n",
            "Target: tensor([65.4000])\n",
            "Prediction: tensor([73.6730])\n",
            "Input: tensor([1.7800e+02, 2.0070e+03, 1.0000e+00, 1.6500e+02, 9.0000e+00, 8.7000e+00,\n",
            "        0.0000e+00, 3.2000e+01, 5.7600e+01, 1.0000e+01, 6.7000e+01, 5.2500e+00,\n",
            "        6.2000e+01, 1.0000e-01, 1.6000e+00, 1.5000e+00, 7.2800e-01, 1.2900e+01])\n",
            "Target: tensor([73.4000])\n",
            "Prediction: tensor([86.7251])\n",
            "Input: tensor([1.6800e+02, 2.0040e+03, 1.0000e+00, 2.3800e+02, 6.0000e+00, 2.8600e+00,\n",
            "        1.8610e+02, 1.0000e+00, 4.0000e+00, 8.0000e+00, 9.8000e+01, 4.3000e+00,\n",
            "        9.7000e+01, 1.0000e-01, 3.4000e+00, 3.4000e+00, 0.0000e+00, 1.0300e+01])\n",
            "Target: tensor([63.5000])\n",
            "Prediction: tensor([64.7674])\n",
            "Input: tensor([1.0700e+02, 2.0010e+03, 1.0000e+00, 2.6600e+02, 2.0000e+00, 2.8700e+00,\n",
            "        6.1849e+01, 1.0677e+04, 3.9100e+01, 3.0000e+00, 9.5000e+01, 5.4500e+00,\n",
            "        9.5000e+01, 1.0000e-01, 2.5000e+00, 2.6000e+00, 5.8800e-01, 9.4000e+00])\n",
            "Target: tensor([63.2000])\n",
            "Prediction: tensor([51.5465])\n",
            "Input: tensor([4.4000e+01, 2.0010e+03, 1.0000e+00, 1.7700e+02, 1.6000e+01, 2.5300e+00,\n",
            "        0.0000e+00, 0.0000e+00, 2.5700e+01, 2.1000e+01, 9.8000e+01, 5.9302e+00,\n",
            "        6.2000e+01, 1.0000e-01, 5.9000e+00, 6.0000e+00, 6.2742e-01, 1.2000e+01])\n",
            "Target: tensor([66.6000])\n",
            "Prediction: tensor([54.5583])\n",
            "Input: tensor([9.0000e+00, 2.0110e+03, 1.0000e+00, 1.2500e+02, 5.0000e+00, 1.9800e+00,\n",
            "        2.6314e+02, 0.0000e+00, 4.8800e+01, 6.0000e+00, 9.1000e+01, 5.1000e+00,\n",
            "        8.7000e+01, 1.0000e-01, 2.8000e+00, 2.9000e+00, 7.4100e-01, 1.1700e+01])\n",
            "Target: tensor([71.6000])\n",
            "Prediction: tensor([60.1588])\n",
            "Input: tensor([8.0000e+01, 2.0100e+03, 0.0000e+00, 6.0000e+00, 2.0000e+00, 6.9500e+00,\n",
            "        5.2197e+03, 3.7200e+02, 6.1000e+01, 2.0000e+00, 9.6000e+01, 9.4200e+00,\n",
            "        9.6000e+01, 1.0000e-01, 5.0000e-01, 5.0000e-01, 8.6900e-01, 1.6400e+01])\n",
            "Target: tensor([81.8000])\n",
            "Prediction: tensor([85.1920])\n",
            "Input: tensor([5.4000e+01, 2.0030e+03, 1.0000e+00, 1.9900e+02, 0.0000e+00, 1.1640e+01,\n",
            "        1.3272e+02, 0.0000e+00, 5.4900e+01, 0.0000e+00, 9.5000e+01, 4.9200e+00,\n",
            "        9.4000e+01, 1.0000e-01, 2.2000e+00, 2.3000e+00, 7.9800e-01, 1.5600e+01])\n",
            "Target: tensor([71.9000])\n",
            "Prediction: tensor([62.5145])\n",
            "Input: tensor([1.5000e+02, 2.0140e+03, 1.0000e+00, 3.4300e+02, 2.6000e+01, 4.6149e+00,\n",
            "        4.6074e+01, 4.4100e+02, 3.8235e+01, 3.9000e+01, 4.4000e+01, 2.7400e+00,\n",
            "        3.9000e+01, 3.5000e+00, 4.8506e+00, 4.8814e+00, 4.2100e-01, 4.9000e+00])\n",
            "Target: tensor([56.6000])\n",
            "Prediction: tensor([71.0769])\n",
            "Input: tensor([8.4000e+01, 2.0150e+03, 1.0000e+00, 1.9800e+02, 4.0000e+00, 4.6149e+00,\n",
            "        0.0000e+00, 5.2600e+02, 5.3100e+01, 5.0000e+00, 9.8000e+01, 5.9302e+00,\n",
            "        9.8000e+01, 1.0000e-01, 2.4000e+00, 2.5000e+00, 7.9300e-01, 1.5000e+01])\n",
            "Target: tensor([72.])\n",
            "Prediction: tensor([65.4509])\n",
            "Input: tensor([1.7200e+02, 2.0040e+03, 0.0000e+00, 8.3000e+01, 4.0000e+00, 1.2220e+01,\n",
            "        0.0000e+00, 1.8900e+02, 6.1000e+00, 4.0000e+00, 9.2000e+01, 7.9800e+00,\n",
            "        9.2000e+01, 1.0000e-01, 7.0000e-01, 5.0000e-01, 6.2742e-01, 1.2000e+01])\n",
            "Target: tensor([78.8000])\n",
            "Prediction: tensor([79.8452])\n",
            "Input: tensor([7.3000e+01, 2.0090e+03, 0.0000e+00, 5.5000e+01, 0.0000e+00, 1.0220e+01,\n",
            "        6.8758e+02, 0.0000e+00, 5.8500e+01, 0.0000e+00, 9.6000e+01, 9.1200e+00,\n",
            "        9.6000e+01, 1.0000e-01, 9.0000e-01, 9.0000e-01, 8.9400e-01, 1.8400e+01])\n",
            "Target: tensor([81.6000])\n",
            "Prediction: tensor([77.3050])\n",
            "Input: tensor([1.8000e+02, 2.0070e+03, 1.0000e+00, 2.4000e+01, 3.8000e+01, 5.0000e-02,\n",
            "        0.0000e+00, 1.3000e+01, 3.5100e+01, 4.9000e+01, 7.9000e+01, 4.9200e+00,\n",
            "        7.9000e+01, 1.0000e-01, 1.3800e+01, 1.3800e+01, 4.7700e-01, 8.6000e+00])\n",
            "Target: tensor([63.4000])\n",
            "Prediction: tensor([94.3716])\n",
            "Input: tensor([1.7000e+02, 2.0090e+03, 1.0000e+00, 2.3100e+02, 5.0000e+00, 8.7100e+00,\n",
            "        3.2455e+02, 0.0000e+00, 5.8000e+01, 6.0000e+00, 7.4000e+01, 7.8000e+00,\n",
            "        7.1000e+01, 3.0000e-01, 2.5000e+00, 2.6000e+00, 7.3400e-01, 1.4900e+01])\n",
            "Target: tensor([69.2000])\n",
            "Prediction: tensor([79.9780])\n",
            "Input: tensor([1.4100e+02, 2.0030e+03, 1.0000e+00, 1.3400e+02, 1.0000e+00, 7.2500e+00,\n",
            "        3.8975e+02, 1.5000e+01, 5.2800e+01, 1.0000e+00, 8.9000e+01, 8.1300e+00,\n",
            "        8.9000e+01, 1.0000e-01, 2.7000e+00, 2.7000e+00, 7.1500e-01, 1.3000e+01])\n",
            "Target: tensor([73.])\n",
            "Prediction: tensor([79.3210])\n",
            "Input: tensor([8.4000e+01, 2.0080e+03, 1.0000e+00, 2.5800e+02, 8.0000e+00, 7.6000e+00,\n",
            "        7.0833e+02, 2.0000e+01, 4.7900e+01, 9.0000e+00, 9.9000e+01, 3.6500e+00,\n",
            "        9.9000e+01, 1.0000e-01, 2.4000e+00, 2.5000e+00, 7.5800e-01, 1.4600e+01])\n",
            "Target: tensor([66.6000])\n",
            "Prediction: tensor([61.9229])\n",
            "Input: tensor([1.4000e+01, 2.0050e+03, 1.0000e+00, 2.5200e+02, 1.0000e+00, 1.1010e+01,\n",
            "        4.5650e+01, 1.0000e+00, 5.6700e+01, 1.0000e+00, 9.8000e+01, 6.8900e+00,\n",
            "        9.9000e+01, 1.0000e-01, 2.3000e+00, 2.5000e+00, 7.1300e-01, 1.4400e+01])\n",
            "Target: tensor([68.1000])\n",
            "Prediction: tensor([53.8259])\n",
            "Input: tensor([1.9000e+01, 2.0070e+03, 1.0000e+00, 2.1600e+02, 1.1000e+01, 3.4700e+00,\n",
            "        0.0000e+00, 0.0000e+00, 4.7300e+01, 1.4000e+01, 8.5000e+01, 4.9600e+00,\n",
            "        8.4000e+01, 2.0000e-01, 1.3000e+00, 1.2000e+00, 6.2600e-01, 1.4100e+01])\n",
            "Target: tensor([66.8000])\n",
            "Prediction: tensor([57.2081])\n",
            "Input: tensor([1.5500e+02, 2.0060e+03, 1.0000e+00, 5.6400e+02, 3.0000e+00, 5.5300e+00,\n",
            "        4.3708e+02, 0.0000e+00, 2.8200e+01, 4.0000e+00, 8.8000e+01, 6.8100e+00,\n",
            "        8.7000e+01, 4.3700e+01, 6.9000e+00, 7.1000e+00, 5.0200e-01, 9.9000e+00])\n",
            "Target: tensor([47.8000])\n",
            "Prediction: tensor([40.7432])\n",
            "Input: tensor([6.6000e+01, 2.0040e+03, 1.0000e+00, 2.1000e+01, 1.5000e+01, 2.4000e+00,\n",
            "        2.8840e+02, 0.0000e+00, 4.3100e+01, 1.8000e+01, 8.8000e+01, 6.7700e+00,\n",
            "        8.7000e+01, 4.0000e-01, 1.4000e+00, 1.4000e+00, 5.6400e-01, 9.3000e+00])\n",
            "Target: tensor([69.6000])\n",
            "Prediction: tensor([77.4351])\n",
            "Input: tensor([1.7000e+02, 2.0050e+03, 1.0000e+00, 2.7800e+02, 5.0000e+00, 7.3100e+00,\n",
            "        2.1743e+02, 2.3920e+03, 5.6400e+01, 6.0000e+00, 9.5000e+01, 6.4100e+00,\n",
            "        9.6000e+01, 9.0000e-01, 2.7000e+00, 2.8000e+00, 7.0700e-01, 1.4500e+01])\n",
            "Target: tensor([67.])\n",
            "Prediction: tensor([71.4282])\n",
            "Input: tensor([1.7300e+02, 2.0140e+03, 1.0000e+00, 3.4000e+01, 8.6000e+01, 1.0000e-02,\n",
            "        0.0000e+00, 8.8000e+01, 2.3200e+01, 1.2100e+02, 9.7000e+01, 5.5800e+00,\n",
            "        9.7000e+01, 1.4000e+00, 6.8000e+00, 6.6000e+00, 6.2742e-01, 1.2000e+01])\n",
            "Target: tensor([67.])\n",
            "Prediction: tensor([100.2821])\n",
            "Input: tensor([5.0000e+01, 2.0120e+03, 1.0000e+00, 1.6500e+02, 5.4000e+01, 2.3000e-01,\n",
            "        0.0000e+00, 2.4500e+02, 5.8600e+01, 6.4000e+01, 9.3000e+01, 5.2900e+00,\n",
            "        9.3000e+01, 1.0000e-01, 2.9000e+00, 2.8000e+00, 6.7300e-01, 1.2400e+01])\n",
            "Target: tensor([72.])\n",
            "Prediction: tensor([74.5457])\n",
            "Input: tensor([2.0000e+01, 2.0140e+03, 1.0000e+00, 8.9000e+01, 0.0000e+00, 4.0300e+00,\n",
            "        7.3287e+02, 3.0000e+03, 5.5300e+01, 0.0000e+00, 8.6000e+01, 9.5700e+00,\n",
            "        8.6000e+01, 1.0000e-01, 2.4000e+00, 2.4000e+00, 7.4200e-01, 1.4200e+01])\n",
            "Target: tensor([77.2000])\n",
            "Prediction: tensor([64.2942])\n",
            "Input: tensor([5.7000e+01, 2.0060e+03, 1.0000e+00, 9.6000e+01, 0.0000e+00, 1.0150e+01,\n",
            "        5.2478e+02, 0.0000e+00, 5.8600e+01, 0.0000e+00, 9.7000e+01, 8.3800e+00,\n",
            "        9.7000e+01, 1.0000e-01, 9.0000e-01, 8.0000e-01, 8.6900e-01, 1.7200e+01])\n",
            "Target: tensor([79.2000])\n",
            "Prediction: tensor([71.6382])\n",
            "Input: tensor([9.4000e+01, 2.0050e+03, 1.0000e+00, 1.3800e+02, 2.0000e+00, 1.0000e-02,\n",
            "        4.7230e+02, 2.9200e+02, 5.6000e+01, 3.0000e+00, 9.8000e+01, 2.7100e+00,\n",
            "        9.8000e+01, 1.0000e-01, 5.5000e+00, 5.4000e+00, 7.4800e-01, 1.5700e+01])\n",
            "Target: tensor([71.9000])\n",
            "Prediction: tensor([69.5330])\n",
            "Input: tensor([1.4200e+02, 2.0000e+03, 1.0000e+00, 1.8800e+02, 0.0000e+00, 8.2400e+00,\n",
            "        6.0176e+02, 0.0000e+00, 2.7100e+01, 0.0000e+00, 9.8000e+01, 4.6200e+00,\n",
            "        9.8000e+01, 1.0000e-01, 6.3000e+00, 6.7000e+00, 0.0000e+00, 1.2300e+01])\n",
            "Target: tensor([71.8000])\n",
            "Prediction: tensor([68.6521])\n",
            "Input: tensor([1.0700e+02, 2.0080e+03, 1.0000e+00, 2.2500e+02, 2.0000e+00, 4.2600e+00,\n",
            "        1.8101e+02, 3.1000e+01, 4.4900e+01, 2.0000e+00, 9.5000e+01, 5.5800e+00,\n",
            "        9.6000e+01, 1.0000e-01, 2.2000e+00, 2.3000e+00, 6.7300e-01, 1.3400e+01])\n",
            "Target: tensor([67.4000])\n",
            "Prediction: tensor([65.3880])\n",
            "Input: tensor([2.3000e+01, 2.0030e+03, 1.0000e+00, 8.9000e+01, 0.0000e+00, 1.2000e-01,\n",
            "        1.4065e+03, 2.4000e+01, 2.9100e+01, 0.0000e+00, 9.9000e+01, 3.9000e+00,\n",
            "        9.2000e+01, 1.0000e-01, 6.6000e+00, 6.1000e+00, 8.2300e-01, 1.3400e+01])\n",
            "Target: tensor([76.])\n",
            "Prediction: tensor([58.0760])\n",
            "Input: tensor([1.4700e+02, 2.0150e+03, 1.0000e+00, 1.7700e+02, 0.0000e+00, 4.6149e+00,\n",
            "        0.0000e+00, 0.0000e+00, 5.5000e+00, 0.0000e+00, 9.9000e+01, 5.9302e+00,\n",
            "        9.8000e+01, 1.0000e-01, 1.1000e+00, 1.2000e+00, 5.1400e-01, 9.6000e+00])\n",
            "Target: tensor([69.2000])\n",
            "Prediction: tensor([66.3136])\n",
            "Input: tensor([1.0100e+02, 2.0050e+03, 1.0000e+00, 2.9000e+01, 5.7000e+01, 5.5000e-01,\n",
            "        6.0212e+01, 3.3000e+01, 1.8000e+01, 1.0100e+02, 7.8000e+01, 6.3400e+00,\n",
            "        7.7000e+01, 1.9000e+00, 9.9000e+00, 9.7000e+00, 3.3800e-01, 5.8000e+00])\n",
            "Target: tensor([53.6000])\n",
            "Prediction: tensor([85.8889])\n",
            "Input: tensor([1.2200e+02, 2.0090e+03, 1.0000e+00, 1.2700e+02, 1.0000e+00, 6.8700e+00,\n",
            "        1.0922e+03, 0.0000e+00, 5.3400e+01, 2.0000e+00, 8.5000e+01, 7.5600e+00,\n",
            "        8.5000e+01, 1.0000e-01, 2.0000e+00, 1.9000e+00, 7.5500e-01, 1.2800e+01])\n",
            "Target: tensor([76.8000])\n",
            "Prediction: tensor([78.5638])\n",
            "Input: tensor([6.0000e+01, 2.0150e+03, 1.0000e+00, 2.6200e+02, 3.0000e+00, 4.6149e+00,\n",
            "        0.0000e+00, 7.1000e+01, 2.7300e+01, 5.0000e+00, 9.6000e+01, 5.9302e+00,\n",
            "        9.7000e+01, 1.7000e+00, 7.3000e+00, 7.2000e+00, 4.5000e-01, 8.9000e+00])\n",
            "Target: tensor([61.1000])\n",
            "Prediction: tensor([52.5127])\n",
            "Input: tensor([3.8000e+01, 2.0020e+03, 1.0000e+00, 9.9000e+01, 1.0000e+00, 4.1700e+00,\n",
            "        1.1295e+02, 0.0000e+00, 4.7300e+01, 1.0000e+00, 9.4000e+01, 8.2300e+00,\n",
            "        9.4000e+01, 1.0000e-01, 2.2000e+00, 2.2000e+00, 7.1200e-01, 1.1900e+01])\n",
            "Target: tensor([78.3000])\n",
            "Prediction: tensor([65.4622])\n",
            "Input: tensor([3.3000e+01, 2.0030e+03, 1.0000e+00, 1.0000e+00, 2.0000e+00, 6.3700e+00,\n",
            "        5.8410e+02, 1.0000e+00, 5.6100e+01, 2.0000e+00, 9.6000e+01, 7.3400e+00,\n",
            "        9.6000e+01, 1.0000e-01, 1.0000e+00, 1.0000e+00, 7.7500e-01, 1.4000e+01])\n",
            "Target: tensor([77.9000])\n",
            "Prediction: tensor([74.2795])\n",
            "Input: tensor([1.3000e+01, 2.0150e+03, 1.0000e+00, 9.8000e+01, 0.0000e+00, 4.6149e+00,\n",
            "        0.0000e+00, 0.0000e+00, 5.4500e+01, 0.0000e+00, 9.7000e+01, 5.9302e+00,\n",
            "        9.7000e+01, 1.0000e-01, 3.8000e+00, 3.7000e+00, 7.9400e-01, 1.5300e+01])\n",
            "Target: tensor([75.5000])\n",
            "Prediction: tensor([62.7148])\n",
            "Input: tensor([1.4500e+02, 2.0010e+03, 0.0000e+00, 1.4500e+02, 0.0000e+00, 1.0730e+01,\n",
            "        0.0000e+00, 0.0000e+00, 5.1100e+01, 1.0000e+00, 9.9000e+01, 5.5000e+00,\n",
            "        9.9000e+01, 1.0000e-01, 1.5000e+00, 1.6000e+00, 7.6300e-01, 1.3300e+01])\n",
            "Target: tensor([73.3000])\n",
            "Prediction: tensor([77.7918])\n",
            "Input: tensor([1.4500e+02, 2.0150e+03, 0.0000e+00, 1.9000e+01, 0.0000e+00, 4.6149e+00,\n",
            "        0.0000e+00, 1.0000e+00, 5.9100e+01, 0.0000e+00, 9.6000e+01, 5.9302e+00,\n",
            "        9.6000e+01, 1.0000e-01, 1.2000e+00, 1.2000e+00, 8.4200e-01, 1.5000e+01])\n",
            "Target: tensor([76.7000])\n",
            "Prediction: tensor([87.9078])\n",
            "Input: tensor([1.4500e+02, 2.0070e+03, 0.0000e+00, 1.4000e+01, 0.0000e+00, 1.0580e+01,\n",
            "        0.0000e+00, 0.0000e+00, 5.4200e+01, 0.0000e+00, 9.9000e+01, 7.7600e+00,\n",
            "        9.9000e+01, 1.0000e-01, 1.3000e+00, 1.4000e+00, 8.0200e-01, 1.4500e+01])\n",
            "Target: tensor([74.4000])\n",
            "Prediction: tensor([88.1966])\n",
            "Input: tensor([4.9000e+01, 2.0090e+03, 1.0000e+00, 1.3700e+02, 7.0000e+00, 3.8700e+00,\n",
            "        2.8214e+02, 0.0000e+00, 5.0000e+00, 8.0000e+00, 9.1000e+01, 5.5800e+00,\n",
            "        9.4000e+01, 1.0000e-01, 1.3000e+00, 1.2000e+00, 7.0200e-01, 1.3100e+01])\n",
            "Target: tensor([75.1000])\n",
            "Prediction: tensor([58.2205])\n",
            "Input: tensor([1.6200e+02, 2.0090e+03, 1.0000e+00, 1.6500e+02, 2.0000e+00, 9.0000e-02,\n",
            "        3.6199e+01, 1.0000e+01, 1.5100e+01, 3.0000e+00, 7.8000e+01, 1.2000e+00,\n",
            "        7.2000e+01, 1.0000e-01, 1.1600e+01, 1.1600e+01, 5.9900e-01, 1.2100e+01])\n",
            "Target: tensor([66.6000])\n",
            "Prediction: tensor([69.7552])\n",
            "Input: tensor([2.5000e+01, 2.0040e+03, 1.0000e+00, 3.2300e+02, 4.9000e+01, 4.5400e+00,\n",
            "        5.6961e+01, 7.7000e+01, 1.3700e+01, 9.1000e+01, 8.3000e+01, 6.4500e+00,\n",
            "        7.9000e+01, 2.5000e+00, 1.5000e+00, 1.1000e+00, 0.0000e+00, 3.9000e+00])\n",
            "Target: tensor([52.4000])\n",
            "Prediction: tensor([53.4535])\n",
            "Input: tensor([7.8000e+01, 2.0080e+03, 0.0000e+00, 7.5000e+01, 0.0000e+00, 1.2660e+01,\n",
            "        9.5282e+03, 5.7000e+01, 5.7400e+01, 0.0000e+00, 9.3000e+01, 8.6400e+00,\n",
            "        9.3000e+01, 1.0000e-01, 3.0000e-01, 2.0000e-01, 9.0800e-01, 1.7900e+01])\n",
            "Target: tensor([79.8000])\n",
            "Prediction: tensor([83.7205])\n",
            "Input: tensor([4.7000e+01, 2.0120e+03, 1.0000e+00, 2.6300e+02, 1.0000e+00, 5.2000e-01,\n",
            "        2.1721e+02, 7.0900e+02, 3.3200e+01, 2.0000e+00, 8.1000e+01, 8.9500e+00,\n",
            "        8.1000e+01, 1.9000e+00, 5.6000e+00, 5.5000e+00, 4.6000e-01, 6.3000e+00])\n",
            "Target: tensor([62.2000])\n",
            "Prediction: tensor([52.4050])\n",
            "Input: tensor([8.9000e+01, 2.0130e+03, 1.0000e+00, 2.3000e+01, 9.0000e+00, 1.0000e-02,\n",
            "        0.0000e+00, 7.1000e+01, 2.1000e+00, 1.2000e+01, 8.6000e+01, 2.0000e+00,\n",
            "        8.7000e+01, 3.0000e-01, 9.0000e+00, 9.1000e+00, 5.6300e-01, 1.0400e+01])\n",
            "Target: tensor([64.9000])\n",
            "Prediction: tensor([69.3660])\n",
            "Input: tensor([3.8000e+01, 2.0090e+03, 1.0000e+00, 9.6000e+01, 1.0000e+00, 4.0700e+00,\n",
            "        2.4887e+01, 0.0000e+00, 5.4400e+01, 1.0000e+00, 8.0000e+00, 9.6900e+00,\n",
            "        8.6000e+01, 1.0000e-01, 1.9000e+00, 1.8000e+00, 7.4700e-01, 1.3100e+01])\n",
            "Target: tensor([79.2000])\n",
            "Prediction: tensor([84.7066])\n",
            "Input: tensor([8.3000e+01, 2.0100e+03, 1.0000e+00, 1.1700e+02, 4.0000e+00, 5.1000e-01,\n",
            "        7.1597e+02, 0.0000e+00, 6.1700e+01, 4.0000e+00, 9.8000e+01, 8.4200e+00,\n",
            "        9.8000e+01, 1.0000e-01, 3.8000e+00, 3.8000e+00, 7.3900e-01, 1.3200e+01])\n",
            "Target: tensor([73.4000])\n",
            "Prediction: tensor([72.8436])\n",
            "Input: tensor([4.9000e+01, 2.0050e+03, 1.0000e+00, 1.5100e+02, 8.0000e+00, 3.5400e+00,\n",
            "        1.8093e+01, 0.0000e+00, 4.7200e+01, 9.0000e+00, 8.9000e+01, 5.8700e+00,\n",
            "        9.2000e+01, 3.0000e-01, 1.4000e+00, 1.3000e+00, 6.8800e-01, 1.2800e+01])\n",
            "Target: tensor([74.2000])\n",
            "Prediction: tensor([65.2417])\n",
            "Input: tensor([1.8000e+02, 2.0000e+03, 1.0000e+00, 2.5200e+02, 4.8000e+01, 7.0000e-02,\n",
            "        0.0000e+00, 0.0000e+00, 3.1200e+01, 6.6000e+01, 7.4000e+01, 4.1400e+00,\n",
            "        7.4000e+01, 1.0000e-01, 1.4100e+01, 1.4100e+01, 4.3600e-01, 7.7000e+00])\n",
            "Target: tensor([68.])\n",
            "Prediction: tensor([79.8402])\n",
            "Input: tensor([2.5000e+01, 2.0110e+03, 1.0000e+00, 2.7500e+02, 4.2000e+01, 4.5100e+00,\n",
            "        8.5556e+01, 8.6000e+02, 1.7100e+01, 7.1000e+01, 9.0000e+00, 5.1700e+00,\n",
            "        9.1000e+01, 9.0000e-01, 8.8000e+00, 8.4000e+00, 3.7700e-01, 6.7000e+00])\n",
            "Target: tensor([58.1000])\n",
            "Prediction: tensor([70.5317])\n",
            "Input: tensor([6.4000e+01, 2.0000e+03, 1.0000e+00, 8.4000e+01, 1.0000e+00, 8.4800e+00,\n",
            "        1.2218e+02, 5.6000e+01, 5.7400e+01, 1.0000e+00, 8.9000e+01, 7.6000e+00,\n",
            "        8.9000e+01, 1.0000e-01, 9.0000e-01, 8.0000e-01, 7.9400e-01, 1.3900e+01])\n",
            "Target: tensor([78.2000])\n",
            "Prediction: tensor([73.4376])\n",
            "Input: tensor([5.6000e+01, 2.0030e+03, 1.0000e+00, 2.2000e+01, 0.0000e+00, 1.7600e+00,\n",
            "        2.5382e+02, 3.0500e+02, 5.3200e+01, 0.0000e+00, 9.5000e+01, 3.3500e+00,\n",
            "        9.4000e+01, 1.0000e-01, 4.2000e+00, 3.9000e+00, 6.8900e-01, 1.3300e+01])\n",
            "Target: tensor([68.])\n",
            "Prediction: tensor([72.4860])\n",
            "Input: tensor([7.0000e+00, 2.0000e+03, 0.0000e+00, 7.8000e+01, 1.0000e+00, 1.0170e+01,\n",
            "        3.4719e+02, 1.0800e+02, 5.8200e+01, 2.0000e+00, 9.0000e+00, 8.8000e+00,\n",
            "        9.0000e+00, 1.0000e-01, 7.0000e-01, 7.0000e-01, 8.9700e-01, 2.0400e+01])\n",
            "Target: tensor([79.5000])\n",
            "Prediction: tensor([76.1645])\n",
            "Input: tensor([3.4000e+01, 2.0020e+03, 1.0000e+00, 1.6000e+01, 4.2200e+02, 2.9100e+00,\n",
            "        1.0636e+02, 5.8341e+04, 2.1900e+01, 5.1100e+02, 8.6000e+01, 4.7900e+00,\n",
            "        8.6000e+01, 1.0000e-01, 5.5000e+00, 4.9000e+00, 6.0000e-01, 9.7000e+00])\n",
            "Target: tensor([72.7000])\n",
            "Prediction: tensor([104.9044])\n",
            "Input: tensor([6.1000e+01, 2.0070e+03, 1.0000e+00, 1.2000e+01, 1.0000e+00, 8.6500e+00,\n",
            "        1.0616e+02, 4.4000e+01, 4.9900e+01, 1.0000e+00, 8.8000e+01, 8.1700e+00,\n",
            "        9.8000e+01, 1.0000e-01, 2.7000e+00, 2.9000e+00, 7.2200e-01, 1.2500e+01])\n",
            "Target: tensor([74.4000])\n",
            "Prediction: tensor([77.8336])\n",
            "Input: tensor([5.2000e+01, 2.0030e+03, 1.0000e+00, 3.3400e+02, 3.0000e+00, 7.1300e+00,\n",
            "        3.0978e+02, 1.8000e+01, 1.9500e+01, 4.0000e+00, 4.6000e+01, 2.2300e+00,\n",
            "        3.7000e+01, 3.6000e+00, 1.2000e+00, 1.1000e+00, 5.5400e-01, 8.4000e+00])\n",
            "Target: tensor([53.8000])\n",
            "Prediction: tensor([50.3172])\n",
            "Input: tensor([1.7000e+01, 2.0100e+03, 1.0000e+00, 2.5400e+02, 2.5000e+01, 1.3300e+00,\n",
            "        9.4257e+01, 3.9200e+02, 2.3000e+01, 3.9000e+01, 7.7000e+01, 4.9500e+00,\n",
            "        7.6000e+01, 1.4000e+00, 7.8000e+00, 7.6000e+00, 4.5100e-01, 9.5000e+00])\n",
            "Target: tensor([58.7000])\n",
            "Prediction: tensor([52.0792])\n",
            "Input: tensor([7.2000e+01, 2.0050e+03, 0.0000e+00, 1.8200e+02, 1.0000e+00, 1.2940e+01,\n",
            "        1.3171e+03, 2.0000e+00, 5.8800e+01, 1.0000e+00, 9.9000e+01, 8.2800e+00,\n",
            "        9.9000e+01, 1.0000e-01, 2.0000e+00, 2.0000e+00, 7.9500e-01, 1.5000e+01])\n",
            "Target: tensor([72.9000])\n",
            "Prediction: tensor([68.6946])\n",
            "Input: tensor([1.5800e+02, 2.0100e+03, 1.0000e+00, 1.2700e+02, 7.0000e+00, 7.8000e-01,\n",
            "        0.0000e+00, 2.6000e+01, 5.2300e+01, 9.0000e+00, 8.3000e+01, 3.2800e+00,\n",
            "        8.0000e+00, 1.0000e-01, 6.4000e+00, 6.1000e+00, 6.5000e-01, 1.1700e+01])\n",
            "Target: tensor([73.7000])\n",
            "Prediction: tensor([74.3112])\n",
            "Input: tensor([1.2000e+01, 2.0040e+03, 1.0000e+00, 1.5800e+02, 1.8500e+02, 1.0000e-02,\n",
            "        4.1147e+00, 9.7430e+03, 1.2000e+01, 2.4700e+02, 8.8000e+01, 2.6200e+00,\n",
            "        9.9000e+01, 1.0000e-01, 2.1000e+00, 2.7000e+00, 4.9100e-01, 8.1000e+00])\n",
            "Target: tensor([67.3000])\n",
            "Prediction: tensor([82.4869])\n",
            "Input: tensor([1.6400e+02, 2.0040e+03, 1.0000e+00, 1.5100e+02, 0.0000e+00, 1.8000e+00,\n",
            "        4.2330e+02, 0.0000e+00, 6.8600e+01, 0.0000e+00, 9.1000e+01, 4.8700e+00,\n",
            "        9.0000e+00, 1.0000e-01, 1.0000e-01, 1.0000e-01, 6.9300e-01, 1.4600e+01])\n",
            "Target: tensor([72.2000])\n",
            "Prediction: tensor([74.9112])\n",
            "Input: tensor([1.7800e+02, 2.0100e+03, 1.0000e+00, 1.5800e+02, 9.0000e+00, 7.2200e+00,\n",
            "        0.0000e+00, 0.0000e+00, 5.9300e+01, 1.0000e+01, 7.4000e+01, 5.4000e+00,\n",
            "        7.8000e+01, 1.0000e-01, 1.6000e+00, 1.5000e+00, 7.5400e-01, 1.4000e+01])\n",
            "Target: tensor([73.7000])\n",
            "Prediction: tensor([87.4033])\n",
            "Input: tensor([8.9000e+01, 2.0060e+03, 1.0000e+00, 2.4000e+01, 1.1000e+01, 3.6900e+00,\n",
            "        0.0000e+00, 5.8000e+01, 1.5500e+01, 1.5000e+01, 5.6000e+01, 4.1400e+00,\n",
            "        5.7000e+01, 2.0000e-01, 9.9000e+00, 9.9000e+00, 5.0300e-01, 9.0000e+00])\n",
            "Target: tensor([61.5000])\n",
            "Prediction: tensor([76.4864])\n",
            "Input: tensor([1.5100e+02, 2.0110e+03, 0.0000e+00, 6.3000e+01, 1.0000e+00, 9.6200e+00,\n",
            "        4.8738e+03, 3.8020e+03, 6.4100e+01, 2.0000e+00, 9.7000e+01, 9.4800e+00,\n",
            "        9.7000e+01, 1.0000e-01, 6.0000e-01, 5.0000e-01, 8.6700e-01, 1.6900e+01])\n",
            "Target: tensor([82.1000])\n",
            "Prediction: tensor([88.4477])\n",
            "Input: tensor([1.3700e+02, 2.0110e+03, 1.0000e+00, 1.3900e+02, 0.0000e+00, 2.1500e+00,\n",
            "        5.5872e+02, 0.0000e+00, 7.2900e+01, 0.0000e+00, 6.0000e+00, 5.8000e+00,\n",
            "        6.5000e+01, 1.0000e-01, 2.0000e-01, 1.0000e-01, 6.9300e-01, 1.2900e+01])\n",
            "Target: tensor([73.])\n",
            "Prediction: tensor([96.6398])\n",
            "Input: tensor([6.8000e+01, 2.0090e+03, 1.0000e+00, 2.8800e+02, 4.0000e+00, 2.5500e+00,\n",
            "        4.7130e+01, 0.0000e+00, 2.2500e+01, 7.0000e+00, 7.8000e+01, 6.8100e+00,\n",
            "        8.0000e+00, 6.0000e+00, 8.3000e+00, 8.1000e+00, 4.0100e-01, 8.9000e+00])\n",
            "Target: tensor([56.3000])\n",
            "Prediction: tensor([45.4262])\n",
            "Input: tensor([2.0000e+01, 2.0100e+03, 1.0000e+00, 9.4000e+01, 0.0000e+00, 4.5400e+00,\n",
            "        6.3039e+02, 4.5000e+01, 5.3100e+01, 0.0000e+00, 9.0000e+00, 9.5800e+00,\n",
            "        8.9000e+01, 1.0000e-01, 2.6000e+00, 2.6000e+00, 7.1700e-01, 1.3300e+01])\n",
            "Target: tensor([76.4000])\n",
            "Prediction: tensor([82.4018])\n",
            "Input: tensor([1.5600e+02, 2.0120e+03, 0.0000e+00, 5.7000e+01, 0.0000e+00, 7.4000e+00,\n",
            "        1.0947e+04, 3.0000e+01, 5.8100e+01, 0.0000e+00, 9.8000e+01, 1.1800e+01,\n",
            "        9.8000e+01, 1.0000e-01, 1.4000e+00, 1.3000e+00, 9.0300e-01, 1.5800e+01])\n",
            "Target: tensor([81.7000])\n",
            "Prediction: tensor([95.6005])\n",
            "Input: tensor([1.4300e+02, 2.0090e+03, 1.0000e+00, 4.3300e+02, 2.8000e+01, 3.9700e+00,\n",
            "        4.9837e+01, 3.1000e+01, 2.1200e+01, 4.2000e+01, 8.1000e+01, 1.3130e+01,\n",
            "        8.4000e+01, 1.7000e+00, 8.5000e+00, 8.4000e+00, 3.7500e-01, 8.5000e+00])\n",
            "Target: tensor([47.1000])\n",
            "Prediction: tensor([58.4294])\n",
            "Input: tensor([1.6700e+02, 2.0140e+03, 1.0000e+00, 1.7000e+01, 1.6000e+01, 1.4500e+00,\n",
            "        1.8191e+02, 5.6500e+02, 6.5300e+01, 1.9000e+01, 9.6000e+01, 5.4100e+00,\n",
            "        9.6000e+01, 1.0000e-01, 4.9000e+00, 4.7000e+00, 7.5900e-01, 1.4500e+01])\n",
            "Target: tensor([75.5000])\n",
            "Prediction: tensor([93.7301])\n",
            "Input: tensor([1.3600e+02, 2.0040e+03, 1.0000e+00, 1.8100e+02, 0.0000e+00, 5.4200e+00,\n",
            "        0.0000e+00, 0.0000e+00, 4.3800e+01, 0.0000e+00, 9.9000e+01, 3.7200e+00,\n",
            "        9.9000e+01, 4.0000e-01, 3.8000e+00, 3.7000e+00, 6.8900e-01, 1.3200e+01])\n",
            "Target: tensor([71.2000])\n",
            "Prediction: tensor([70.7800])\n",
            "Input: tensor([1.4400e+02, 2.0030e+03, 0.0000e+00, 7.3000e+01, 0.0000e+00, 1.4300e+00,\n",
            "        2.2631e+03, 3.3000e+01, 2.9600e+01, 0.0000e+00, 9.6000e+01, 3.6300e+00,\n",
            "        9.6000e+01, 1.0000e-01, 2.1000e+00, 2.0000e+00, 8.1900e-01, 1.2700e+01])\n",
            "Target: tensor([79.3000])\n",
            "Prediction: tensor([78.5236])\n",
            "Input: tensor([1.3800e+02, 2.0050e+03, 1.0000e+00, 2.2200e+02, 0.0000e+00, 5.2700e+00,\n",
            "        1.0814e+01, 0.0000e+00, 2.3400e+01, 0.0000e+00, 9.7000e+01, 1.4000e+00,\n",
            "        9.7000e+01, 1.6000e+00, 7.0000e+00, 7.0000e+00, 5.1400e-01, 1.0000e+01])\n",
            "Target: tensor([64.3000])\n",
            "Prediction: tensor([63.5836])\n",
            "Input: tensor([1.0200e+02, 2.0120e+03, 0.0000e+00, 5.8000e+01, 0.0000e+00, 7.6700e+00,\n",
            "        3.4312e+02, 0.0000e+00, 6.8400e+01, 0.0000e+00, 9.9000e+01, 9.9500e+00,\n",
            "        9.9000e+01, 1.0000e-01, 8.0000e-01, 7.0000e-01, 8.2100e-01, 1.4100e+01])\n",
            "Target: tensor([81.])\n",
            "Prediction: tensor([82.1567])\n",
            "Input: tensor([1.2800e+02, 2.0060e+03, 0.0000e+00, 9.6000e+01, 0.0000e+00, 1.3110e+01,\n",
            "        2.8840e+03, 0.0000e+00, 5.4900e+01, 0.0000e+00, 9.7000e+01, 9.6700e+00,\n",
            "        9.7000e+01, 1.0000e-01, 7.0000e-01, 5.0000e-01, 7.9300e-01, 1.5400e+01])\n",
            "Target: tensor([78.5000])\n",
            "Prediction: tensor([83.4306])\n",
            "Input: tensor([1.0100e+02, 2.0010e+03, 1.0000e+00, 3.4000e+01, 6.0000e+01, 5.1000e-01,\n",
            "        4.3959e+00, 4.4640e+03, 1.6100e+01, 1.1000e+02, 5.6000e+01, 6.3900e+00,\n",
            "        4.9000e+01, 2.4000e+00, 1.8000e+00, 1.7000e+00, 2.9700e-01, 4.6000e+00])\n",
            "Target: tensor([55.])\n",
            "Prediction: tensor([85.3053])\n",
            "Input: tensor([1.1300e+02, 2.0120e+03, 1.0000e+00, 1.6700e+02, 2.0000e+01, 2.6000e-01,\n",
            "        8.0588e+01, 3.3620e+03, 1.7400e+01, 2.5000e+01, 9.0000e+00, 5.8900e+00,\n",
            "        9.0000e+00, 2.0000e-01, 1.6300e+01, 1.6700e+01, 5.3800e-01, 1.2300e+01])\n",
            "Target: tensor([68.9000])\n",
            "Prediction: tensor([72.7527])\n",
            "Input: tensor([1.7800e+02, 2.0000e+03, 1.0000e+00, 1.6800e+02, 1.1000e+01, 8.0100e+00,\n",
            "        0.0000e+00, 2.2000e+01, 5.3400e+01, 1.3000e+01, 8.6000e+01, 4.9100e+00,\n",
            "        7.7000e+01, 1.0000e-01, 1.8000e+00, 1.7000e+00, 6.7000e-01, 1.0600e+01])\n",
            "Target: tensor([72.5000])\n",
            "Prediction: tensor([83.2047])\n",
            "Input: tensor([1.5200e+02, 2.0100e+03, 1.0000e+00, 1.3800e+02, 3.0000e+00, 2.3100e+00,\n",
            "        1.9173e+02, 7.9000e+01, 1.9800e+01, 4.0000e+00, 9.9000e+01, 3.4300e+00,\n",
            "        9.9000e+01, 1.0000e-01, 1.5300e+01, 1.5300e+01, 7.3900e-01, 1.3500e+01])\n",
            "Target: tensor([74.5000])\n",
            "Prediction: tensor([69.7409])\n",
            "Input: tensor([1.7000e+01, 2.0150e+03, 1.0000e+00, 2.4900e+02, 2.5000e+01, 4.6149e+00,\n",
            "        0.0000e+00, 5.5000e+01, 2.5700e+01, 3.9000e+01, 7.8000e+01, 5.9302e+00,\n",
            "        8.2000e+01, 1.0000e+00, 6.9000e+00, 6.8000e+00, 4.8100e-01, 1.0700e+01])\n",
            "Target: tensor([60.])\n",
            "Prediction: tensor([54.6540])\n",
            "Input: tensor([1.4500e+02, 2.0110e+03, 0.0000e+00, 1.2200e+02, 0.0000e+00, 1.0240e+01,\n",
            "        0.0000e+00, 0.0000e+00, 5.6500e+01, 0.0000e+00, 9.9000e+01, 7.9600e+00,\n",
            "        9.9000e+01, 1.0000e-01, 1.2000e+00, 1.3000e+00, 8.2900e-01, 1.5000e+01])\n",
            "Target: tensor([75.6000])\n",
            "Prediction: tensor([81.0089])\n",
            "Input: tensor([4.5000e+01, 2.0090e+03, 1.0000e+00, 2.9200e+02, 2.3800e+02, 2.1300e+00,\n",
            "        0.0000e+00, 5.7000e+01, 1.8600e+01, 3.2300e+02, 7.8000e+01, 5.6100e+00,\n",
            "        7.2000e+01, 1.7000e+00, 1.6000e+00, 1.4000e+00, 6.2742e-01, 1.2000e+01])\n",
            "Target: tensor([56.7000])\n",
            "Prediction: tensor([99.1872])\n",
            "Input: tensor([8.0000e+00, 2.0020e+03, 0.0000e+00, 9.0000e+00, 0.0000e+00, 1.2500e+01,\n",
            "        3.9791e+03, 0.0000e+00, 5.1200e+01, 0.0000e+00, 8.2000e+01, 1.2700e+00,\n",
            "        8.3000e+01, 1.0000e-01, 1.7000e+00, 1.9000e+00, 8.4700e-01, 1.6100e+01])\n",
            "Target: tensor([78.7000])\n",
            "Prediction: tensor([73.5187])\n",
            "Input: tensor([6.2000e+01, 2.0130e+03, 0.0000e+00, 7.1000e+01, 2.0000e+00, 1.0940e+01,\n",
            "        8.9588e+02, 1.7710e+03, 6.1400e+01, 3.0000e+00, 9.4000e+01, 1.1160e+01,\n",
            "        9.5000e+01, 1.0000e-01, 1.1000e+00, 1.1000e+00, 9.1900e-01, 1.6900e+01])\n",
            "Target: tensor([86.])\n",
            "Prediction: tensor([75.1832])\n",
            "Input: tensor([1.7100e+02, 2.0090e+03, 1.0000e+00, 8.4000e+01, 1.0000e+00, 1.7300e+00,\n",
            "        2.9240e+02, 0.0000e+00, 5.5100e+01, 1.0000e+00, 9.4000e+01, 4.5000e+00,\n",
            "        9.3000e+01, 1.0000e-01, 5.1000e+00, 4.9000e+00, 8.3100e-01, 1.3200e+01])\n",
            "Target: tensor([76.])\n",
            "Prediction: tensor([84.8388])\n",
            "Input: tensor([2.7000e+01, 2.0020e+03, 1.0000e+00, 1.4800e+02, 0.0000e+00, 3.8200e+00,\n",
            "        1.5521e+02, 0.0000e+00, 2.2600e+01, 0.0000e+00, 9.2000e+01, 5.1700e+00,\n",
            "        9.1000e+01, 8.0000e-01, 9.2000e+00, 9.1000e+00, 5.6900e-01, 1.1300e+01])\n",
            "Target: tensor([77.])\n",
            "Prediction: tensor([54.0261])\n",
            "Input: tensor([1.3000e+02, 2.0070e+03, 1.0000e+00, 7.7000e+01, 2.0000e+00, 9.0500e+00,\n",
            "        0.0000e+00, 1.9400e+02, 2.8200e+01, 2.0000e+00, 9.1000e+01, 5.9900e+00,\n",
            "        9.1000e+01, 1.0000e-01, 1.5000e+00, 1.0000e+00, 6.2742e-01, 1.2000e+01])\n",
            "Target: tensor([79.8000])\n",
            "Prediction: tensor([77.3488])\n",
            "Input: tensor([6.0000e+00, 2.0000e+03, 1.0000e+00, 1.4200e+02, 1.0000e+00, 2.9000e+00,\n",
            "        3.2756e+01, 1.5000e+01, 4.7100e+01, 1.0000e+00, 9.6000e+01, 6.2500e+00,\n",
            "        9.3000e+01, 1.0000e-01, 2.1000e+00, 2.2000e+00, 6.3900e-01, 1.1200e+01])\n",
            "Target: tensor([72.])\n",
            "Prediction: tensor([56.8215])\n",
            "Input: tensor([9.0000e+01, 2.0050e+03, 0.0000e+00, 2.1600e+02, 0.0000e+00, 9.9200e+00,\n",
            "        8.6926e+01, 2.0000e+00, 5.7000e+01, 0.0000e+00, 9.9000e+01, 6.3700e+00,\n",
            "        9.9000e+01, 1.0000e-01, 2.5000e+00, 2.5000e+00, 7.9100e-01, 1.5900e+01])\n",
            "Target: tensor([76.])\n",
            "Prediction: tensor([66.2525])\n",
            "Input: tensor([3.1000e+01, 2.0000e+03, 1.0000e+00, 4.9000e+01, 1.6000e+01, 1.5100e+00,\n",
            "        3.0784e+01, 3.2070e+03, 1.6500e+01, 2.5000e+01, 3.8000e+01, 4.2400e+00,\n",
            "        3.7000e+01, 1.4300e+01, 1.5000e+00, 1.5000e+00, 3.1200e-01, 5.2000e+00])\n",
            "Target: tensor([46.])\n",
            "Prediction: tensor([66.8473])\n",
            "Input: tensor([2.0000e+00, 2.0080e+03, 1.0000e+00, 1.2600e+02, 2.0000e+01, 4.6000e-01,\n",
            "        4.3087e+01, 2.1700e+02, 5.1800e+01, 2.3000e+01, 9.2000e+01, 4.2000e+00,\n",
            "        9.3000e+01, 1.0000e-01, 6.0000e+00, 5.9000e+00, 6.9700e-01, 1.2600e+01])\n",
            "Target: tensor([74.1000])\n",
            "Prediction: tensor([61.7876])\n",
            "Input: tensor([1.3700e+02, 2.0050e+03, 1.0000e+00, 1.6000e+01, 0.0000e+00, 3.6300e+00,\n",
            "        2.8747e+02, 0.0000e+00, 6.9700e+01, 0.0000e+00, 5.5000e+01, 4.4700e+00,\n",
            "        4.9000e+01, 1.0000e-01, 2.0000e-01, 2.0000e-01, 6.7100e-01, 1.2600e+01])\n",
            "Target: tensor([71.6000])\n",
            "Prediction: tensor([92.7284])\n",
            "Input: tensor([4.6000e+01, 2.0060e+03, 0.0000e+00, 9.3000e+01, 0.0000e+00, 1.1020e+01,\n",
            "        8.5095e+02, 2.7000e+01, 5.5400e+01, 0.0000e+00, 9.3000e+01, 9.9200e+00,\n",
            "        9.3000e+01, 1.0000e-01, 1.2000e+00, 9.0000e-01, 9.0200e-01, 1.6900e+01])\n",
            "Target: tensor([78.1000])\n",
            "Prediction: tensor([71.0092])\n",
            "Input: tensor([3.0000e+01, 2.0140e+03, 1.0000e+00, 6.5000e+01, 2.0000e+00, 8.1000e+00,\n",
            "        1.0219e+02, 4.1800e+02, 6.6400e+01, 2.0000e+00, 9.1000e+01, 1.4500e+00,\n",
            "        9.1000e+01, 1.0000e-01, 5.0000e-01, 5.0000e-01, 9.1200e-01, 1.5900e+01])\n",
            "Target: tensor([82.])\n",
            "Prediction: tensor([71.0264])\n",
            "Input: tensor([1.4400e+02, 2.0150e+03, 0.0000e+00, 5.5000e+01, 0.0000e+00, 1.7900e+00,\n",
            "        0.0000e+00, 0.0000e+00, 3.3200e+01, 0.0000e+00, 9.6000e+01, 5.9302e+00,\n",
            "        9.6000e+01, 1.0000e-01, 2.2000e+00, 2.2000e+00, 9.2400e-01, 1.5400e+01])\n",
            "Target: tensor([83.1000])\n",
            "Prediction: tensor([79.5298])\n",
            "Input: tensor([1.1800e+02, 2.0010e+03, 1.0000e+00, 4.8000e+01, 5.7400e+02, 9.5800e+00,\n",
            "        1.5831e+01, 1.6811e+05, 1.7300e+01, 9.3600e+02, 3.6000e+01, 3.2500e+00,\n",
            "        2.7000e+01, 5.1000e+00, 1.4100e+01, 1.4100e+01, 0.0000e+00, 8.0000e+00])\n",
            "Target: tensor([47.4000])\n",
            "Prediction: tensor([62.2536])\n",
            "Input: tensor([6.6000e+01, 2.0080e+03, 1.0000e+00, 1.9000e+01, 1.3000e+01, 2.2100e+00,\n",
            "        4.7222e+02, 0.0000e+00, 4.5900e+01, 1.5000e+01, 9.6000e+01, 6.6500e+00,\n",
            "        9.5000e+01, 4.0000e-01, 1.3000e+00, 1.3000e+00, 5.8900e-01, 1.0400e+01])\n",
            "Target: tensor([79.])\n",
            "Prediction: tensor([76.9431])\n",
            "Input: tensor([1.0200e+02, 2.0070e+03, 0.0000e+00, 6.5000e+01, 0.0000e+00, 7.4500e+00,\n",
            "        2.5789e+03, 2.0000e+00, 6.6100e+01, 0.0000e+00, 7.6000e+01, 8.3600e+00,\n",
            "        7.4000e+01, 1.0000e-01, 7.0000e-01, 7.0000e-01, 8.0800e-01, 1.4400e+01])\n",
            "Target: tensor([79.6000])\n",
            "Prediction: tensor([84.8806])\n",
            "Input: tensor([1.0000e+00, 2.0030e+03, 1.0000e+00, 1.8000e+01, 1.0000e+00, 4.2900e+00,\n",
            "        1.4719e+01, 8.0000e+00, 4.7900e+01, 1.0000e+00, 9.7000e+01, 6.2700e+00,\n",
            "        9.7000e+01, 1.0000e-01, 1.9000e+00, 2.0000e+00, 6.7400e-01, 1.0700e+01])\n",
            "Target: tensor([72.8000])\n",
            "Prediction: tensor([65.7513])\n",
            "Input: tensor([1.7800e+02, 2.0080e+03, 1.0000e+00, 1.6800e+02, 9.0000e+00, 8.1800e+00,\n",
            "        0.0000e+00, 0.0000e+00, 5.8200e+01, 1.0000e+01, 7.6000e+01, 3.9800e+00,\n",
            "        5.0000e+00, 1.0000e-01, 1.6000e+00, 1.5000e+00, 7.4500e-01, 1.3400e+01])\n",
            "Target: tensor([73.2000])\n",
            "Prediction: tensor([79.0994])\n",
            "Input: tensor([1.5000e+01, 2.0140e+03, 0.0000e+00, 7.6000e+01, 0.0000e+00, 1.2600e+01,\n",
            "        7.1633e+03, 7.0000e+01, 6.3400e+01, 1.0000e+00, 9.9000e+01, 1.5900e+00,\n",
            "        9.9000e+01, 1.0000e-01, 1.0000e+00, 1.0000e+00, 8.9000e-01, 1.6300e+01])\n",
            "Target: tensor([89.])\n",
            "Prediction: tensor([72.8893])\n",
            "Input: tensor([2.1000e+01, 2.0120e+03, 1.0000e+00, 3.0000e+00, 2.0000e+00, 1.0000e-02,\n",
            "        1.2834e+01, 7.0000e+00, 3.6200e+01, 3.0000e+00, 9.6000e+01, 6.2700e+00,\n",
            "        9.5000e+01, 4.4000e+00, 7.3000e+00, 7.0000e+00, 6.8700e-01, 1.2500e+01])\n",
            "Target: tensor([63.4000])\n",
            "Prediction: tensor([65.6730])\n",
            "Input: tensor([1.7500e+02, 2.0020e+03, 1.0000e+00, 1.2400e+02, 1.0000e+00, 5.8600e+00,\n",
            "        2.7469e+01, 0.0000e+00, 5.6300e+01, 1.0000e+00, 9.3000e+01, 7.1800e+00,\n",
            "        9.5000e+01, 1.0000e-01, 1.7000e+00, 1.7000e+00, 7.4600e-01, 1.4700e+01])\n",
            "Target: tensor([75.4000])\n",
            "Prediction: tensor([84.4632])\n",
            "Input: tensor([9.0000e+00, 2.0120e+03, 1.0000e+00, 1.2300e+02, 5.0000e+00, 1.0000e-02,\n",
            "        2.8561e+02, 0.0000e+00, 4.9700e+01, 6.0000e+00, 9.2000e+01, 5.3700e+00,\n",
            "        8.9000e+01, 1.0000e-01, 2.8000e+00, 2.8000e+00, 7.4200e-01, 1.1800e+01])\n",
            "Target: tensor([71.9000])\n",
            "Prediction: tensor([60.1516])\n",
            "Input: tensor([1.2000e+01, 2.0020e+03, 1.0000e+00, 1.6400e+02, 2.0700e+02, 1.0000e-02,\n",
            "        3.9723e-01, 3.4840e+03, 1.1200e+01, 2.8000e+02, 8.3000e+01, 2.5900e+00,\n",
            "        8.3000e+01, 1.0000e-01, 2.5000e+00, 2.1100e+01, 4.7600e-01, 7.7000e+00])\n",
            "Target: tensor([66.3000])\n",
            "Prediction: tensor([87.3849])\n",
            "Input: tensor([1.0400e+02, 2.0090e+03, 1.0000e+00, 1.6600e+02, 0.0000e+00, 2.8300e+00,\n",
            "        6.2424e+02, 1.5000e+01, 3.2000e+00, 0.0000e+00, 9.9000e+01, 4.9700e+00,\n",
            "        9.9000e+01, 1.0000e-01, 7.3000e+00, 7.3000e+00, 7.3400e-01, 1.3800e+01])\n",
            "Target: tensor([72.8000])\n",
            "Prediction: tensor([59.4686])\n",
            "Input: tensor([0.0000e+00, 2.0060e+03, 1.0000e+00, 2.9500e+02, 8.4000e+01, 3.0000e-02,\n",
            "        1.7172e+01, 1.9900e+03, 1.4700e+01, 1.1600e+02, 5.8000e+01, 7.4300e+00,\n",
            "        5.8000e+01, 1.0000e-01, 1.9200e+01, 1.9300e+01, 4.0500e-01, 8.1000e+00])\n",
            "Target: tensor([57.3000])\n",
            "Prediction: tensor([56.8974])\n",
            "Input: tensor([1.0600e+02, 2.0090e+03, 1.0000e+00, 1.7200e+02, 0.0000e+00, 2.0600e+00,\n",
            "        0.0000e+00, 0.0000e+00, 6.5800e+01, 0.0000e+00, 8.1000e+01, 1.3440e+01,\n",
            "        9.1000e+01, 1.0000e-01, 2.0000e-01, 2.0000e-01, 6.2900e-01, 1.1400e+01])\n",
            "Target: tensor([68.5000])\n",
            "Prediction: tensor([76.0481])\n",
            "Input: tensor([1.3300e+02, 2.0140e+03, 1.0000e+00, 2.2500e+02, 1.3000e+01, 1.0120e+01,\n",
            "        1.3406e+03, 4.7110e+03, 5.9900e+01, 1.5000e+01, 9.7000e+01, 7.7000e+00,\n",
            "        9.7000e+01, 1.0000e-01, 2.3000e+00, 2.3000e+00, 8.0300e-01, 1.4900e+01])\n",
            "Target: tensor([73.])\n",
            "Prediction: tensor([72.2499])\n",
            "Input: tensor([1.3500e+02, 2.0130e+03, 1.0000e+00, 1.4100e+02, 0.0000e+00, 9.7300e+00,\n",
            "        0.0000e+00, 0.0000e+00, 4.5900e+01, 0.0000e+00, 9.9000e+01, 7.8500e+00,\n",
            "        9.9000e+01, 1.0000e-01, 4.3000e+00, 4.3000e+00, 7.3400e-01, 1.3100e+01])\n",
            "Target: tensor([74.8000])\n",
            "Prediction: tensor([75.6011])\n",
            "Input: tensor([1.3400e+02, 2.0020e+03, 1.0000e+00, 4.1500e+02, 3.1000e+01, 7.8200e+00,\n",
            "        1.9660e+00, 2.7380e+03, 1.4100e+01, 5.0000e+01, 8.5000e+01, 4.1800e+00,\n",
            "        8.8000e+01, 8.0000e+00, 7.2000e+00, 7.4000e+00, 3.4300e-01, 7.2000e+00])\n",
            "Target: tensor([57.])\n",
            "Prediction: tensor([53.9304])\n",
            "Input: tensor([1.0100e+02, 2.0080e+03, 1.0000e+00, 2.7800e+02, 5.5000e+01, 5.7000e-01,\n",
            "        1.0214e+02, 9.8000e+01, 1.9600e+01, 9.4000e+01, 7.4000e+01, 6.7400e+00,\n",
            "        7.4000e+01, 1.6000e+00, 9.2000e+00, 9.0000e+00, 3.6000e-01, 5.8000e+00])\n",
            "Target: tensor([55.5000])\n",
            "Prediction: tensor([68.6738])\n",
            "Input: tensor([5.4000e+01, 2.0110e+03, 1.0000e+00, 1.3800e+02, 0.0000e+00, 1.0000e-02,\n",
            "        2.1469e+03, 7.0000e+00, 5.8000e+01, 0.0000e+00, 9.3000e+01, 5.8300e+00,\n",
            "        9.3000e+01, 1.0000e-01, 1.9000e+00, 2.0000e+00, 8.3800e-01, 1.6400e+01])\n",
            "Target: tensor([76.1000])\n",
            "Prediction: tensor([67.2789])\n",
            "Input: tensor([8.3000e+01, 2.0130e+03, 1.0000e+00, 1.1400e+02, 4.0000e+00, 4.0000e-01,\n",
            "        5.4662e+02, 1.2000e+02, 6.4000e+01, 4.0000e+00, 9.8000e+01, 7.2300e+00,\n",
            "        9.8000e+01, 1.0000e-01, 3.9000e+00, 3.9000e+00, 7.3700e-01, 1.3100e+01])\n",
            "Target: tensor([73.9000])\n",
            "Prediction: tensor([73.1600])\n",
            "Input: tensor([1.6900e+02, 2.0140e+03, 1.0000e+00, 3.8000e+01, 6.8000e+01, 1.0000e-02,\n",
            "        1.4168e+01, 3.1400e+02, 1.8100e+01, 9.7000e+01, 8.2000e+01, 7.2200e+00,\n",
            "        7.8000e+01, 3.2000e+00, 5.7000e+00, 5.6000e+00, 4.8300e-01, 1.0000e+01])\n",
            "Target: tensor([61.5000])\n",
            "Prediction: tensor([96.0434])\n",
            "Input: tensor([3.9000e+01, 2.0080e+03, 0.0000e+00, 1.1600e+02, 0.0000e+00, 1.2060e+01,\n",
            "        2.4254e+03, 5.1000e+01, 5.9400e+01, 0.0000e+00, 9.6000e+01, 7.7000e+00,\n",
            "        9.6000e+01, 1.0000e-01, 1.7000e+00, 1.7000e+00, 8.0000e-01, 1.4300e+01])\n",
            "Target: tensor([76.])\n",
            "Prediction: tensor([69.8588])\n",
            "Input: tensor([1.5400e+02, 2.0120e+03, 1.0000e+00, 1.7800e+02, 0.0000e+00, 5.7300e+00,\n",
            "        1.1683e+03, 0.0000e+00, 5.6300e+01, 0.0000e+00, 8.4000e+01, 6.9000e+00,\n",
            "        8.4000e+01, 9.0000e-01, 3.5000e+00, 3.4000e+00, 7.0800e-01, 1.2700e+01])\n",
            "Target: tensor([71.3000])\n",
            "Prediction: tensor([79.1917])\n",
            "Input: tensor([5.0000e+01, 2.0090e+03, 1.0000e+00, 1.7400e+02, 5.4000e+01, 2.1000e-01,\n",
            "        0.0000e+00, 6.0800e+02, 5.6200e+01, 6.4000e+01, 9.7000e+01, 5.1000e+00,\n",
            "        9.7000e+01, 1.0000e-01, 3.0000e+00, 3.0000e+00, 6.5900e-01, 1.2000e+01])\n",
            "Target: tensor([69.9000])\n",
            "Prediction: tensor([72.5140])\n",
            "Input: tensor([6.6000e+01, 2.0140e+03, 1.0000e+00, 1.8700e+02, 1.0000e+01, 1.8800e+00,\n",
            "        6.5753e+02, 0.0000e+00, 4.9900e+01, 1.3000e+01, 6.5000e+01, 6.2000e+00,\n",
            "        7.3000e+01, 4.0000e-01, 1.2000e+00, 1.2000e+00, 6.1400e-01, 1.0700e+01])\n",
            "Target: tensor([71.7000])\n",
            "Prediction: tensor([69.7476])\n",
            "Input: tensor([1.8200e+02, 2.0020e+03, 1.0000e+00, 7.3000e+01, 2.5000e+01, 4.4300e+00,\n",
            "        0.0000e+00, 3.0400e+02, 2.6300e+01, 4.0000e+01, 7.3000e+01, 6.5300e+00,\n",
            "        7.1000e+01, 3.9800e+01, 1.2000e+00, 1.3000e+00, 4.2700e-01, 1.0000e+01])\n",
            "Target: tensor([44.8000])\n",
            "Prediction: tensor([86.1654])\n",
            "Input: tensor([7.3000e+01, 2.0060e+03, 0.0000e+00, 6.1000e+01, 0.0000e+00, 7.2000e+00,\n",
            "        1.0031e+03, 0.0000e+00, 5.7400e+01, 0.0000e+00, 9.7000e+01, 8.9600e+00,\n",
            "        9.7000e+01, 1.0000e-01, 9.0000e-01, 9.0000e-01, 8.8400e-01, 1.8100e+01])\n",
            "Target: tensor([81.1000])\n",
            "Prediction: tensor([76.0444])\n",
            "Input: tensor([1.5900e+02, 2.0010e+03, 1.0000e+00, 1.9400e+02, 1.3000e+01, 8.6000e-01,\n",
            "        1.1420e+00, 3.8000e+01, 3.1600e+01, 1.6000e+01, 8.4000e+01, 4.5900e+00,\n",
            "        8.5000e+01, 3.0000e-01, 4.1000e+00, 4.1000e+00, 5.3500e-01, 9.7000e+00])\n",
            "Target: tensor([64.])\n",
            "Prediction: tensor([74.3516])\n",
            "Input: tensor([4.6000e+01, 2.0140e+03, 0.0000e+00, 7.3000e+01, 0.0000e+00, 9.6400e+00,\n",
            "        1.0469e+04, 2.7000e+01, 5.8400e+01, 0.0000e+00, 9.4000e+01, 1.8000e+00,\n",
            "        9.4000e+01, 1.0000e-01, 1.1000e+00, 9.0000e-01, 9.2600e-01, 1.9200e+01])\n",
            "Target: tensor([84.])\n",
            "Prediction: tensor([78.7641])\n",
            "Input: tensor([2.6000e+01, 2.0130e+03, 1.0000e+00, 3.3000e+01, 2.2000e+01, 1.0000e-02,\n",
            "        4.0151e+01, 0.0000e+00, 1.7600e+01, 3.2000e+01, 9.6000e+01, 8.3000e+00,\n",
            "        9.6000e+01, 1.0000e+00, 7.4000e+00, 7.4000e+00, 3.9800e-01, 1.0500e+01])\n",
            "Target: tensor([58.6000])\n",
            "Prediction: tensor([65.8791])\n",
            "Input: tensor([1.0800e+02, 2.0140e+03, 1.0000e+00, 1.7000e+01, 0.0000e+00, 1.0000e-02,\n",
            "        7.2603e+02, 0.0000e+00, 6.1300e+01, 0.0000e+00, 9.1000e+01, 6.4200e+00,\n",
            "        9.1000e+01, 1.0000e-01, 1.8000e+00, 1.9000e+00, 8.0300e-01, 1.5100e+01])\n",
            "Target: tensor([75.9000])\n",
            "Prediction: tensor([83.3198])\n",
            "Input: tensor([7.0000e+00, 2.0100e+03, 0.0000e+00, 6.4000e+01, 1.0000e+00, 1.0520e+01,\n",
            "        8.8758e+03, 7.0000e+01, 6.3900e+01, 1.0000e+00, 9.2000e+01, 9.2000e+00,\n",
            "        9.2000e+01, 1.0000e-01, 7.0000e-01, 6.0000e-01, 9.2700e-01, 1.9500e+01])\n",
            "Target: tensor([81.9000])\n",
            "Prediction: tensor([75.4940])\n",
            "Input: tensor([9.4000e+01, 2.0110e+03, 1.0000e+00, 1.6100e+02, 2.0000e+00, 1.0000e-02,\n",
            "        3.6116e+01, 0.0000e+00, 6.9000e+00, 2.0000e+00, 9.8000e+01, 4.7700e+00,\n",
            "        9.8000e+01, 1.0000e-01, 5.6000e+00, 5.4000e+00, 7.5600e-01, 1.4000e+01])\n",
            "Target: tensor([71.3000])\n",
            "Prediction: tensor([59.0568])\n",
            "Input: tensor([1.0200e+02, 2.0110e+03, 0.0000e+00, 5.9000e+01, 0.0000e+00, 6.9100e+00,\n",
            "        3.6013e+03, 3.0000e+00, 6.8000e+01, 0.0000e+00, 9.6000e+01, 9.6000e+00,\n",
            "        9.6000e+01, 1.0000e-01, 8.0000e-01, 7.0000e-01, 8.2600e-01, 1.4800e+01])\n",
            "Target: tensor([87.])\n",
            "Prediction: tensor([84.5002])\n",
            "Input: tensor([1.0600e+02, 2.0120e+03, 1.0000e+00, 1.6800e+02, 0.0000e+00, 2.9800e+00,\n",
            "        0.0000e+00, 0.0000e+00, 6.7500e+01, 0.0000e+00, 8.1000e+01, 1.2770e+01,\n",
            "        8.1000e+01, 1.0000e-01, 2.0000e-01, 2.0000e-01, 6.4000e-01, 1.1700e+01])\n",
            "Target: tensor([69.])\n",
            "Prediction: tensor([75.8974])\n",
            "Input: tensor([1.0200e+02, 2.0010e+03, 0.0000e+00, 7.9000e+01, 0.0000e+00, 5.6200e+00,\n",
            "        1.3002e+02, 2.0000e+00, 6.2800e+01, 0.0000e+00, 9.5000e+01, 7.1100e+00,\n",
            "        9.5000e+01, 1.0000e-01, 7.0000e-01, 7.0000e-01, 7.8300e-01, 1.3700e+01])\n",
            "Target: tensor([77.8000])\n",
            "Prediction: tensor([78.7090])\n",
            "Input: tensor([1.3600e+02, 2.0150e+03, 1.0000e+00, 1.5600e+02, 0.0000e+00, 4.6149e+00,\n",
            "        0.0000e+00, 0.0000e+00, 5.4100e+01, 0.0000e+00, 9.7000e+01, 5.9302e+00,\n",
            "        9.8000e+01, 1.0000e-01, 3.5000e+00, 3.4000e+00, 7.2000e-01, 1.3300e+01])\n",
            "Target: tensor([73.2000])\n",
            "Prediction: tensor([75.4321])\n",
            "Input: tensor([1.3000e+01, 2.0100e+03, 1.0000e+00, 1.6000e+01, 0.0000e+00, 8.4100e+00,\n",
            "        1.5496e+02, 0.0000e+00, 5.7000e+00, 0.0000e+00, 9.0000e+00, 6.1700e+00,\n",
            "        8.6000e+01, 1.0000e-01, 3.8000e+00, 3.8000e+00, 7.8100e-01, 1.5800e+01])\n",
            "Target: tensor([74.7000])\n",
            "Prediction: tensor([77.5133])\n",
            "Input: tensor([1.3200e+02, 2.0010e+03, 0.0000e+00, 1.7900e+02, 4.0000e+00, 9.7800e+00,\n",
            "        1.8011e+02, 1.0000e+01, 5.1900e+01, 5.0000e+00, 9.9000e+01, 4.3600e+00,\n",
            "        9.9000e+01, 1.0000e-01, 3.8000e+00, 4.2000e+00, 7.0800e-01, 1.1700e+01])\n",
            "Target: tensor([78.])\n",
            "Prediction: tensor([73.9146])\n",
            "Input: tensor([1.1000e+02, 2.0030e+03, 1.0000e+00, 4.2400e+02, 8.5000e+01, 1.6800e+00,\n",
            "        4.2527e+01, 2.8898e+04, 1.7700e+01, 1.2400e+02, 6.7000e+01, 6.3900e+00,\n",
            "        8.5000e+01, 1.5300e+01, 4.0000e+00, 3.9000e+00, 3.1800e-01, 6.7000e+00])\n",
            "Target: tensor([51.])\n",
            "Prediction: tensor([42.3487])\n",
            "Input: tensor([1.9000e+01, 2.0000e+03, 1.0000e+00, 2.4300e+02, 1.5000e+01, 2.3200e+00,\n",
            "        0.0000e+00, 1.2200e+02, 4.2600e+01, 2.0000e+01, 7.4000e+01, 5.6700e+00,\n",
            "        7.5000e+01, 1.0000e-01, 1.5000e+00, 1.4000e+00, 6.0000e-01, 1.3300e+01])\n",
            "Target: tensor([62.6000])\n",
            "Prediction: tensor([56.2520])\n",
            "Input: tensor([1.6100e+02, 2.0120e+03, 1.0000e+00, 1.5000e+01, 0.0000e+00, 1.2300e+00,\n",
            "        0.0000e+00, 7.0000e+00, 5.8500e+01, 0.0000e+00, 9.7000e+01, 6.7600e+00,\n",
            "        9.5000e+01, 1.0000e-01, 2.2000e+00, 2.2000e+00, 7.3900e-01, 1.2900e+01])\n",
            "Target: tensor([75.1000])\n",
            "Prediction: tensor([88.9719])\n",
            "Input: tensor([4.3000e+01, 2.0080e+03, 1.0000e+00, 4.3700e+02, 6.0000e+01, 2.6900e+00,\n",
            "        0.0000e+00, 1.2000e+01, 2.3800e+01, 8.5000e+01, 5.8000e+01, 6.2100e+00,\n",
            "        7.4000e+01, 4.1000e+00, 6.6000e+00, 6.6000e+00, 6.2742e-01, 1.2000e+01])\n",
            "Target: tensor([54.])\n",
            "Prediction: tensor([54.4808])\n",
            "Input: tensor([2.7000e+01, 2.0090e+03, 1.0000e+00, 1.2400e+02, 0.0000e+00, 4.4500e+00,\n",
            "        3.3998e+02, 0.0000e+00, 2.6800e+01, 0.0000e+00, 9.9000e+01, 4.2400e+00,\n",
            "        9.9000e+01, 4.0000e-01, 7.6000e+00, 7.6000e+00, 6.2100e-01, 1.2400e+01])\n",
            "Target: tensor([72.4000])\n",
            "Prediction: tensor([56.4558])\n",
            "Input: tensor([3.1000e+01, 2.0020e+03, 1.0000e+00, 5.8000e+01, 1.7000e+01, 1.4700e+00,\n",
            "        3.1594e+01, 9.3800e+02, 1.7200e+01, 2.5000e+01, 4.2000e+01, 4.1600e+00,\n",
            "        4.4000e+01, 1.3400e+01, 1.2000e+00, 1.2000e+00, 3.1500e-01, 5.4000e+00])\n",
            "Target: tensor([45.6000])\n",
            "Prediction: tensor([68.4792])\n",
            "Input: tensor([1.1600e+02, 2.0060e+03, 1.0000e+00, 1.7000e+01, 3.0000e+00, 3.6900e+00,\n",
            "        2.1411e+01, 0.0000e+00, 4.7100e+01, 4.0000e+00, 8.8000e+01, 6.3300e+00,\n",
            "        8.8000e+01, 3.0000e-01, 2.0000e+00, 1.9000e+00, 5.9700e-01, 1.1000e+01])\n",
            "Target: tensor([73.])\n",
            "Prediction: tensor([82.7991])\n",
            "Input: tensor([1.1200e+02, 2.0080e+03, 1.0000e+00, 3.1700e+02, 3.0000e+00, 6.2800e+00,\n",
            "        5.9550e+01, 0.0000e+00, 3.2000e+00, 4.0000e+00, 8.3000e+01, 7.1500e+00,\n",
            "        8.3000e+01, 1.1700e+01, 1.1500e+01, 1.1400e+01, 5.8900e-01, 1.1300e+01])\n",
            "Target: tensor([61.7000])\n",
            "Prediction: tensor([51.0231])\n",
            "Input: tensor([6.4000e+01, 2.0030e+03, 1.0000e+00, 8.1000e+01, 0.0000e+00, 9.4600e+00,\n",
            "        2.1249e+03, 0.0000e+00, 5.9200e+01, 1.0000e+00, 9.3000e+01, 8.6100e+00,\n",
            "        9.4000e+01, 1.0000e-01, 8.0000e-01, 8.0000e-01, 8.2300e-01, 1.5200e+01])\n",
            "Target: tensor([79.1000])\n",
            "Prediction: tensor([75.3840])\n",
            "Input: tensor([6.7000e+01, 2.0080e+03, 1.0000e+00, 3.3000e+01, 3.0000e+01, 2.1000e-01,\n",
            "        1.9685e+01, 8.9000e+01, 1.9800e+01, 4.7000e+01, 5.9000e+01, 3.2100e+00,\n",
            "        6.0000e+00, 2.3000e+00, 8.6000e+00, 8.6000e+00, 3.7100e-01, 7.9000e+00])\n",
            "Target: tensor([56.8000])\n",
            "Prediction: tensor([71.7736])\n",
            "Input: tensor([9.6000e+01, 2.0090e+03, 0.0000e+00, 7.6000e+01, 0.0000e+00, 1.1420e+01,\n",
            "        2.0524e+03, 0.0000e+00, 5.8800e+01, 0.0000e+00, 9.6000e+01, 8.1100e+00,\n",
            "        9.9000e+01, 1.0000e-01, 9.0000e-01, 9.0000e-01, 8.8800e-01, 1.3500e+01])\n",
            "Target: tensor([83.])\n",
            "Prediction: tensor([80.5188])\n",
            "Input: tensor([5.9000e+01, 2.0050e+03, 1.0000e+00, 3.7000e+01, 2.0000e+00, 7.7200e+00,\n",
            "        3.5324e+02, 0.0000e+00, 3.8000e+00, 3.0000e+00, 4.4000e+01, 2.7600e+00,\n",
            "        4.5000e+01, 1.0900e+01, 7.2000e+00, 7.1000e+00, 6.4000e-01, 1.2400e+01])\n",
            "Target: tensor([65.])\n",
            "Prediction: tensor([68.9020])\n",
            "Input: tensor([1.6400e+02, 2.0140e+03, 1.0000e+00, 1.3500e+02, 0.0000e+00, 1.0000e-02,\n",
            "        5.6597e+02, 0.0000e+00, 7.4800e+01, 0.0000e+00, 8.2000e+01, 5.1800e+00,\n",
            "        8.0000e+00, 1.0000e-01, 1.0000e-01, 1.0000e-01, 7.1600e-01, 1.4300e+01])\n",
            "Target: tensor([73.3000])\n",
            "Prediction: tensor([79.1420])\n",
            "Input: tensor([2.5000e+01, 2.0000e+03, 1.0000e+00, 3.4800e+02, 4.8000e+01, 3.7100e+00,\n",
            "        1.9839e+01, 6.0740e+03, 1.2200e+01, 9.2000e+01, 4.5000e+01, 5.6000e+00,\n",
            "        4.5000e+01, 4.0000e+00, 1.1400e+01, 1.1100e+01, 0.0000e+00, 3.4000e+00])\n",
            "Target: tensor([51.])\n",
            "Prediction: tensor([48.4930])\n",
            "Input: tensor([4.2000e+01, 2.0070e+03, 0.0000e+00, 1.7000e+01, 0.0000e+00, 1.3430e+01,\n",
            "        0.0000e+00, 2.0000e+00, 6.2200e+01, 0.0000e+00, 9.9000e+01, 6.5200e+00,\n",
            "        9.9000e+01, 1.0000e-01, 2.0000e+00, 2.1000e+00, 6.2742e-01, 1.2000e+01])\n",
            "Target: tensor([76.8000])\n",
            "Prediction: tensor([75.8607])\n",
            "Input: tensor([1.1500e+02, 2.0110e+03, 0.0000e+00, 7.2000e+01, 0.0000e+00, 9.4700e+00,\n",
            "        8.3424e+03, 5.9700e+02, 6.5300e+01, 0.0000e+00, 9.5000e+01, 1.1240e+01,\n",
            "        9.5000e+01, 1.0000e-01, 3.0000e-01, 3.0000e-01, 9.0100e-01, 1.9700e+01])\n",
            "Target: tensor([86.])\n",
            "Prediction: tensor([88.6243])\n",
            "Input: tensor([1.4000e+02, 2.0090e+03, 1.0000e+00, 2.1900e+02, 2.1000e+01, 3.0000e-01,\n",
            "        1.1775e+00, 9.9900e+02, 2.1200e+01, 3.3000e+01, 8.3000e+01, 4.8100e+00,\n",
            "        8.6000e+01, 5.0000e-01, 1.6000e+00, 1.5000e+00, 4.4400e-01, 7.5000e+00])\n",
            "Target: tensor([63.5000])\n",
            "Prediction: tensor([70.1075])\n",
            "Input: tensor([1.3100e+02, 2.0130e+03, 1.0000e+00, 1.6300e+02, 1.0000e+00, 1.0490e+01,\n",
            "        0.0000e+00, 2.7000e+01, 5.2100e+01, 1.0000e+00, 9.2000e+01, 1.5000e+00,\n",
            "        9.0000e+00, 1.0000e-01, 2.7000e+00, 2.9000e+00, 6.2742e-01, 1.2000e+01])\n",
            "Target: tensor([71.7000])\n",
            "Prediction: tensor([67.3192])\n",
            "Input: tensor([1.7900e+02, 2.0040e+03, 1.0000e+00, 1.3600e+02, 2.9000e+01, 2.8600e+00,\n",
            "        0.0000e+00, 2.1700e+02, 1.9000e+00, 3.6000e+01, 9.6000e+01, 5.9000e+00,\n",
            "        9.6000e+01, 2.0000e-01, 1.5400e+01, 1.6100e+01, 6.0100e-01, 1.1000e+01])\n",
            "Target: tensor([74.2000])\n",
            "Prediction: tensor([75.9441])\n",
            "Input: tensor([1.5100e+02, 2.0020e+03, 0.0000e+00, 8.3000e+01, 2.0000e+00, 1.2260e+01,\n",
            "        2.2835e+02, 6.7000e+01, 5.8800e+01, 2.0000e+00, 9.8000e+01, 7.2500e+00,\n",
            "        9.8000e+01, 1.0000e-01, 6.0000e-01, 5.0000e-01, 8.2800e-01, 1.5700e+01])\n",
            "Target: tensor([79.5000])\n",
            "Prediction: tensor([85.8294])\n",
            "Input: tensor([6.9000e+01, 2.0050e+03, 1.0000e+00, 2.3800e+02, 1.0000e+00, 7.3500e+00,\n",
            "        1.7464e+01, 0.0000e+00, 3.9000e+01, 1.0000e+00, 9.3000e+01, 5.8300e+00,\n",
            "        9.3000e+01, 1.8000e+00, 5.7000e+00, 5.5000e+00, 6.1900e-01, 1.1400e+01])\n",
            "Target: tensor([65.])\n",
            "Prediction: tensor([57.9343])\n",
            "Input: tensor([1.0600e+02, 2.0070e+03, 1.0000e+00, 1.7500e+02, 0.0000e+00, 1.6400e+00,\n",
            "        0.0000e+00, 0.0000e+00, 6.4700e+01, 0.0000e+00, 7.9000e+01, 1.1990e+01,\n",
            "        7.9000e+01, 1.0000e-01, 2.0000e-01, 2.0000e-01, 6.2500e-01, 1.1000e+01])\n",
            "Target: tensor([68.2000])\n",
            "Prediction: tensor([74.5611])\n",
            "Input: tensor([1.1600e+02, 2.0110e+03, 1.0000e+00, 1.4700e+02, 3.0000e+00, 3.3900e+00,\n",
            "        3.2161e+02, 0.0000e+00, 5.9000e+00, 3.0000e+00, 9.9000e+01, 6.3900e+00,\n",
            "        9.8000e+01, 1.0000e-01, 1.8000e+00, 1.8000e+00, 6.2000e-01, 1.1500e+01])\n",
            "Target: tensor([74.5000])\n",
            "Prediction: tensor([64.6875])\n",
            "Input: tensor([4.1000e+01, 2.0150e+03, 0.0000e+00, 5.2000e+01, 0.0000e+00, 4.6149e+00,\n",
            "        0.0000e+00, 0.0000e+00, 6.3000e+00, 0.0000e+00, 9.7000e+01, 5.9302e+00,\n",
            "        9.7000e+01, 1.0000e-01, 1.0000e+00, 1.0000e+00, 8.5400e-01, 1.4300e+01])\n",
            "Target: tensor([85.])\n",
            "Prediction: tensor([61.3669])\n",
            "Input: tensor([1.7300e+02, 2.0070e+03, 1.0000e+00, 4.1100e+02, 9.4000e+01, 4.4000e+00,\n",
            "        0.0000e+00, 7.7260e+03, 1.9100e+01, 1.4100e+02, 8.8000e+01, 4.7200e+00,\n",
            "        8.3000e+01, 8.5000e+00, 7.5000e+00, 7.4000e+00, 6.2742e-01, 1.2000e+01])\n",
            "Target: tensor([54.5000])\n",
            "Prediction: tensor([68.2406])\n",
            "Input: tensor([1.3200e+02, 2.0040e+03, 0.0000e+00, 1.6500e+02, 4.0000e+00, 9.8200e+00,\n",
            "        4.3133e+02, 1.1700e+02, 5.3400e+01, 4.0000e+00, 9.7000e+01, 5.4300e+00,\n",
            "        9.7000e+01, 1.0000e-01, 3.4000e+00, 3.9000e+00, 7.3300e-01, 1.2900e+01])\n",
            "Target: tensor([71.7000])\n",
            "Prediction: tensor([75.7633])\n",
            "Input: tensor([1.3500e+02, 2.0030e+03, 1.0000e+00, 1.7100e+02, 0.0000e+00, 1.2550e+01,\n",
            "        0.0000e+00, 0.0000e+00, 3.8400e+01, 0.0000e+00, 9.1000e+01, 6.1000e+00,\n",
            "        9.0000e+00, 2.0000e-01, 4.4000e+00, 4.4000e+00, 6.8400e-01, 1.2400e+01])\n",
            "Target: tensor([72.2000])\n",
            "Prediction: tensor([65.1961])\n",
            "Input: tensor([0.0000e+00, 2.0130e+03, 1.0000e+00, 2.6800e+02, 6.6000e+01, 1.0000e-02,\n",
            "        7.3219e+01, 4.3000e+02, 1.8100e+01, 8.9000e+01, 6.2000e+01, 8.1300e+00,\n",
            "        6.4000e+01, 1.0000e-01, 1.7700e+01, 1.7700e+01, 4.7000e-01, 9.9000e+00])\n",
            "Target: tensor([59.9000])\n",
            "Prediction: tensor([57.1604])\n",
            "Input: tensor([5.0000e+01, 2.0030e+03, 1.0000e+00, 1.7800e+02, 5.9000e+01, 1.5000e-01,\n",
            "        0.0000e+00, 1.6400e+02, 5.2300e+01, 7.2000e+01, 9.8000e+01, 5.4100e+00,\n",
            "        9.8000e+01, 1.0000e-01, 3.3000e+00, 3.3000e+00, 6.2100e-01, 1.1300e+01])\n",
            "Target: tensor([68.6000])\n",
            "Prediction: tensor([72.6803])\n",
            "Input: tensor([7.0000e+00, 2.0050e+03, 0.0000e+00, 6.7000e+01, 1.0000e+00, 1.0300e+01,\n",
            "        5.7913e+02, 1.0000e+01, 6.1500e+01, 2.0000e+00, 9.2000e+01, 8.4500e+00,\n",
            "        9.2000e+01, 1.0000e-01, 7.0000e-01, 6.0000e-01, 9.1000e-01, 2.0300e+01])\n",
            "Target: tensor([81.])\n",
            "Prediction: tensor([68.4385])\n",
            "Input: tensor([7.1000e+01, 2.0020e+03, 1.0000e+00, 1.6900e+02, 6.0000e+00, 3.0900e+00,\n",
            "        1.5486e+02, 0.0000e+00, 4.4000e+00, 7.0000e+00, 9.5000e+01, 7.2800e+00,\n",
            "        9.5000e+01, 1.5000e+00, 2.7000e+00, 2.6000e+00, 5.6100e-01, 1.0100e+01])\n",
            "Target: tensor([71.6000])\n",
            "Prediction: tensor([57.3166])\n",
            "Input: tensor([1.3600e+02, 2.0140e+03, 1.0000e+00, 1.5700e+02, 0.0000e+00, 7.0100e+00,\n",
            "        0.0000e+00, 0.0000e+00, 5.3100e+01, 0.0000e+00, 9.7000e+01, 8.6300e+00,\n",
            "        9.8000e+01, 1.0000e-01, 3.5000e+00, 3.4000e+00, 7.2000e-01, 1.3300e+01])\n",
            "Target: tensor([73.1000])\n",
            "Prediction: tensor([76.0164])\n",
            "Input: tensor([1.4400e+02, 2.0060e+03, 0.0000e+00, 6.6000e+01, 0.0000e+00, 1.5500e+00,\n",
            "        2.6394e+03, 2.3000e+01, 3.5000e+00, 0.0000e+00, 9.5000e+01, 3.6600e+00,\n",
            "        9.5000e+01, 1.0000e-01, 2.1000e+00, 2.0000e+00, 8.3900e-01, 1.3900e+01])\n",
            "Target: tensor([87.])\n",
            "Prediction: tensor([74.5920])\n",
            "Input: tensor([4.1000e+01, 2.0050e+03, 0.0000e+00, 6.5000e+01, 0.0000e+00, 1.1410e+01,\n",
            "        1.5625e+03, 1.0000e+00, 5.5300e+01, 0.0000e+00, 9.8000e+01, 6.3700e+00,\n",
            "        9.8000e+01, 1.0000e-01, 9.0000e-01, 1.0000e+00, 8.2600e-01, 1.3500e+01])\n",
            "Target: tensor([78.7000])\n",
            "Prediction: tensor([71.8847])\n",
            "Input: tensor([1.6000e+02, 2.0020e+03, 1.0000e+00, 1.9200e+02, 1.6000e+01, 5.9300e+00,\n",
            "        2.7638e+01, 1.0315e+04, 2.2000e+00, 1.9000e+01, 9.7000e+01, 3.7000e+00,\n",
            "        9.6000e+01, 7.0000e-01, 9.2000e+00, 9.5000e+00, 6.5700e-01, 1.1500e+01])\n",
            "Target: tensor([71.4000])\n",
            "Prediction: tensor([59.0684])\n",
            "Input: tensor([4.2000e+01, 2.0080e+03, 0.0000e+00, 1.6000e+01, 0.0000e+00, 1.3250e+01,\n",
            "        0.0000e+00, 2.0000e+00, 6.2600e+01, 0.0000e+00, 9.9000e+01, 6.8200e+00,\n",
            "        9.9000e+01, 1.0000e-01, 1.9000e+00, 2.0000e+00, 6.2742e-01, 1.2000e+01])\n",
            "Target: tensor([77.])\n",
            "Prediction: tensor([76.0639])\n",
            "Input: tensor([1.1000e+02, 2.0050e+03, 1.0000e+00, 4.3400e+02, 8.0000e+01, 1.2300e+00,\n",
            "        6.7334e+01, 1.2598e+04, 1.8500e+01, 1.1700e+02, 7.1000e+01, 6.8700e+00,\n",
            "        8.0000e+00, 1.6200e+01, 3.9000e+00, 3.8000e+00, 3.4100e-01, 7.3000e+00])\n",
            "Target: tensor([58.])\n",
            "Prediction: tensor([46.5942])\n",
            "Input: tensor([1.7600e+02, 2.0130e+03, 1.0000e+00, 1.8500e+02, 1.7000e+01, 1.0000e-02,\n",
            "        1.9162e+01, 0.0000e+00, 4.3000e+01, 1.9000e+01, 9.9000e+01, 6.3200e+00,\n",
            "        9.9000e+01, 1.0000e-01, 3.0000e+00, 3.1000e+00, 6.8100e-01, 1.2000e+01])\n",
            "Target: tensor([69.1000])\n",
            "Prediction: tensor([79.0617])\n",
            "Input: tensor([1.2000e+01, 2.0080e+03, 1.0000e+00, 1.4700e+02, 1.4400e+02, 1.0000e-02,\n",
            "        4.2489e+01, 2.6600e+03, 1.4000e+01, 1.8600e+02, 9.6000e+01, 2.8500e+00,\n",
            "        9.6000e+01, 1.0000e-01, 1.9300e+01, 1.9900e+01, 5.2000e-01, 8.6000e+00])\n",
            "Target: tensor([69.1000])\n",
            "Prediction: tensor([75.9458])\n",
            "Input: tensor([7.8000e+01, 2.0000e+03, 0.0000e+00, 9.4000e+01, 0.0000e+00, 1.4070e+01,\n",
            "        3.7946e+03, 0.0000e+00, 5.1500e+01, 0.0000e+00, 8.6000e+01, 6.3000e+00,\n",
            "        8.6000e+01, 1.0000e-01, 3.0000e-01, 3.0000e-01, 8.4800e-01, 1.6200e+01])\n",
            "Target: tensor([76.4000])\n",
            "Prediction: tensor([77.5861])\n",
            "Input: tensor([5.4000e+01, 2.0070e+03, 1.0000e+00, 1.8900e+02, 0.0000e+00, 1.7870e+01,\n",
            "        1.9041e+03, 1.0000e+00, 5.6300e+01, 0.0000e+00, 9.5000e+01, 5.1600e+00,\n",
            "        9.5000e+01, 1.0000e-01, 2.0000e+00, 2.1000e+00, 8.2900e-01, 1.6100e+01])\n",
            "Target: tensor([73.])\n",
            "Prediction: tensor([66.3766])\n",
            "Input: tensor([1.3000e+01, 2.0030e+03, 1.0000e+00, 1.2100e+02, 0.0000e+00, 7.6500e+00,\n",
            "        1.3514e+01, 0.0000e+00, 4.5400e+01, 0.0000e+00, 9.0000e+00, 5.8200e+00,\n",
            "        8.9000e+01, 4.0000e-01, 4.1000e+00, 4.1000e+00, 7.5300e-01, 1.4200e+01])\n",
            "Target: tensor([73.7000])\n",
            "Prediction: tensor([77.2081])\n",
            "Input: tensor([1.1100e+02, 2.0040e+03, 1.0000e+00, 2.2800e+02, 6.6000e+01, 4.4000e-01,\n",
            "        4.1545e+00, 1.3290e+03, 1.5700e+01, 9.0000e+01, 9.2000e+01, 1.9700e+00,\n",
            "        8.2000e+01, 5.0000e-01, 1.3300e+01, 1.3600e+01, 4.5500e-01, 7.8000e+00])\n",
            "Target: tensor([63.5000])\n",
            "Prediction: tensor([68.8960])\n",
            "Input: tensor([1.8100e+02, 2.0040e+03, 1.0000e+00, 5.7800e+02, 3.6000e+01, 2.4600e+00,\n",
            "        8.3699e+00, 3.5000e+01, 1.8000e+01, 5.9000e+01, 8.4000e+01, 7.3300e+00,\n",
            "        8.3000e+01, 1.7600e+01, 7.2000e+00, 7.1000e+00, 4.5600e-01, 1.0500e+01])\n",
            "Target: tensor([47.9000])\n",
            "Prediction: tensor([51.0190])\n",
            "Input: tensor([1.7800e+02, 2.0020e+03, 1.0000e+00, 1.6700e+02, 1.0000e+01, 6.8900e+00,\n",
            "        0.0000e+00, 2.3920e+03, 5.4700e+01, 1.2000e+01, 8.1000e+01, 4.9300e+00,\n",
            "        6.5000e+01, 1.0000e-01, 1.7000e+00, 1.7000e+00, 6.8400e-01, 1.1000e+01])\n",
            "Target: tensor([73.1000])\n",
            "Prediction: tensor([81.0053])\n",
            "Input: tensor([4.6000e+01, 2.0010e+03, 0.0000e+00, 1.2000e+01, 0.0000e+00, 1.1560e+01,\n",
            "        5.3048e+02, 1.1000e+01, 5.2800e+01, 0.0000e+00, 9.7000e+01, 9.1000e+00,\n",
            "        9.7000e+01, 1.0000e-01, 1.3000e+00, 1.0000e+00, 8.6200e-01, 1.6200e+01])\n",
            "Target: tensor([77.])\n",
            "Prediction: tensor([75.4539])\n",
            "Input: tensor([4.6000e+01, 2.0100e+03, 0.0000e+00, 8.4000e+01, 0.0000e+00, 1.0280e+01,\n",
            "        9.5449e+02, 5.0000e+00, 5.7000e+01, 0.0000e+00, 9.0000e+00, 1.1800e+01,\n",
            "        9.0000e+00, 1.0000e-01, 1.1000e+00, 9.0000e-01, 9.0600e-01, 1.6800e+01])\n",
            "Target: tensor([79.2000])\n",
            "Prediction: tensor([81.9719])\n",
            "Input: tensor([1.1400e+02, 2.0080e+03, 0.0000e+00, 6.8000e+01, 1.0000e+00, 9.6200e+00,\n",
            "        1.0873e+04, 1.0900e+02, 5.7900e+01, 1.0000e+00, 9.7000e+01, 9.5700e+00,\n",
            "        9.7000e+01, 1.0000e-01, 1.0000e+00, 9.0000e-01, 9.0500e-01, 1.6800e+01])\n",
            "Target: tensor([83.])\n",
            "Prediction: tensor([89.3148])\n",
            "Input: tensor([1.0700e+02, 2.0050e+03, 1.0000e+00, 2.7400e+02, 2.0000e+00, 2.7500e+00,\n",
            "        9.8684e+01, 0.0000e+00, 4.2100e+01, 2.0000e+00, 9.9000e+01, 5.9000e+00,\n",
            "        9.9000e+01, 1.0000e-01, 2.3000e+00, 2.4000e+00, 6.3700e-01, 1.1800e+01])\n",
            "Target: tensor([64.5000])\n",
            "Prediction: tensor([60.4272])\n",
            "Input: tensor([1.8100e+02, 2.0030e+03, 1.0000e+00, 6.4000e+01, 3.9000e+01, 2.3300e+00,\n",
            "        6.5790e+01, 8.8100e+02, 1.7600e+01, 6.2000e+01, 8.5000e+01, 8.1800e+00,\n",
            "        8.3000e+01, 1.8200e+01, 7.3000e+00, 7.2000e+00, 4.4300e-01, 1.0200e+01])\n",
            "Target: tensor([46.4000])\n",
            "Prediction: tensor([87.3787])\n",
            "Input: tensor([9.7000e+01, 2.0020e+03, 1.0000e+00, 2.7100e+02, 4.1000e+01, 9.0000e-01,\n",
            "        4.7526e+01, 1.0795e+04, 1.4700e+01, 6.3000e+01, 6.1000e+01, 5.2900e+00,\n",
            "        6.2000e+01, 7.0000e-01, 8.5000e+00, 8.4000e+00, 4.6200e-01, 8.3000e+00])\n",
            "Target: tensor([59.3000])\n",
            "Prediction: tensor([56.3906])\n",
            "Input: tensor([1.7700e+02, 2.0050e+03, 1.0000e+00, 1.6500e+02, 0.0000e+00, 8.8000e-01,\n",
            "        3.3729e+02, 3.0000e+00, 4.4900e+01, 0.0000e+00, 6.7000e+01, 3.8700e+00,\n",
            "        6.8000e+01, 1.0000e-01, 1.6000e+00, 1.5000e+00, 0.0000e+00, 1.0600e+01])\n",
            "Target: tensor([69.9000])\n",
            "Prediction: tensor([81.3970])\n",
            "Input: tensor([2.8000e+01, 2.0080e+03, 1.0000e+00, 1.9900e+02, 1.6000e+01, 2.2400e+00,\n",
            "        5.3100e+01, 4.2110e+03, 1.5300e+01, 1.8000e+01, 9.1000e+01, 5.5500e+00,\n",
            "        9.1000e+01, 7.0000e-01, 1.1200e+01, 1.1400e+01, 5.1100e-01, 1.0500e+01])\n",
            "Target: tensor([65.6000])\n",
            "Prediction: tensor([48.5448])\n",
            "Input: tensor([1.4000e+02, 2.0130e+03, 1.0000e+00, 1.9600e+02, 2.0000e+01, 2.6000e-01,\n",
            "        1.1839e+01, 1.7000e+01, 2.3200e+01, 2.8000e+01, 8.9000e+01, 4.5100e+00,\n",
            "        9.2000e+01, 3.0000e-01, 9.9000e+00, 9.7000e+00, 4.7400e-01, 8.7000e+00])\n",
            "Target: tensor([66.])\n",
            "Prediction: tensor([70.6207])\n",
            "Input: tensor([1.4100e+02, 2.0080e+03, 1.0000e+00, 1.3200e+02, 1.0000e+00, 9.5400e+00,\n",
            "        9.6332e+01, 2.0000e+00, 5.5800e+01, 1.0000e+00, 9.5000e+01, 1.5000e+00,\n",
            "        9.5000e+01, 1.0000e-01, 2.3000e+00, 2.4000e+00, 7.4900e-01, 1.3500e+01])\n",
            "Target: tensor([74.])\n",
            "Prediction: tensor([78.8707])\n",
            "Input: tensor([9.6000e+01, 2.0010e+03, 0.0000e+00, 9.6000e+01, 0.0000e+00, 1.2890e+01,\n",
            "        7.8773e+03, 0.0000e+00, 5.4600e+01, 0.0000e+00, 9.9000e+01, 7.4000e+00,\n",
            "        9.9000e+01, 1.0000e-01, 1.0000e+00, 1.0000e+00, 8.5400e-01, 1.3400e+01])\n",
            "Target: tensor([78.])\n",
            "Prediction: tensor([81.8932])\n",
            "Input: tensor([1.0800e+02, 2.0150e+03, 1.0000e+00, 1.6000e+01, 0.0000e+00, 4.6149e+00,\n",
            "        0.0000e+00, 0.0000e+00, 6.1800e+01, 0.0000e+00, 8.9000e+01, 5.9302e+00,\n",
            "        8.9000e+01, 1.0000e-01, 1.8000e+00, 1.8000e+00, 8.0400e-01, 1.5100e+01])\n",
            "Target: tensor([76.1000])\n",
            "Prediction: tensor([84.1231])\n",
            "Input: tensor([6.1000e+01, 2.0080e+03, 1.0000e+00, 1.2800e+02, 1.0000e+00, 7.1700e+00,\n",
            "        1.5176e+02, 5.6000e+01, 5.5000e+00, 1.0000e+00, 9.0000e+00, 8.9900e+00,\n",
            "        9.2000e+01, 1.0000e-01, 2.6000e+00, 2.8000e+00, 7.3500e-01, 1.3100e+01])\n",
            "Target: tensor([73.9000])\n",
            "Prediction: tensor([77.0350])\n",
            "Input: tensor([1.0000e+00, 2.0010e+03, 1.0000e+00, 1.4000e+01, 1.0000e+00, 4.2500e+00,\n",
            "        9.6206e+01, 1.8000e+01, 4.6000e+01, 1.0000e+00, 9.7000e+01, 6.0000e+00,\n",
            "        9.7000e+01, 1.0000e-01, 2.1000e+00, 2.1000e+00, 6.6200e-01, 1.0600e+01])\n",
            "Target: tensor([73.6000])\n",
            "Prediction: tensor([65.6081])\n",
            "Input: tensor([1.3500e+02, 2.0080e+03, 1.0000e+00, 1.4900e+02, 0.0000e+00, 1.2090e+01,\n",
            "        0.0000e+00, 0.0000e+00, 4.2200e+01, 0.0000e+00, 9.6000e+01, 7.4300e+00,\n",
            "        9.6000e+01, 1.0000e-01, 4.3000e+00, 4.4000e+00, 7.1000e-01, 1.2600e+01])\n",
            "Target: tensor([74.1000])\n",
            "Prediction: tensor([74.9295])\n",
            "Input: tensor([3.7000e+01, 2.0140e+03, 1.0000e+00, 2.7500e+02, 7.0000e+00, 1.0000e-02,\n",
            "        0.0000e+00, 7.1000e+01, 2.6800e+01, 1.0000e+01, 9.0000e+00, 5.1500e+00,\n",
            "        9.0000e+00, 3.0000e+00, 7.6000e+00, 7.3000e+00, 5.8100e-01, 1.1100e+01])\n",
            "Target: tensor([64.2000])\n",
            "Prediction: tensor([57.8333])\n",
            "Input: tensor([2.3000e+01, 2.0060e+03, 1.0000e+00, 9.3000e+01, 0.0000e+00, 6.7000e-01,\n",
            "        2.4975e+01, 0.0000e+00, 3.2200e+01, 0.0000e+00, 9.4000e+01, 2.2400e+00,\n",
            "        9.7000e+01, 1.0000e-01, 6.3000e+00, 5.8000e+00, 8.3700e-01, 1.4300e+01])\n",
            "Target: tensor([76.3000])\n",
            "Prediction: tensor([58.9061])\n",
            "Input: tensor([1.0600e+02, 2.0020e+03, 1.0000e+00, 2.1000e+01, 0.0000e+00, 2.7800e+00,\n",
            "        0.0000e+00, 0.0000e+00, 6.2400e+01, 0.0000e+00, 8.4000e+01, 8.2000e+00,\n",
            "        8.4000e+01, 1.0000e-01, 2.0000e-01, 2.0000e-01, 6.0800e-01, 1.0200e+01])\n",
            "Target: tensor([66.2000])\n",
            "Prediction: tensor([84.1087])\n",
            "Input: tensor([5.2000e+01, 2.0050e+03, 1.0000e+00, 3.3700e+02, 3.0000e+00, 7.1900e+00,\n",
            "        1.2066e+01, 0.0000e+00, 2.2000e+00, 4.0000e+00, 5.0000e+00, 1.6300e+00,\n",
            "        3.9000e+01, 4.9000e+00, 9.8000e+00, 9.8000e+00, 5.6300e-01, 8.7000e+00])\n",
            "Target: tensor([54.4000])\n",
            "Prediction: tensor([53.7664])\n",
            "Input: tensor([1.1400e+02, 2.0010e+03, 0.0000e+00, 8.2000e+01, 1.0000e+00, 9.9500e+00,\n",
            "        3.0545e+03, 0.0000e+00, 5.2600e+01, 1.0000e+00, 9.7000e+01, 7.7900e+00,\n",
            "        9.7000e+01, 1.0000e-01, 1.1000e+00, 1.1000e+00, 8.7800e-01, 1.6700e+01])\n",
            "Target: tensor([78.3000])\n",
            "Prediction: tensor([81.1744])\n",
            "Input: tensor([5.1000e+01, 2.0140e+03, 1.0000e+00, 1.8100e+02, 2.0000e+00, 2.5200e+00,\n",
            "        6.6573e+02, 0.0000e+00, 5.5400e+01, 2.0000e+00, 9.3000e+01, 6.7700e+00,\n",
            "        9.4000e+01, 2.0000e-01, 1.6000e+00, 1.6000e+00, 6.7600e-01, 1.3200e+01])\n",
            "Target: tensor([73.3000])\n",
            "Prediction: tensor([63.6457])\n",
            "Input: tensor([9.0000e+01, 2.0120e+03, 0.0000e+00, 1.6300e+02, 0.0000e+00, 1.0210e+01,\n",
            "        1.3560e+03, 3.0000e+00, 5.9800e+01, 0.0000e+00, 9.1000e+01, 5.9100e+00,\n",
            "        9.1000e+01, 1.0000e-01, 2.2000e+00, 2.2000e+00, 8.1200e-01, 1.5500e+01])\n",
            "Target: tensor([73.8000])\n",
            "Prediction: tensor([72.7196])\n",
            "Input: tensor([1.2200e+02, 2.0140e+03, 1.0000e+00, 1.1900e+02, 1.0000e+00, 6.7400e+00,\n",
            "        1.8425e+03, 0.0000e+00, 5.7100e+01, 1.0000e+00, 8.0000e+00, 8.3000e+00,\n",
            "        8.0000e+00, 1.0000e-01, 1.9000e+00, 1.8000e+00, 7.8000e-01, 1.3000e+01])\n",
            "Target: tensor([77.6000])\n",
            "Prediction: tensor([89.4854])\n",
            "Input: tensor([2.8000e+01, 2.0140e+03, 1.0000e+00, 1.7900e+02, 1.1000e+01, 1.0000e-02,\n",
            "        1.2180e+01, 0.0000e+00, 1.8900e+01, 1.2000e+01, 8.7000e+01, 5.6800e+00,\n",
            "        8.8000e+01, 2.0000e-01, 1.9000e+00, 1.1000e+01, 5.5300e-01, 1.0900e+01])\n",
            "Target: tensor([68.3000])\n",
            "Prediction: tensor([53.0815])\n",
            "Input: tensor([1.2800e+02, 2.0080e+03, 0.0000e+00, 9.2000e+01, 0.0000e+00, 1.2350e+01,\n",
            "        3.6529e+03, 1.0000e+00, 5.6500e+01, 0.0000e+00, 9.7000e+01, 9.9000e+00,\n",
            "        9.7000e+01, 1.0000e-01, 7.0000e-01, 5.0000e-01, 8.0400e-01, 1.5800e+01])\n",
            "Target: tensor([79.])\n",
            "Prediction: tensor([84.5167])\n",
            "Input: tensor([2.3000e+01, 2.0010e+03, 1.0000e+00, 1.9000e+01, 0.0000e+00, 4.7000e-01,\n",
            "        1.0787e+03, 1.1000e+01, 2.7000e+01, 0.0000e+00, 9.9000e+01, 3.6000e+00,\n",
            "        9.7000e+01, 1.0000e-01, 6.8000e+00, 6.2000e+00, 8.1900e-01, 1.3400e+01])\n",
            "Target: tensor([74.7000])\n",
            "Prediction: tensor([62.8748])\n",
            "Input: tensor([9.9000e+01, 2.0140e+03, 1.0000e+00, 1.2600e+02, 4.0000e+00, 5.2000e-01,\n",
            "        7.2137e+02, 2.2100e+02, 3.9500e+01, 4.0000e+00, 9.7000e+01, 4.1700e+00,\n",
            "        9.7000e+01, 1.0000e-01, 7.6000e+00, 7.4000e+00, 7.8300e-01, 1.3000e+01])\n",
            "Target: tensor([74.8000])\n",
            "Prediction: tensor([69.0393])\n",
            "Input: tensor([1.6500e+02, 2.0140e+03, 1.0000e+00, 1.7100e+02, 0.0000e+00, 6.9400e+00,\n",
            "        1.5789e+03, 0.0000e+00, 4.6000e+01, 0.0000e+00, 9.4000e+01, 5.9300e+00,\n",
            "        9.2000e+01, 3.0000e-01, 5.8000e+00, 6.0000e+00, 7.7800e-01, 1.2700e+01])\n",
            "Target: tensor([71.1000])\n",
            "Prediction: tensor([77.9737])\n",
            "Input: tensor([1.0000e+01, 2.0130e+03, 1.0000e+00, 1.7200e+02, 0.0000e+00, 9.4200e+00,\n",
            "        0.0000e+00, 0.0000e+00, 6.3200e+01, 0.0000e+00, 9.7000e+01, 7.5000e+00,\n",
            "        9.7000e+01, 1.0000e-01, 2.5000e+00, 2.5000e+00, 7.9000e-01, 1.2600e+01])\n",
            "Target: tensor([74.8000])\n",
            "Prediction: tensor([60.0874])\n",
            "Input: tensor([2.5000e+01, 2.0060e+03, 1.0000e+00, 3.2000e+01, 4.7000e+01, 4.7300e+00,\n",
            "        6.4240e+01, 1.2500e+02, 1.4600e+01, 8.6000e+01, 9.4000e+01, 6.5800e+00,\n",
            "        8.6000e+01, 2.0000e+00, 1.0000e+00, 9.6000e+00, 3.2500e-01, 4.7000e+00])\n",
            "Target: tensor([54.3000])\n",
            "Prediction: tensor([70.3419])\n",
            "Input: tensor([1.1100e+02, 2.0080e+03, 1.0000e+00, 2.9600e+02, 5.9000e+01, 3.0000e-01,\n",
            "        9.5305e+00, 3.3300e+02, 1.8300e+01, 9.6000e+01, 8.5000e+01, 1.8700e+00,\n",
            "        8.5000e+01, 6.0000e-01, 1.3200e+01, 1.3400e+01, 4.9300e-01, 8.2000e+00])\n",
            "Target: tensor([59.2000])\n",
            "Prediction: tensor([66.2215])\n",
            "Input: tensor([1.7700e+02, 2.0140e+03, 1.0000e+00, 1.3400e+02, 0.0000e+00, 1.0000e-02,\n",
            "        5.6482e+02, 1.0000e+01, 5.2500e+01, 0.0000e+00, 6.5000e+01, 5.2000e+00,\n",
            "        6.4000e+01, 1.0000e-01, 1.5000e+00, 1.4000e+00, 5.9600e-01, 1.0800e+01])\n",
            "Target: tensor([71.7000])\n",
            "Prediction: tensor([85.5164])\n",
            "Input: tensor([5.5000e+01, 2.0030e+03, 1.0000e+00, 3.6300e+02, 2.2800e+02, 7.9000e-01,\n",
            "        1.0972e+01, 2.2800e+02, 1.3200e+01, 3.6000e+02, 5.5000e+01, 4.6400e+00,\n",
            "        3.7000e+01, 4.4000e+00, 1.1600e+01, 1.1500e+01, 3.0600e-01, 5.2000e+00])\n",
            "Target: tensor([54.])\n",
            "Prediction: tensor([92.8111])\n",
            "Input: tensor([6.4000e+01, 2.0140e+03, 1.0000e+00, 7.3000e+01, 0.0000e+00, 7.5300e+00,\n",
            "        2.1630e+03, 1.0000e+00, 6.6000e+01, 0.0000e+00, 9.9000e+01, 8.8000e+00,\n",
            "        9.9000e+01, 1.0000e-01, 8.0000e-01, 7.0000e-01, 8.6200e-01, 1.7200e+01])\n",
            "Target: tensor([88.])\n",
            "Prediction: tensor([76.4155])\n",
            "Input: tensor([6.0000e+00, 2.0040e+03, 1.0000e+00, 1.3200e+02, 1.0000e+00, 3.8100e+00,\n",
            "        9.7741e+01, 1.7830e+03, 4.8400e+01, 1.0000e+00, 9.3000e+01, 5.5000e+00,\n",
            "        9.1000e+01, 1.0000e-01, 2.0000e+00, 2.1000e+00, 6.6800e-01, 1.0900e+01])\n",
            "Target: tensor([73.])\n",
            "Prediction: tensor([56.9855])\n",
            "Input: tensor([1.2700e+02, 2.0000e+03, 0.0000e+00, 1.5300e+02, 3.0000e+00, 8.4000e+00,\n",
            "        4.1243e+02, 7.7000e+01, 5.3100e+01, 4.0000e+00, 9.8000e+01, 5.5000e+00,\n",
            "        9.8000e+01, 1.0000e-01, 2.5000e+00, 2.8000e+00, 7.7700e-01, 1.4600e+01])\n",
            "Target: tensor([73.7000])\n",
            "Prediction: tensor([75.3475])\n",
            "Input: tensor([8.1000e+01, 2.0010e+03, 1.0000e+00, 1.7100e+02, 1.0000e+00, 3.8900e+00,\n",
            "        1.6024e+02, 0.0000e+00, 4.2500e+01, 1.0000e+00, 9.9000e+01, 5.3400e+00,\n",
            "        9.9000e+01, 2.2000e+00, 2.0000e+00, 1.8000e+00, 6.8000e-01, 1.0900e+01])\n",
            "Target: tensor([72.7000])\n",
            "Prediction: tensor([64.1118])\n",
            "Input: tensor([6.7000e+01, 2.0040e+03, 1.0000e+00, 3.3400e+02, 3.3000e+01, 3.4000e-01,\n",
            "        1.8930e+01, 1.0000e+01, 1.8100e+01, 5.3000e+01, 6.5000e+01, 3.1400e+00,\n",
            "        6.0000e+00, 2.8000e+00, 9.5000e+00, 9.5000e+00, 3.2500e-01, 5.1000e+00])\n",
            "Target: tensor([54.])\n",
            "Prediction: tensor([49.2180])\n",
            "Input: tensor([1.0000e+01, 2.0120e+03, 1.0000e+00, 1.6700e+02, 0.0000e+00, 9.5000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 6.2600e+01, 0.0000e+00, 9.9000e+01, 7.4300e+00,\n",
            "        9.8000e+01, 2.0000e-01, 2.5000e+00, 2.5000e+00, 7.8900e-01, 1.2600e+01])\n",
            "Target: tensor([74.9000])\n",
            "Prediction: tensor([59.9688])\n",
            "Input: tensor([1.0300e+02, 2.0060e+03, 1.0000e+00, 2.2100e+02, 8.0000e+00, 1.0000e-02,\n",
            "        5.5798e+01, 2.2000e+01, 2.4800e+01, 1.2000e+01, 6.8000e+01, 3.2100e+00,\n",
            "        6.8000e+01, 1.3000e+00, 9.6000e+00, 9.4000e+00, 4.6600e-01, 7.2000e+00])\n",
            "Target: tensor([69.])\n",
            "Prediction: tensor([63.1905])\n",
            "Input: tensor([8.2000e+01, 2.0110e+03, 0.0000e+00, 6.4000e+01, 3.0000e+00, 7.3900e+00,\n",
            "        9.4987e+03, 4.3400e+02, 2.7400e+01, 4.0000e+00, 9.6000e+01, 1.7000e+00,\n",
            "        9.7000e+01, 1.0000e-01, 1.9000e+00, 1.6000e+00, 8.8400e-01, 1.5100e+01])\n",
            "Target: tensor([82.5000])\n",
            "Prediction: tensor([77.3075])\n",
            "Input: tensor([1.3000e+02, 2.0000e+03, 1.0000e+00, 1.1600e+02, 4.0000e+00, 1.0330e+01,\n",
            "        0.0000e+00, 3.2647e+04, 2.4700e+01, 4.0000e+00, 9.9000e+01, 4.2300e+00,\n",
            "        9.7000e+01, 1.0000e-01, 1.6000e+00, 1.1000e+00, 6.2742e-01, 1.2000e+01])\n",
            "Target: tensor([76.])\n",
            "Prediction: tensor([44.9687])\n",
            "Input: tensor([4.0000e+00, 2.0040e+03, 1.0000e+00, 1.4900e+02, 0.0000e+00, 7.2800e+00,\n",
            "        2.2863e+01, 0.0000e+00, 4.8000e+00, 0.0000e+00, 9.7000e+01, 4.2100e+00,\n",
            "        9.7000e+01, 1.0000e-01, 3.5000e+00, 3.4000e+00, 0.0000e+00, 0.0000e+00])\n",
            "Target: tensor([74.4000])\n",
            "Prediction: tensor([48.9477])\n",
            "Input: tensor([1.4400e+02, 2.0130e+03, 0.0000e+00, 5.7000e+01, 0.0000e+00, 1.8300e+00,\n",
            "        7.1434e+02, 1.3800e+02, 3.2700e+01, 0.0000e+00, 9.7000e+01, 4.5300e+00,\n",
            "        9.7000e+01, 1.0000e-01, 2.2000e+00, 2.2000e+00, 9.2000e-01, 1.5400e+01])\n",
            "Target: tensor([82.7000])\n",
            "Prediction: tensor([79.3291])\n",
            "Input: tensor([8.8000e+01, 2.0140e+03, 1.0000e+00, 1.7000e+01, 3.0000e+00, 1.0000e-02,\n",
            "        0.0000e+00, 3.1800e+02, 4.3900e+01, 4.0000e+00, 9.5000e+01, 6.4800e+00,\n",
            "        9.6000e+01, 1.0000e-01, 3.3000e+00, 3.4000e+00, 6.5600e-01, 1.2800e+01])\n",
            "Target: tensor([78.])\n",
            "Prediction: tensor([76.6085])\n",
            "Input: tensor([6.4000e+01, 2.0150e+03, 1.0000e+00, 7.2000e+01, 0.0000e+00, 4.6149e+00,\n",
            "        0.0000e+00, 1.0000e+00, 6.6500e+01, 0.0000e+00, 9.9000e+01, 5.9302e+00,\n",
            "        9.9000e+01, 1.0000e-01, 8.0000e-01, 7.0000e-01, 8.6500e-01, 1.7200e+01])\n",
            "Target: tensor([81.])\n",
            "Prediction: tensor([74.0063])\n",
            "Input: tensor([5.0000e+00, 2.0130e+03, 1.0000e+00, 1.1900e+02, 8.0000e+00, 8.2800e+00,\n",
            "        1.0018e+03, 0.0000e+00, 6.1600e+01, 1.0000e+01, 9.9000e+01, 4.9900e+00,\n",
            "        9.4000e+01, 1.0000e-01, 1.0000e+00, 9.0000e-01, 8.2300e-01, 1.7300e+01])\n",
            "Target: tensor([76.])\n",
            "Prediction: tensor([64.2000])\n",
            "Input: tensor([1.3800e+02, 2.0080e+03, 1.0000e+00, 2.1500e+02, 0.0000e+00, 4.3600e+00,\n",
            "        6.2857e+01, 0.0000e+00, 2.5400e+01, 0.0000e+00, 9.9000e+01, 5.6600e+00,\n",
            "        9.9000e+01, 9.0000e-01, 6.5000e+00, 6.4000e+00, 5.3100e-01, 1.0400e+01])\n",
            "Target: tensor([65.4000])\n",
            "Prediction: tensor([64.9542])\n",
            "Input: tensor([1.3800e+02, 2.0140e+03, 1.0000e+00, 1.9100e+02, 0.0000e+00, 1.0000e-02,\n",
            "        2.2573e+02, 0.0000e+00, 3.1000e+00, 0.0000e+00, 9.5000e+01, 8.3500e+00,\n",
            "        9.5000e+01, 2.0000e-01, 5.6000e+00, 5.4000e+00, 5.6200e-01, 1.1100e+01])\n",
            "Target: tensor([67.3000])\n",
            "Prediction: tensor([62.9478])\n",
            "Input: tensor([6.3000e+01, 2.0090e+03, 1.0000e+00, 2.7100e+02, 4.1000e+01, 1.7600e+00,\n",
            "        3.0723e+01, 1.0100e+02, 2.4900e+01, 6.0000e+01, 9.4000e+01, 5.1700e+00,\n",
            "        9.4000e+01, 2.1000e+00, 7.3000e+00, 7.2000e+00, 5.4200e-01, 1.0400e+01])\n",
            "Target: tensor([66.])\n",
            "Prediction: tensor([59.3121])\n",
            "Input: tensor([1.0000e+02, 2.0100e+03, 1.0000e+00, 7.3000e+01, 0.0000e+00, 1.8300e+00,\n",
            "        9.1140e+01, 0.0000e+00, 2.2100e+01, 0.0000e+00, 9.7000e+01, 7.9300e+00,\n",
            "        9.6000e+01, 1.0000e-01, 1.4000e+01, 1.4100e+01, 6.5300e-01, 1.1600e+01])\n",
            "Target: tensor([76.7000])\n",
            "Prediction: tensor([68.0246])\n",
            "Input: tensor([1.5300e+02, 2.0120e+03, 1.0000e+00, 2.3500e+02, 6.1000e+01, 1.0000e-02,\n",
            "        2.2052e+02, 8.5230e+03, 3.8235e+01, 8.9000e+01, 9.2000e+01, 8.2000e+00,\n",
            "        9.2000e+01, 3.0000e-01, 4.8506e+00, 4.8814e+00, 4.6800e-01, 6.8000e+00])\n",
            "Target: tensor([63.2000])\n",
            "Prediction: tensor([74.9949])\n",
            "Input: tensor([5.1000e+01, 2.0060e+03, 1.0000e+00, 2.1100e+02, 3.0000e+00, 2.7700e+00,\n",
            "        5.7746e+01, 0.0000e+00, 5.1000e+00, 3.0000e+00, 9.6000e+01, 6.6800e+00,\n",
            "        9.6000e+01, 2.0000e-01, 1.8000e+00, 1.7000e+00, 6.5100e-01, 1.2900e+01])\n",
            "Target: tensor([75.])\n",
            "Prediction: tensor([51.0833])\n",
            "Input: tensor([1.9000e+01, 2.0130e+03, 1.0000e+00, 1.9200e+02, 8.0000e+00, 3.7800e+00,\n",
            "        0.0000e+00, 0.0000e+00, 5.1200e+01, 1.0000e+01, 9.5000e+01, 5.9600e+00,\n",
            "        9.4000e+01, 1.0000e-01, 1.2000e+00, 1.1000e+00, 6.6100e-01, 1.3800e+01])\n",
            "Target: tensor([71.])\n",
            "Prediction: tensor([58.3002])\n",
            "Input: tensor([7.5000e+01, 2.0130e+03, 1.0000e+00, 1.8100e+02, 1.2400e+02, 9.0000e-02,\n",
            "        2.2848e+01, 8.4190e+03, 2.5600e+01, 1.4800e+02, 8.6000e+01, 2.9300e+00,\n",
            "        8.5000e+01, 3.0000e-01, 1.5000e+00, 1.3000e+00, 6.7700e-01, 1.2900e+01])\n",
            "Target: tensor([68.7000])\n",
            "Prediction: tensor([78.9837])\n",
            "Input: tensor([1.2000e+01, 2.0140e+03, 1.0000e+00, 1.3200e+02, 9.8000e+01, 1.0000e-02,\n",
            "        1.0446e+01, 2.8900e+02, 1.7700e+01, 1.2100e+02, 9.7000e+01, 2.8200e+00,\n",
            "        9.7000e+01, 1.0000e-01, 1.8100e+01, 1.8600e+01, 5.7000e-01, 1.0000e+01])\n",
            "Target: tensor([71.4000])\n",
            "Prediction: tensor([69.9541])\n",
            "Input: tensor([1.3000e+02, 2.0140e+03, 1.0000e+00, 6.6000e+01, 1.0000e+00, 1.0000e-02,\n",
            "        0.0000e+00, 4.4200e+02, 3.1200e+01, 2.0000e+00, 9.9000e+01, 7.3700e+00,\n",
            "        9.9000e+01, 1.0000e-01, 1.5000e+00, 1.0000e+00, 6.2742e-01, 1.2000e+01])\n",
            "Target: tensor([82.])\n",
            "Prediction: tensor([75.9478])\n",
            "Input: tensor([1.0000e+02, 2.0080e+03, 1.0000e+00, 8.1000e+01, 0.0000e+00, 1.7600e+00,\n",
            "        1.0777e+03, 0.0000e+00, 2.3000e+00, 0.0000e+00, 9.8000e+01, 9.3000e+00,\n",
            "        9.8000e+01, 1.0000e-01, 1.4200e+01, 1.4300e+01, 6.4100e-01, 1.1800e+01])\n",
            "Target: tensor([75.9000])\n",
            "Prediction: tensor([64.4936])\n",
            "Input: tensor([1.7200e+02, 2.0090e+03, 0.0000e+00, 7.8000e+01, 4.0000e+00, 1.0790e+01,\n",
            "        0.0000e+00, 1.2120e+03, 6.3100e+01, 4.0000e+00, 9.3000e+01, 9.8100e+00,\n",
            "        9.3000e+01, 1.0000e-01, 8.0000e-01, 5.0000e-01, 6.2742e-01, 1.2000e+01])\n",
            "Target: tensor([81.])\n",
            "Prediction: tensor([90.1100])\n",
            "Input: tensor([2.8000e+01, 2.0110e+03, 1.0000e+00, 1.9000e+01, 1.3000e+01, 2.1200e+00,\n",
            "        6.0186e+01, 7.2200e+02, 1.7000e+01, 1.5000e+01, 8.7000e+01, 5.6400e+00,\n",
            "        8.8000e+01, 3.0000e-01, 1.1000e+01, 1.1200e+01, 5.3300e-01, 1.0700e+01])\n",
            "Target: tensor([67.])\n",
            "Prediction: tensor([64.8388])\n",
            "Input: tensor([1.7500e+02, 2.0010e+03, 1.0000e+00, 1.2300e+02, 1.0000e+00, 6.4800e+00,\n",
            "        4.2148e+02, 0.0000e+00, 5.5700e+01, 1.0000e+00, 9.4000e+01, 7.4600e+00,\n",
            "        9.4000e+01, 1.0000e-01, 1.8000e+00, 1.7000e+00, 7.4200e-01, 1.4200e+01])\n",
            "Target: tensor([75.2000])\n",
            "Prediction: tensor([84.5619])\n",
            "Input: tensor([1.3800e+02, 2.0100e+03, 1.0000e+00, 2.4000e+01, 0.0000e+00, 5.5800e+00,\n",
            "        6.3040e+01, 0.0000e+00, 2.6900e+01, 0.0000e+00, 9.8000e+01, 5.2400e+00,\n",
            "        9.8000e+01, 5.0000e-01, 6.1000e+00, 6.0000e+00, 5.4200e-01, 1.0600e+01])\n",
            "Target: tensor([66.2000])\n",
            "Prediction: tensor([79.3660])\n",
            "Input: tensor([9.0000e+00, 2.0010e+03, 1.0000e+00, 1.5100e+02, 8.0000e+00, 5.1000e-01,\n",
            "        4.1042e+00, 5.7400e+02, 4.2600e+01, 1.0000e+01, 7.7000e+01, 4.4800e+00,\n",
            "        7.7000e+01, 1.0000e-01, 3.1000e+00, 3.1000e+00, 6.4200e-01, 1.0400e+01])\n",
            "Target: tensor([67.5000])\n",
            "Prediction: tensor([58.3675])\n",
            "Input: tensor([1.3700e+02, 2.0010e+03, 1.0000e+00, 1.7500e+02, 0.0000e+00, 3.4300e+00,\n",
            "        1.9941e+02, 0.0000e+00, 6.6500e+01, 0.0000e+00, 8.3000e+01, 5.1600e+00,\n",
            "        8.5000e+01, 1.0000e-01, 2.0000e-01, 2.0000e-01, 6.4500e-01, 1.2000e+01])\n",
            "Target: tensor([75.])\n",
            "Prediction: tensor([78.1681])\n",
            "Input: tensor([1.8200e+02, 2.0000e+03, 1.0000e+00, 6.6500e+02, 2.4000e+01, 1.6800e+00,\n",
            "        0.0000e+00, 1.4830e+03, 2.5500e+01, 3.9000e+01, 7.8000e+01, 7.1000e+00,\n",
            "        7.8000e+01, 4.3500e+01, 1.1000e+01, 1.1200e+01, 4.3400e-01, 9.8000e+00])\n",
            "Target: tensor([46.])\n",
            "Prediction: tensor([39.4520])\n",
            "Input: tensor([8.2000e+01, 2.0090e+03, 0.0000e+00, 6.4000e+01, 3.0000e+00, 7.0900e+00,\n",
            "        8.9918e+02, 7.4100e+02, 2.6400e+01, 4.0000e+00, 9.9000e+01, 9.5100e+00,\n",
            "        9.7000e+01, 1.0000e-01, 1.8000e+00, 1.6000e+00, 8.8100e-01, 1.5000e+01])\n",
            "Target: tensor([83.])\n",
            "Prediction: tensor([70.8406])\n",
            "Input: tensor([1.5800e+02, 2.0070e+03, 1.0000e+00, 1.2100e+02, 8.0000e+00, 8.3000e-01,\n",
            "        1.7981e+01, 4.0300e+02, 4.9400e+01, 9.0000e+00, 8.3000e+01, 3.7200e+00,\n",
            "        8.0000e+00, 1.0000e-01, 6.4000e+00, 6.2000e+00, 6.4400e-01, 1.1500e+01])\n",
            "Target: tensor([73.8000])\n",
            "Prediction: tensor([74.0079])\n",
            "Input: tensor([7.3000e+01, 2.0040e+03, 0.0000e+00, 6.5000e+01, 0.0000e+00, 6.7900e+00,\n",
            "        8.5061e+03, 0.0000e+00, 5.6500e+01, 0.0000e+00, 9.9000e+01, 9.5900e+00,\n",
            "        9.9000e+01, 1.0000e-01, 1.0000e+00, 9.0000e-01, 8.7300e-01, 1.8300e+01])\n",
            "Target: tensor([88.])\n",
            "Prediction: tensor([80.8401])\n",
            "Input: tensor([6.4000e+01, 2.0130e+03, 1.0000e+00, 7.4000e+01, 0.0000e+00, 7.4600e+00,\n",
            "        2.1831e+03, 3.0000e+00, 6.5400e+01, 0.0000e+00, 9.9000e+01, 9.2600e+00,\n",
            "        9.9000e+01, 1.0000e-01, 8.0000e-01, 7.0000e-01, 8.6000e-01, 1.7100e+01])\n",
            "Target: tensor([86.])\n",
            "Prediction: tensor([76.2633])\n",
            "Input: tensor([1.1200e+02, 2.0140e+03, 1.0000e+00, 2.4200e+02, 2.0000e+00, 1.0000e-02,\n",
            "        7.5140e+02, 4.7700e+02, 3.4900e+01, 3.0000e+00, 8.8000e+01, 8.9300e+00,\n",
            "        8.8000e+01, 2.2000e+00, 8.6000e+00, 8.5000e+00, 6.3200e-01, 1.1700e+01])\n",
            "Target: tensor([65.9000])\n",
            "Prediction: tensor([62.3113])\n",
            "Input: tensor([1.3600e+02, 2.0070e+03, 1.0000e+00, 1.7000e+01, 0.0000e+00, 5.8900e+00,\n",
            "        0.0000e+00, 0.0000e+00, 4.6600e+01, 0.0000e+00, 9.9000e+01, 3.9200e+00,\n",
            "        9.9000e+01, 3.0000e-01, 3.6000e+00, 3.6000e+00, 7.0200e-01, 1.3300e+01])\n",
            "Target: tensor([71.9000])\n",
            "Prediction: tensor([83.2722])\n",
            "Input: tensor([2.3000e+01, 2.0000e+03, 1.0000e+00, 1.6000e+01, 0.0000e+00, 3.7000e-01,\n",
            "        1.1797e+01, 4.2000e+01, 2.6100e+01, 0.0000e+00, 9.9000e+01, 3.5000e+00,\n",
            "        9.9000e+01, 1.0000e-01, 6.8000e+00, 6.3000e+00, 8.1800e-01, 1.3400e+01])\n",
            "Target: tensor([74.4000])\n",
            "Prediction: tensor([62.2014])\n",
            "Input: tensor([1.7200e+02, 2.0140e+03, 0.0000e+00, 7.1000e+01, 3.0000e+00, 1.0370e+01,\n",
            "        0.0000e+00, 1.3300e+02, 6.6000e+01, 4.0000e+00, 9.5000e+01, 9.1200e+00,\n",
            "        9.5000e+01, 1.0000e-01, 8.0000e-01, 5.0000e-01, 6.2742e-01, 1.2000e+01])\n",
            "Target: tensor([81.])\n",
            "Prediction: tensor([91.6689])\n",
            "Input: tensor([7.4000e+01, 2.0060e+03, 1.0000e+00, 2.8000e+01, 1.5000e+03, 1.3700e+00,\n",
            "        3.4859e+01, 6.4185e+04, 1.3900e+01, 2.0000e+03, 6.6000e+01, 4.2500e+00,\n",
            "        6.5000e+01, 3.0000e-01, 2.7100e+01, 2.8000e+01, 5.3600e-01, 9.7000e+00])\n",
            "Target: tensor([64.8000])\n",
            "Prediction: tensor([335.3307])\n",
            "Input: tensor([1.1100e+02, 2.0110e+03, 1.0000e+00, 2.7000e+01, 4.7000e+01, 3.3000e-01,\n",
            "        2.1237e+01, 2.0460e+03, 2.5000e+00, 6.1000e+01, 9.0000e+00, 1.8700e+00,\n",
            "        8.4000e+01, 5.0000e-01, 1.3000e+01, 1.3300e+01, 5.2600e-01, 9.1000e+00])\n",
            "Target: tensor([65.6000])\n",
            "Prediction: tensor([93.7557])\n",
            "Input: tensor([1.3900e+02, 2.0060e+03, 1.0000e+00, 1.0000e+00, 9.0000e+00, 8.0000e-02,\n",
            "        1.3955e+03, 8.0700e+02, 6.9000e+00, 1.0000e+01, 9.6000e+01, 3.5500e+00,\n",
            "        9.6000e+01, 1.0000e-01, 7.2000e+00, 7.3000e+00, 7.6700e-01, 1.2500e+01])\n",
            "Target: tensor([73.2000])\n",
            "Prediction: tensor([77.9847])\n",
            "Input: tensor([1.3300e+02, 2.0090e+03, 1.0000e+00, 2.6100e+02, 1.5000e+01, 1.1210e+01,\n",
            "        1.3701e+02, 1.0100e+02, 5.7000e+01, 1.8000e+01, 9.8000e+01, 7.4400e+00,\n",
            "        9.8000e+01, 3.0000e-01, 2.3000e+00, 2.5000e+00, 7.7600e-01, 1.4000e+01])\n",
            "Target: tensor([68.2000])\n",
            "Prediction: tensor([72.5241])\n",
            "Input: tensor([1.0900e+02, 2.0030e+03, 1.0000e+00, 1.4600e+02, 2.4000e+01, 5.8000e-01,\n",
            "        8.8165e+01, 1.0841e+04, 4.7300e+01, 2.8000e+01, 9.1000e+01, 5.2500e+00,\n",
            "        9.1000e+01, 1.0000e-01, 6.6000e+00, 6.4000e+00, 5.5100e-01, 9.3000e+00])\n",
            "Target: tensor([69.9000])\n",
            "Prediction: tensor([65.8311])\n",
            "Input: tensor([1.0900e+02, 2.0040e+03, 1.0000e+00, 1.4200e+02, 2.3000e+01, 5.6000e-01,\n",
            "        1.0036e+02, 6.3990e+03, 4.8200e+01, 2.7000e+01, 9.7000e+01, 5.2200e+00,\n",
            "        9.7000e+01, 1.0000e-01, 6.5000e+00, 6.4000e+00, 5.6100e-01, 9.6000e+00])\n",
            "Target: tensor([72.])\n",
            "Prediction: tensor([69.2414])\n",
            "Input: tensor([1.1600e+02, 2.0090e+03, 1.0000e+00, 1.6300e+02, 3.0000e+00, 3.3600e+00,\n",
            "        2.9275e+02, 0.0000e+00, 4.9400e+01, 3.0000e+00, 9.9000e+01, 6.8200e+00,\n",
            "        9.8000e+01, 2.0000e-01, 1.9000e+00, 1.8000e+00, 6.1300e-01, 1.1300e+01])\n",
            "Target: tensor([73.2000])\n",
            "Prediction: tensor([71.7291])\n",
            "Input: tensor([1.1100e+02, 2.0020e+03, 1.0000e+00, 2.3500e+02, 7.1000e+01, 4.1000e-01,\n",
            "        3.4219e+00, 7.3600e+02, 1.4600e+01, 9.6000e+01, 8.4000e+01, 2.5000e+00,\n",
            "        7.9000e+01, 4.0000e-01, 1.3300e+01, 1.3700e+01, 4.3500e-01, 7.6000e+00])\n",
            "Target: tensor([62.8000])\n",
            "Prediction: tensor([71.1489])\n",
            "Input: tensor([1.5300e+02, 2.0010e+03, 1.0000e+00, 2.8300e+02, 7.1000e+01, 1.8100e+00,\n",
            "        2.8881e+01, 4.3620e+03, 3.8235e+01, 1.0800e+02, 6.6000e+01, 2.9600e+00,\n",
            "        6.6000e+01, 2.0000e-01, 4.8506e+00, 4.8814e+00, 3.9900e-01, 5.6000e+00])\n",
            "Target: tensor([58.9000])\n",
            "Prediction: tensor([79.6571])\n",
            "Input: tensor([2.6000e+01, 2.0030e+03, 1.0000e+00, 3.8700e+02, 2.4000e+01, 5.8400e+00,\n",
            "        6.5453e+00, 2.2400e+02, 1.3500e+01, 3.8000e+01, 7.5000e+01, 5.2500e+00,\n",
            "        8.2000e+01, 5.1000e+00, 8.5000e+00, 8.5000e+00, 2.7600e-01, 4.7000e+00])\n",
            "Target: tensor([51.9000])\n",
            "Prediction: tensor([43.2030])\n",
            "Input: tensor([9.2000e+01, 2.0000e+03, 1.0000e+00, 5.4300e+02, 5.0000e+00, 3.1000e+00,\n",
            "        2.9866e+01, 6.6000e+02, 2.4900e+01, 7.0000e+00, 8.2000e+01, 6.9200e+00,\n",
            "        8.3000e+01, 2.9800e+01, 1.1500e+01, 1.1600e+01, 4.4500e-01, 9.6000e+00])\n",
            "Target: tensor([49.3000])\n",
            "Prediction: tensor([33.4920])\n",
            "Input: tensor([1.0100e+02, 2.0070e+03, 1.0000e+00, 2.8200e+02, 5.6000e+01, 5.5000e-01,\n",
            "        8.1840e+01, 2.0000e+00, 1.9000e+01, 9.6000e+01, 7.6000e+01, 6.9700e+00,\n",
            "        7.4000e+01, 1.7000e+00, 9.4000e+00, 9.3000e+00, 3.6300e-01, 6.4000e+00])\n",
            "Target: tensor([55.])\n",
            "Prediction: tensor([68.0698])\n",
            "Input: tensor([1.1400e+02, 2.0060e+03, 0.0000e+00, 7.1000e+01, 1.0000e+00, 9.7900e+00,\n",
            "        8.3440e+03, 1.0000e+00, 5.6500e+01, 1.0000e+00, 9.6000e+01, 9.3600e+00,\n",
            "        9.6000e+01, 1.0000e-01, 1.0000e+00, 1.0000e+00, 8.9300e-01, 1.6500e+01])\n",
            "Target: tensor([79.8000])\n",
            "Prediction: tensor([87.0991])\n",
            "Input: tensor([1.7100e+02, 2.0150e+03, 1.0000e+00, 7.5000e+01, 1.0000e+00, 4.6149e+00,\n",
            "        0.0000e+00, 3.4700e+02, 6.4200e+01, 1.0000e+00, 9.9000e+01, 5.9302e+00,\n",
            "        9.9000e+01, 1.0000e-01, 5.3000e+00, 5.1000e+00, 8.3600e-01, 1.3300e+01])\n",
            "Target: tensor([77.1000])\n",
            "Prediction: tensor([87.1705])\n",
            "Input: tensor([9.5000e+01, 2.0070e+03, 0.0000e+00, 2.4000e+01, 0.0000e+00, 1.3400e+01,\n",
            "        1.5815e+03, 0.0000e+00, 5.9000e+01, 0.0000e+00, 9.5000e+01, 6.2200e+00,\n",
            "        9.5000e+01, 1.0000e-01, 2.9000e+00, 3.0000e+00, 8.1200e-01, 1.6400e+01])\n",
            "Target: tensor([72.])\n",
            "Prediction: tensor([83.2571])\n",
            "Input: tensor([1.1800e+02, 2.0030e+03, 1.0000e+00, 4.1000e+01, 5.6700e+02, 9.7500e+00,\n",
            "        3.0196e+01, 1.4126e+05, 1.8300e+01, 9.1800e+02, 4.2000e+01, 4.5000e+00,\n",
            "        2.9000e+01, 5.4000e+00, 1.3500e+01, 1.3600e+01, 0.0000e+00, 8.1000e+00])\n",
            "Target: tensor([48.1000])\n",
            "Prediction: tensor([83.5857])\n",
            "Input: tensor([1.0700e+02, 2.0130e+03, 1.0000e+00, 2.2700e+02, 1.0000e+00, 1.0000e-02,\n",
            "        2.4120e+02, 0.0000e+00, 5.4000e+00, 1.0000e+00, 9.8000e+01, 4.2100e+00,\n",
            "        9.8000e+01, 1.0000e-01, 2.2000e+00, 2.3000e+00, 7.2000e-01, 1.4700e+01])\n",
            "Target: tensor([68.1000])\n",
            "Prediction: tensor([56.2630])\n",
            "Input: tensor([8.2000e+01, 2.0050e+03, 0.0000e+00, 6.9000e+01, 3.0000e+00, 7.9900e+00,\n",
            "        6.7997e+03, 0.0000e+00, 2.4400e+01, 4.0000e+00, 9.5000e+01, 8.1800e+00,\n",
            "        9.8000e+01, 1.0000e-01, 1.7000e+00, 1.5000e+00, 8.7000e-01, 1.4900e+01])\n",
            "Target: tensor([82.])\n",
            "Prediction: tensor([75.9230])\n",
            "Input: tensor([1.3200e+02, 2.0100e+03, 0.0000e+00, 1.5300e+02, 2.0000e+00, 9.0000e+00,\n",
            "        9.8325e+02, 1.9300e+02, 5.6900e+01, 2.0000e+00, 9.4000e+01, 5.8300e+00,\n",
            "        9.4000e+01, 1.0000e-01, 3.0000e+00, 3.2000e+00, 7.9700e-01, 1.5800e+01])\n",
            "Target: tensor([73.4000])\n",
            "Prediction: tensor([77.7039])\n",
            "Input: tensor([9.1000e+01, 2.0020e+03, 1.0000e+00, 1.7000e+01, 1.0000e+00, 1.9800e+00,\n",
            "        7.0132e+01, 3.6000e+01, 5.9100e+01, 1.0000e+00, 7.7000e+01, 1.5000e+00,\n",
            "        7.7000e+01, 1.0000e-01, 4.8000e+00, 4.7000e+00, 0.0000e+00, 1.5200e+01])\n",
            "Target: tensor([73.2000])\n",
            "Prediction: tensor([80.8066])\n",
            "Input: tensor([2.2000e+01, 2.0100e+03, 1.0000e+00, 1.5400e+02, 5.4000e+01, 7.5200e+00,\n",
            "        1.1112e+03, 6.8000e+01, 5.2000e+01, 6.1000e+01, 9.9000e+01, 8.2700e+00,\n",
            "        9.9000e+01, 1.0000e-01, 2.9000e+00, 2.9000e+00, 7.1600e-01, 1.3800e+01])\n",
            "Target: tensor([73.8000])\n",
            "Prediction: tensor([72.2660])\n",
            "Input: tensor([3.5000e+01, 2.0070e+03, 1.0000e+00, 1.4400e+02, 1.4000e+01, 4.6600e+00,\n",
            "        7.8059e+02, 0.0000e+00, 5.2000e+01, 1.7000e+01, 9.3000e+01, 6.2500e+00,\n",
            "        9.3000e+01, 1.0000e-01, 2.3000e+00, 2.1000e+00, 6.7500e-01, 1.1900e+01])\n",
            "Target: tensor([73.5000])\n",
            "Prediction: tensor([66.1271])\n",
            "Input: tensor([1.4100e+02, 2.0090e+03, 1.0000e+00, 1.3100e+02, 1.0000e+00, 9.8500e+00,\n",
            "        8.2081e+02, 1.0000e+00, 5.6400e+01, 1.0000e+00, 9.7000e+01, 9.9000e+00,\n",
            "        9.5000e+01, 1.0000e-01, 2.3000e+00, 2.3000e+00, 7.5400e-01, 1.3600e+01])\n",
            "Target: tensor([74.1000])\n",
            "Prediction: tensor([80.4773])\n",
            "Input: tensor([2.2000e+01, 2.0150e+03, 1.0000e+00, 1.4200e+02, 4.2000e+01, 4.6149e+00,\n",
            "        0.0000e+00, 2.1400e+02, 5.6100e+01, 4.7000e+01, 9.8000e+01, 5.9302e+00,\n",
            "        9.6000e+01, 1.0000e-01, 2.7000e+00, 2.6000e+00, 7.5400e-01, 1.5200e+01])\n",
            "Target: tensor([75.])\n",
            "Prediction: tensor([69.5992])\n",
            "Input: tensor([4.0000e+00, 2.0100e+03, 1.0000e+00, 1.3800e+02, 0.0000e+00, 7.8400e+00,\n",
            "        1.9840e+03, 0.0000e+00, 4.4400e+01, 0.0000e+00, 9.9000e+01, 5.6300e+00,\n",
            "        9.8000e+01, 1.0000e-01, 3.3000e+00, 3.3000e+00, 7.8300e-01, 1.4100e+01])\n",
            "Target: tensor([75.6000])\n",
            "Prediction: tensor([58.4189])\n",
            "Input: tensor([1.2000e+01, 2.0100e+03, 1.0000e+00, 1.4200e+02, 1.2600e+02, 1.0000e-02,\n",
            "        6.2659e+01, 7.8800e+02, 1.5200e+01, 1.6100e+02, 9.4000e+01, 3.6000e+00,\n",
            "        9.4000e+01, 1.0000e-01, 1.8900e+01, 1.9400e+01, 5.3500e-01, 8.9000e+00])\n",
            "Target: tensor([69.9000])\n",
            "Prediction: tensor([74.7252])\n",
            "Input: tensor([6.7000e+01, 2.0090e+03, 1.0000e+00, 2.9700e+02, 2.9000e+01, 1.8000e-01,\n",
            "        2.4848e+01, 2.6400e+02, 2.3000e+00, 4.6000e+01, 6.0000e+00, 3.8500e+00,\n",
            "        5.7000e+01, 2.3000e+00, 8.4000e+00, 8.4000e+00, 3.7600e-01, 8.1000e+00])\n",
            "Target: tensor([57.3000])\n",
            "Prediction: tensor([65.3484])\n",
            "Input: tensor([1.7800e+02, 2.0060e+03, 1.0000e+00, 1.6300e+02, 9.0000e+00, 8.2700e+00,\n",
            "        0.0000e+00, 7.8000e+01, 5.7100e+01, 1.1000e+01, 7.3000e+01, 4.8500e+00,\n",
            "        7.1000e+01, 1.0000e-01, 1.6000e+00, 1.6000e+00, 7.1400e-01, 1.2400e+01])\n",
            "Target: tensor([73.6000])\n",
            "Prediction: tensor([86.1696])\n",
            "Input: tensor([6.1000e+01, 2.0110e+03, 1.0000e+00, 1.2700e+02, 1.0000e+00, 8.1400e+00,\n",
            "        1.9895e+02, 6.4000e+01, 5.2800e+01, 1.0000e+00, 8.8000e+01, 9.3800e+00,\n",
            "        9.4000e+01, 1.0000e-01, 2.6000e+00, 2.8000e+00, 7.4200e-01, 1.3300e+01])\n",
            "Target: tensor([73.9000])\n",
            "Prediction: tensor([70.0319])\n",
            "Input: tensor([1.5500e+02, 2.0110e+03, 1.0000e+00, 4.3800e+02, 2.0000e+00, 5.2000e+00,\n",
            "        7.3571e+02, 0.0000e+00, 3.2000e+00, 3.0000e+00, 8.5000e+01, 8.6100e+00,\n",
            "        9.1000e+01, 1.5700e+01, 5.1000e+00, 5.2000e+00, 5.2600e-01, 1.1200e+01])\n",
            "Target: tensor([55.])\n",
            "Prediction: tensor([49.5960])\n",
            "Input: tensor([1.3600e+02, 2.0130e+03, 1.0000e+00, 1.6100e+02, 0.0000e+00, 7.0700e+00,\n",
            "        0.0000e+00, 0.0000e+00, 5.2200e+01, 0.0000e+00, 9.7000e+01, 5.2100e+00,\n",
            "        9.7000e+01, 1.0000e-01, 3.5000e+00, 3.4000e+00, 7.1700e-01, 1.3300e+01])\n",
            "Target: tensor([72.7000])\n",
            "Prediction: tensor([74.9616])\n",
            "Input: tensor([1.7200e+02, 2.0030e+03, 0.0000e+00, 8.6000e+01, 4.0000e+00, 1.1850e+01,\n",
            "        0.0000e+00, 4.6000e+02, 5.9500e+01, 4.0000e+00, 9.1000e+01, 7.8100e+00,\n",
            "        9.1000e+01, 1.0000e-01, 7.0000e-01, 5.0000e-01, 6.2742e-01, 1.2000e+01])\n",
            "Target: tensor([78.3000])\n",
            "Prediction: tensor([89.4656])\n",
            "Input: tensor([1.2000e+01, 2.0090e+03, 1.0000e+00, 1.4400e+02, 1.3500e+02, 1.0000e-02,\n",
            "        5.3264e+01, 7.1800e+02, 1.4600e+01, 1.7300e+02, 9.7000e+01, 2.9100e+00,\n",
            "        9.7000e+01, 1.0000e-01, 1.9100e+01, 1.9700e+01, 5.2300e-01, 8.4000e+00])\n",
            "Target: tensor([69.5000])\n",
            "Prediction: tensor([75.9470])\n",
            "Input: tensor([7.9000e+01, 2.0140e+03, 1.0000e+00, 6.0000e+00, 1.0000e+00, 2.6200e+00,\n",
            "        4.3483e+03, 6.0000e+00, 6.4600e+01, 1.0000e+00, 9.5000e+01, 7.8100e+00,\n",
            "        9.5000e+01, 1.0000e-01, 1.2000e+00, 1.1000e+00, 8.9500e-01, 1.6000e+01])\n",
            "Target: tensor([82.2000])\n",
            "Prediction: tensor([84.0562])\n",
            "Input: tensor([5.6000e+01, 2.0110e+03, 1.0000e+00, 1.9700e+02, 0.0000e+00, 1.0000e-02,\n",
            "        4.0179e+02, 0.0000e+00, 5.9500e+01, 0.0000e+00, 9.9000e+01, 4.6000e+00,\n",
            "        9.9000e+01, 1.0000e-01, 4.0000e+00, 3.7000e+00, 7.0900e-01, 1.4700e+01])\n",
            "Target: tensor([69.2000])\n",
            "Prediction: tensor([61.2582])\n",
            "Input: tensor([1.1500e+02, 2.0120e+03, 0.0000e+00, 7.0000e+00, 0.0000e+00, 9.2000e+00,\n",
            "        9.2457e+02, 6.8000e+01, 6.5900e+01, 0.0000e+00, 9.3000e+01, 1.1530e+01,\n",
            "        9.3000e+01, 1.0000e-01, 3.0000e-01, 3.0000e-01, 9.0400e-01, 1.9500e+01])\n",
            "Target: tensor([81.1000])\n",
            "Prediction: tensor([88.6115])\n",
            "Input: tensor([1.1000e+01, 2.0070e+03, 1.0000e+00, 7.7000e+01, 0.0000e+00, 2.0000e+00,\n",
            "        2.7836e+02, 7.0000e+00, 5.7600e+01, 0.0000e+00, 9.7000e+01, 3.8000e+00,\n",
            "        9.7000e+01, 1.0000e-01, 6.1000e+00, 5.9000e+00, 8.1300e-01, 1.4400e+01])\n",
            "Target: tensor([75.6000])\n",
            "Prediction: tensor([63.2617])\n",
            "Input: tensor([4.1000e+01, 2.0090e+03, 0.0000e+00, 6.0000e+00, 0.0000e+00, 1.0800e+01,\n",
            "        2.3025e+02, 0.0000e+00, 5.7300e+01, 0.0000e+00, 9.9000e+01, 7.4000e+00,\n",
            "        9.9000e+01, 1.0000e-01, 9.0000e-01, 1.0000e+00, 8.4900e-01, 1.4100e+01])\n",
            "Target: tensor([79.3000])\n",
            "Prediction: tensor([75.5157])\n",
            "Input: tensor([1.5900e+02, 2.0050e+03, 1.0000e+00, 1.9400e+02, 1.0000e+01, 3.7000e-01,\n",
            "        1.9837e+01, 0.0000e+00, 3.3500e+01, 1.2000e+01, 7.9000e+01, 5.8900e+00,\n",
            "        8.4000e+01, 3.0000e-01, 3.8000e+00, 3.9000e+00, 5.7200e-01, 1.0600e+01])\n",
            "Target: tensor([65.5000])\n",
            "Prediction: tensor([75.2820])\n",
            "Input: tensor([1.1000e+02, 2.0010e+03, 1.0000e+00, 4.8000e+01, 9.0000e+01, 2.0900e+00,\n",
            "        3.7825e+01, 7.0850e+03, 1.6900e+01, 1.3200e+02, 7.2000e+01, 5.6400e+00,\n",
            "        7.3000e+01, 1.3400e+01, 4.1000e+00, 4.0000e+00, 2.9800e-01, 5.8000e+00])\n",
            "Target: tensor([49.5000])\n",
            "Prediction: tensor([86.9306])\n",
            "Input: tensor([9.6000e+01, 2.0000e+03, 0.0000e+00, 9.8000e+01, 0.0000e+00, 1.3140e+01,\n",
            "        8.2461e+03, 0.0000e+00, 5.4000e+01, 0.0000e+00, 9.9000e+01, 7.4800e+00,\n",
            "        9.9000e+01, 1.0000e-01, 1.0000e+00, 1.0000e+00, 8.4800e-01, 1.3500e+01])\n",
            "Target: tensor([77.8000])\n",
            "Prediction: tensor([81.9367])\n",
            "Input: tensor([9.7000e+01, 2.0000e+03, 1.0000e+00, 2.8300e+02, 4.4000e+01, 1.1600e+00,\n",
            "        3.5661e+01, 3.5256e+04, 1.3900e+01, 6.8000e+01, 5.8000e+01, 5.8000e+00,\n",
            "        5.7000e+01, 6.0000e-01, 8.7000e+00, 8.6000e+00, 0.0000e+00, 8.0000e+00])\n",
            "Target: tensor([57.9000])\n",
            "Prediction: tensor([35.1960])\n",
            "Input: tensor([7.1000e+01, 2.0130e+03, 1.0000e+00, 1.5000e+01, 4.0000e+00, 3.1100e+00,\n",
            "        3.1176e+02, 0.0000e+00, 4.9300e+01, 4.0000e+00, 9.7000e+01, 9.1500e+00,\n",
            "        9.7000e+01, 4.0000e-01, 2.2000e+00, 2.1000e+00, 6.1400e-01, 1.1600e+01])\n",
            "Target: tensor([74.3000])\n",
            "Prediction: tensor([77.0414])\n",
            "Input: tensor([1.5100e+02, 2.0030e+03, 0.0000e+00, 8.3000e+01, 2.0000e+00, 1.2090e+01,\n",
            "        3.2050e+03, 2.5600e+02, 5.9300e+01, 2.0000e+00, 9.9000e+01, 7.9900e+00,\n",
            "        9.8000e+01, 1.0000e-01, 6.0000e-01, 5.0000e-01, 8.3000e-01, 1.5600e+01])\n",
            "Target: tensor([79.4000])\n",
            "Prediction: tensor([87.8560])\n",
            "Input: tensor([3.3000e+01, 2.0100e+03, 1.0000e+00, 8.9000e+01, 2.0000e+00, 7.9300e+00,\n",
            "        1.7749e+02, 0.0000e+00, 6.6000e+00, 2.0000e+00, 9.2000e+01, 6.9700e+00,\n",
            "        9.2000e+01, 1.0000e-01, 8.0000e-01, 9.0000e-01, 8.1500e-01, 1.5200e+01])\n",
            "Target: tensor([79.1000])\n",
            "Prediction: tensor([59.2858])\n",
            "Input: tensor([6.7000e+01, 2.0070e+03, 1.0000e+00, 3.6000e+01, 3.1000e+01, 1.9000e-01,\n",
            "        1.3996e+00, 3.0000e+00, 1.9400e+01, 4.8000e+01, 4.6000e+01, 3.8000e+00,\n",
            "        6.3000e+01, 2.4000e+00, 8.9000e+00, 8.8000e+00, 3.6400e-01, 7.6000e+00])\n",
            "Target: tensor([56.4000])\n",
            "Prediction: tensor([79.8885])\n",
            "Input: tensor([2.3000e+01, 2.0050e+03, 1.0000e+00, 9.2000e+01, 0.0000e+00, 1.6000e-01,\n",
            "        1.7971e+02, 9.0000e+00, 3.1200e+01, 0.0000e+00, 9.3000e+01, 2.6200e+00,\n",
            "        9.4000e+01, 1.0000e-01, 6.4000e+00, 5.9000e+00, 8.3400e-01, 1.4100e+01])\n",
            "Target: tensor([76.2000])\n",
            "Prediction: tensor([58.7234])\n",
            "Input: tensor([1.3600e+02, 2.0030e+03, 1.0000e+00, 1.8400e+02, 0.0000e+00, 5.1000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 4.2900e+01, 0.0000e+00, 9.9000e+01, 3.9100e+00,\n",
            "        9.9000e+01, 4.0000e-01, 3.8000e+00, 3.8000e+00, 6.8200e-01, 1.3000e+01])\n",
            "Target: tensor([71.])\n",
            "Prediction: tensor([70.3048])\n",
            "Input: tensor([1.1500e+02, 2.0000e+03, 0.0000e+00, 8.7000e+01, 0.0000e+00, 8.9100e+00,\n",
            "        2.1430e+03, 6.5000e+01, 5.8900e+01, 0.0000e+00, 8.2000e+01, 7.4700e+00,\n",
            "        9.0000e+00, 1.0000e-01, 3.0000e-01, 3.0000e-01, 8.6400e-01, 1.7200e+01])\n",
            "Target: tensor([78.6000])\n",
            "Prediction: tensor([75.8583])\n",
            "Input: tensor([3.4000e+01, 2.0070e+03, 1.0000e+00, 9.6000e+01, 2.8500e+02, 3.8800e+00,\n",
            "        3.1266e+02, 1.0902e+05, 2.5700e+01, 3.3200e+02, 9.4000e+01, 4.3200e+00,\n",
            "        9.3000e+01, 1.0000e-01, 4.7000e+00, 4.1000e+00, 6.5900e-01, 1.1400e+01])\n",
            "Target: tensor([74.4000])\n",
            "Prediction: tensor([26.2209])\n",
            "Input: tensor([1.1200e+02, 2.0020e+03, 1.0000e+00, 4.5200e+02, 3.0000e+00, 5.0900e+00,\n",
            "        2.0373e+02, 1.2780e+03, 2.5800e+01, 4.0000e+00, 7.8000e+01, 6.1700e+00,\n",
            "        7.7000e+01, 2.4600e+01, 1.4700e+01, 1.4800e+01, 5.5600e-01, 1.1800e+01])\n",
            "Target: tensor([55.7000])\n",
            "Prediction: tensor([42.5991])\n",
            "Input: tensor([7.0000e+01, 2.0130e+03, 1.0000e+00, 2.5300e+02, 1.4000e+01, 5.6800e+00,\n",
            "        4.9897e+00, 0.0000e+00, 4.7700e+01, 1.9000e+01, 6.7000e+01, 8.1000e+00,\n",
            "        6.8000e+01, 5.0000e-01, 3.9000e+00, 3.9000e+00, 4.8300e-01, 9.1000e+00])\n",
            "Target: tensor([62.7000])\n",
            "Prediction: tensor([65.2721])\n",
            "Input: tensor([9.5000e+01, 2.0150e+03, 0.0000e+00, 1.6500e+02, 0.0000e+00, 4.6149e+00,\n",
            "        0.0000e+00, 5.0000e+01, 6.2400e+01, 0.0000e+00, 9.3000e+01, 5.9302e+00,\n",
            "        9.3000e+01, 1.0000e-01, 2.6000e+00, 2.6000e+00, 8.4600e-01, 1.6500e+01])\n",
            "Target: tensor([73.6000])\n",
            "Prediction: tensor([71.3195])\n",
            "Input: tensor([1.0800e+02, 2.0130e+03, 1.0000e+00, 1.9000e+01, 0.0000e+00, 1.0000e-02,\n",
            "        7.0714e+02, 0.0000e+00, 6.7000e+00, 0.0000e+00, 9.4000e+01, 6.4300e+00,\n",
            "        9.4000e+01, 1.0000e-01, 1.8000e+00, 1.9000e+00, 7.9900e-01, 1.5100e+01])\n",
            "Target: tensor([75.8000])\n",
            "Prediction: tensor([72.4706])\n",
            "Input: tensor([4.9000e+01, 2.0100e+03, 1.0000e+00, 1.3400e+02, 7.0000e+00, 3.9500e+00,\n",
            "        3.6793e+02, 0.0000e+00, 5.7000e+00, 8.0000e+00, 8.8000e+01, 5.9000e+00,\n",
            "        9.1000e+01, 1.0000e-01, 1.3000e+00, 1.2000e+00, 7.0300e-01, 1.3100e+01])\n",
            "Target: tensor([75.])\n",
            "Prediction: tensor([59.0718])\n",
            "Input: tensor([1.3200e+02, 2.0110e+03, 0.0000e+00, 1.3900e+02, 2.0000e+00, 9.1000e+00,\n",
            "        1.0326e+01, 4.1890e+03, 5.7700e+01, 2.0000e+00, 8.9000e+01, 5.5300e+00,\n",
            "        8.9000e+01, 1.0000e-01, 2.9000e+00, 3.1000e+00, 7.9800e-01, 1.5700e+01])\n",
            "Target: tensor([74.3000])\n",
            "Prediction: tensor([75.2976])\n",
            "Input: tensor([1.1300e+02, 2.0040e+03, 1.0000e+00, 2.1800e+02, 3.5000e+01, 2.1000e-01,\n",
            "        3.1932e+01, 1.2074e+04, 1.3400e+01, 4.7000e+01, 8.0000e+00, 5.8200e+00,\n",
            "        8.0000e+00, 2.0000e-01, 1.7800e+01, 1.8400e+01, 4.6300e-01, 9.3000e+00])\n",
            "Target: tensor([64.7000])\n",
            "Prediction: tensor([63.7114])\n",
            "Input: tensor([4.3000e+01, 2.0150e+03, 1.0000e+00, 3.9700e+02, 5.7000e+01, 4.6149e+00,\n",
            "        0.0000e+00, 6.5000e+01, 2.8000e+01, 7.9000e+01, 8.1000e+01, 5.9302e+00,\n",
            "        8.3000e+01, 1.9000e+00, 5.5000e+00, 5.5000e+00, 6.2742e-01, 1.2000e+01])\n",
            "Target: tensor([53.3000])\n",
            "Prediction: tensor([54.4151])\n",
            "Input: tensor([1.2200e+02, 2.0120e+03, 1.0000e+00, 1.2000e+01, 1.0000e+00, 6.9500e+00,\n",
            "        2.0175e+02, 0.0000e+00, 5.5600e+01, 1.0000e+00, 8.7000e+01, 7.2500e+00,\n",
            "        8.5000e+01, 1.0000e-01, 1.9000e+00, 1.9000e+00, 7.6500e-01, 1.2800e+01])\n",
            "Target: tensor([77.2000])\n",
            "Prediction: tensor([86.1548])\n",
            "Input: tensor([1.6700e+02, 2.0100e+03, 1.0000e+00, 1.1600e+02, 2.1000e+01, 1.4900e+00,\n",
            "        3.2782e+01, 7.0000e+00, 6.1900e+01, 2.5000e+01, 9.7000e+01, 5.6100e+00,\n",
            "        9.7000e+01, 1.0000e-01, 4.9000e+00, 4.7000e+00, 7.1500e-01, 1.3000e+01])\n",
            "Target: tensor([74.2000])\n",
            "Prediction: tensor([87.2748])\n",
            "Input: tensor([7.5000e+01, 2.0060e+03, 1.0000e+00, 1.9100e+02, 1.5900e+02, 6.0000e-02,\n",
            "        7.2016e+01, 2.0422e+04, 1.9700e+01, 1.9400e+02, 7.8000e+01, 2.9100e+00,\n",
            "        7.2000e+01, 1.0000e-01, 1.8000e+00, 1.8000e+00, 6.3200e-01, 1.0900e+01])\n",
            "Target: tensor([67.3000])\n",
            "Prediction: tensor([74.5619])\n",
            "Input: tensor([1.2600e+02, 2.0090e+03, 1.0000e+00, 2.1900e+02, 5.9000e+01, 4.4200e+00,\n",
            "        1.5953e+02, 1.4690e+03, 2.2100e+01, 7.6000e+01, 8.6000e+01, 4.4100e+00,\n",
            "        8.7000e+01, 1.0000e-01, 1.0000e+00, 9.7000e+00, 6.6100e-01, 1.1700e+01])\n",
            "Target: tensor([68.])\n",
            "Prediction: tensor([74.2818])\n",
            "Input: tensor([9.7000e+01, 2.0120e+03, 1.0000e+00, 2.3500e+02, 3.0000e+01, 8.7000e-01,\n",
            "        5.9979e+01, 2.0000e+00, 1.9000e+01, 4.2000e+01, 7.1000e+01, 3.4600e+00,\n",
            "        7.0000e+00, 4.0000e-01, 7.4000e+00, 7.3000e+00, 5.0600e-01, 1.0200e+01])\n",
            "Target: tensor([64.3000])\n",
            "Prediction: tensor([59.4545])\n",
            "Input: tensor([1.2400e+02, 2.0140e+03, 1.0000e+00, 1.4700e+02, 3.0000e+00, 1.0000e-02,\n",
            "        5.6177e+02, 0.0000e+00, 4.9400e+01, 3.0000e+00, 8.3000e+01, 9.8100e+00,\n",
            "        8.7000e+01, 2.0000e-01, 2.0000e+00, 1.9000e+00, 6.8800e-01, 1.2300e+01])\n",
            "Target: tensor([73.9000])\n",
            "Prediction: tensor([76.3215])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_TaXhrluZtS",
        "colab_type": "text"
      },
      "source": [
        "16. The distribution of the model predictions are closed to the desired one. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pliHZDbesFWT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "55004107-a251-45d6-8d8f-f5165316af78"
      },
      "source": [
        "predictions = np.array(predictions)\n",
        "\n",
        "bins = np.arange(0, 100, 5) \n",
        "plt.hist(predictions, bins=bins, alpha=0.5)\n",
        "plt.title('Random Gaussian data (fixed bin size)')\n",
        "plt.xlabel('variable X (bin size = 5)')\n",
        "plt.ylabel('count')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVy5JuYvrkQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}